{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "007c1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/prompt/OpenPrompt\n"
     ]
    }
   ],
   "source": [
    "%cd /aiffel/aiffel/aiffelthon/prompt/OpenPrompt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856572c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Prompt-Summarization'...\n",
      "remote: Enumerating objects: 72487, done.\u001b[K\n",
      "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
      "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
      "remote: Total 72487 (delta 101), reused 189 (delta 100), pack-reused 72297\u001b[K\n",
      "Receiving objects: 100% (72487/72487), 615.41 MiB | 22.31 MiB/s, done.\n",
      "Resolving deltas: 100% (18155/18155), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/kurbster/Prompt-Summarization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0741f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/prompt_sum/Prompt-Summarization\n"
     ]
    }
   ],
   "source": [
    "#%cd /aiffel/aiffel/aiffelthon/prompt_sum/Prompt-Summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18c85ba",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirements: ['transformers>=4.10.0', 'sentencepiece==0.1.96', '# scikit-learn>=0.24.2', 'tqdm>=4.62.2', 'tensorboardX', 'nltk', 'yacs', 'dill', 'datasets', 'rouge==1.0.0', 'pyarrow', 'scipy']\n",
      "running install\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.996-ko-0.9.2 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing openprompt.egg-info/PKG-INFO\n",
      "writing dependency_links to openprompt.egg-info/dependency_links.txt\n",
      "writing requirements to openprompt.egg-info/requires.txt\n",
      "writing top-level names to openprompt.egg-info/top_level.txt\n",
      "reading manifest file 'openprompt.egg-info/SOURCES.txt'\n",
      "adding license file 'LICENSE'\n",
      "writing manifest file 'openprompt.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "copying openprompt/plms/__init__.py -> build/lib/openprompt/plms\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/openprompt\n",
      "copying build/lib/openprompt/lm_bff_trainer.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "copying build/lib/openprompt/config.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "copying build/lib/openprompt/protoverb_trainer.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "creating build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/crossfit_metrics.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/logging.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/cuda.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/calibrate.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/metrics.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/reproduciblity.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/utils/utils.py -> build/bdist.linux-x86_64/egg/openprompt/utils\n",
      "copying build/lib/openprompt/__init__.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "creating build/bdist.linux-x86_64/egg/openprompt/plms\n",
      "copying build/lib/openprompt/plms/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
      "copying build/lib/openprompt/plms/lm.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
      "copying build/lib/openprompt/plms/seq2seq.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
      "copying build/lib/openprompt/plms/mlm.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
      "copying build/lib/openprompt/plms/utils.py -> build/bdist.linux-x86_64/egg/openprompt/plms\n",
      "copying build/lib/openprompt/prompt_base.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "creating build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/soft_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/ptuning_prompts.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/ptr_prompts.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/manual_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/soft_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/knowledgeable_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/automatic_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/manual_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/prompt_generator.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/generation_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/prefix_tuning_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/prototypical_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/one2one_verbalizer.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/prompts/mixed_template.py -> build/bdist.linux-x86_64/egg/openprompt/prompts\n",
      "copying build/lib/openprompt/pipeline_base.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "copying build/lib/openprompt/trainer.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "creating build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/fewglue_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/conditional_generation_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/text_classification_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/lama_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/data_processor.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "creating build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/processor.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/closed_QA.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/sentiment.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/paraphrase.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/relation.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/summarization.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/__init__.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/reading_comprehensation.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/generation.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/topic_classification.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/entity_typing.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/nli.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/ZH/coreference.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH\n",
      "copying build/lib/openprompt/data_utils/nli_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/huggingface_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/typing_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/data_sampler.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/relation_classification_dataset.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/data_utils/utils.py -> build/bdist.linux-x86_64/egg/openprompt/data_utils\n",
      "copying build/lib/openprompt/default_config.py -> build/bdist.linux-x86_64/egg/openprompt\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/lm_bff_trainer.py to lm_bff_trainer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/config.py to config.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/protoverb_trainer.py to protoverb_trainer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/crossfit_metrics.py to crossfit_metrics.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/logging.py to logging.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/cuda.py to cuda.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/calibrate.py to calibrate.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/metrics.py to metrics.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/reproduciblity.py to reproduciblity.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/utils/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/lm.py to lm.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/seq2seq.py to seq2seq.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/mlm.py to mlm.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/plms/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompt_base.py to prompt_base.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/soft_template.py to soft_template.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/ptuning_prompts.py to ptuning_prompts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/ptr_prompts.py to ptr_prompts.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/manual_verbalizer.py to manual_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/soft_verbalizer.py to soft_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/knowledgeable_verbalizer.py to knowledgeable_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/automatic_verbalizer.py to automatic_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/manual_template.py to manual_template.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/prompt_generator.py to prompt_generator.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/generation_verbalizer.py to generation_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/prefix_tuning_template.py to prefix_tuning_template.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/prototypical_verbalizer.py to prototypical_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/one2one_verbalizer.py to one2one_verbalizer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/prompts/mixed_template.py to mixed_template.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/pipeline_base.py to pipeline_base.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/trainer.py to trainer.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/fewglue_dataset.py to fewglue_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/conditional_generation_dataset.py to conditional_generation_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/text_classification_dataset.py to text_classification_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/lama_dataset.py to lama_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/data_processor.py to data_processor.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/processor.py to processor.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/closed_QA.py to closed_QA.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/sentiment.py to sentiment.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/paraphrase.py to paraphrase.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/relation.py to relation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/summarization.py to summarization.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/__init__.py to __init__.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/reading_comprehensation.py to reading_comprehensation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/generation.py to generation.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/topic_classification.py to topic_classification.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/entity_typing.py to entity_typing.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/nli.py to nli.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/ZH/coreference.py to coreference.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/nli_dataset.py to nli_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/huggingface_dataset.py to huggingface_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/typing_dataset.py to typing_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/data_sampler.py to data_sampler.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/relation_classification_dataset.py to relation_classification_dataset.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/data_utils/utils.py to utils.cpython-39.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/openprompt/default_config.py to default_config.cpython-39.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying openprompt.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying openprompt.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying openprompt.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying openprompt.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying openprompt.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "openprompt.prompts.__pycache__.prototypical_verbalizer.cpython-39: module MAY be using inspect.stack\n",
      "creating 'dist/openprompt-1.0.1-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing openprompt-1.0.1-py3.9.egg\n",
      "creating /opt/conda/lib/python3.9/site-packages/openprompt-1.0.1-py3.9.egg\n",
      "Extracting openprompt-1.0.1-py3.9.egg to /opt/conda/lib/python3.9/site-packages\n",
      "Adding openprompt 1.0.1 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.9/site-packages/openprompt-1.0.1-py3.9.egg\n",
      "Processing dependencies for openprompt==1.0.1\n",
      "Searching for scipy==1.7.1\n",
      "Best match: scipy 1.7.1\n",
      "Adding scipy 1.7.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for pyarrow==6.0.1\n",
      "Best match: pyarrow 6.0.1\n",
      "Adding pyarrow 6.0.1 to easy-install.pth file\n",
      "Installing plasma_store script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for rouge==1.0.0\n",
      "Best match: rouge 1.0.0\n",
      "Adding rouge 1.0.0 to easy-install.pth file\n",
      "Installing rouge script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for datasets==2.7.1\n",
      "Best match: datasets 2.7.1\n",
      "Adding datasets 2.7.1 to easy-install.pth file\n",
      "Installing datasets-cli script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for dill==0.3.4\n",
      "Best match: dill 0.3.4\n",
      "Adding dill 0.3.4 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for yacs==0.1.8\n",
      "Best match: yacs 0.1.8\n",
      "Adding yacs 0.1.8 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for nltk==3.6.5\n",
      "Best match: nltk 3.6.5\n",
      "Adding nltk 3.6.5 to easy-install.pth file\n",
      "Installing nltk script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for tensorboardX==2.5.1\n",
      "Best match: tensorboardX 2.5.1\n",
      "Adding tensorboardX 2.5.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for tqdm==4.62.3\n",
      "Best match: tqdm 4.62.3\n",
      "Adding tqdm 4.62.3 to easy-install.pth file\n",
      "Installing tqdm script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for sentencepiece==0.1.96\n",
      "Best match: sentencepiece 0.1.96\n",
      "Adding sentencepiece 0.1.96 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for transformers==4.20.1\n",
      "Best match: transformers 4.20.1\n",
      "Adding transformers 4.20.1 to easy-install.pth file\n",
      "Installing transformers-cli script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for numpy==1.21.4\n",
      "Best match: numpy 1.21.4\n",
      "Adding numpy 1.21.4 to easy-install.pth file\n",
      "Installing f2py script to /opt/conda/bin\n",
      "Installing f2py3 script to /opt/conda/bin\n",
      "Installing f2py3.9 script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for requests==2.26.0\n",
      "Best match: requests 2.26.0\n",
      "Adding requests 2.26.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for PyYAML==6.0\n",
      "Best match: PyYAML 6.0\n",
      "Adding PyYAML 6.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for pandas==1.3.3\n",
      "Best match: pandas 1.3.3\n",
      "Adding pandas 1.3.3 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for packaging==21.3\n",
      "Best match: packaging 21.3\n",
      "Adding packaging 21.3 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for multiprocess==0.70.12.2\n",
      "Best match: multiprocess 0.70.12.2\n",
      "Adding multiprocess 0.70.12.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for huggingface-hub==0.11.0\n",
      "Best match: huggingface-hub 0.11.0\n",
      "Adding huggingface-hub 0.11.0 to easy-install.pth file\n",
      "Installing huggingface-cli script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for aiohttp==3.8.1\n",
      "Best match: aiohttp 3.8.1\n",
      "Adding aiohttp 3.8.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for fsspec==2021.11.1\n",
      "Best match: fsspec 2021.11.1\n",
      "Adding fsspec 2021.11.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for responses==0.18.0\n",
      "Best match: responses 0.18.0\n",
      "Adding responses 0.18.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for xxhash==2.0.2\n",
      "Best match: xxhash 2.0.2\n",
      "Adding xxhash 2.0.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for click==8.0.3\n",
      "Best match: click 8.0.3\n",
      "Adding click 8.0.3 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for joblib==1.1.0\n",
      "Best match: joblib 1.1.0\n",
      "Adding joblib 1.1.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for regex==2021.11.10\n",
      "Best match: regex 2021.11.10\n",
      "Adding regex 2021.11.10 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for protobuf==3.19.1\n",
      "Best match: protobuf 3.19.1\n",
      "Adding protobuf 3.19.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for tokenizers==0.12.1\n",
      "Best match: tokenizers 0.12.1\n",
      "Adding tokenizers 0.12.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for filelock==3.4.0\n",
      "Best match: filelock 3.4.0\n",
      "Adding filelock 3.4.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for idna==2.10\n",
      "Best match: idna 2.10\n",
      "Adding idna 2.10 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.9/site-packages\n",
      "Searching for urllib3==1.26.7\n",
      "Best match: urllib3 1.26.7\n",
      "Adding urllib3 1.26.7 to easy-install.pth file\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for charset-normalizer==2.0.8\r\n",
      "Best match: charset-normalizer 2.0.8\r\n",
      "Adding charset-normalizer 2.0.8 to easy-install.pth file\r\n",
      "Installing normalizer script to /opt/conda/bin\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for certifi==2021.10.8\r\n",
      "Best match: certifi 2021.10.8\r\n",
      "Adding certifi 2021.10.8 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for pytz==2021.3\r\n",
      "Best match: pytz 2021.3\r\n",
      "Adding pytz 2021.3 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for python-dateutil==2.8.2\r\n",
      "Best match: python-dateutil 2.8.2\r\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for pyparsing==3.0.6\r\n",
      "Best match: pyparsing 3.0.6\r\n",
      "Adding pyparsing 3.0.6 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for typing-extensions==4.0.1\r\n",
      "Best match: typing-extensions 4.0.1\r\n",
      "Adding typing-extensions 4.0.1 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for multidict==5.2.0\r\n",
      "Best match: multidict 5.2.0\r\n",
      "Adding multidict 5.2.0 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for attrs==21.2.0\r\n",
      "Best match: attrs 21.2.0\r\n",
      "Adding attrs 21.2.0 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for yarl==1.7.2\r\n",
      "Best match: yarl 1.7.2\r\n",
      "Adding yarl 1.7.2 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for async-timeout==4.0.1\r\n",
      "Best match: async-timeout 4.0.1\r\n",
      "Adding async-timeout 4.0.1 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for frozenlist==1.2.0\r\n",
      "Best match: frozenlist 1.2.0\r\n",
      "Adding frozenlist 1.2.0 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Searching for aiosignal==1.2.0\r\n",
      "Best match: aiosignal 1.2.0\r\n",
      "Adding aiosignal 1.2.0 to easy-install.pth file\r\n",
      "\r\n",
      "Using /opt/conda/lib/python3.9/site-packages\r\n",
      "Finished processing dependencies for openprompt==1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8540422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/prompt/OpenPrompt/openprompt\n"
     ]
    }
   ],
   "source": [
    "%cd /aiffel/aiffel/aiffelthon/prompt/OpenPrompt/openprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bc6cea8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.10.0 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.20.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.96 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.1.96)\n",
      "Requirement already satisfied: tqdm>=4.62.2 in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (4.62.3)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "     |████████████████████████████████| 125 kB 6.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (3.6.5)\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.1.8)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.3.4)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.14.0)\n",
      "Collecting rouge==1.0.0\n",
      "  Downloading rouge-1.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.7.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge==1.0.0->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (2021.11.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers>=4.10.0->-r requirements.txt (line 1)) (2.26.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /opt/conda/lib/python3.9/site-packages (from tensorboardX->-r requirements.txt (line 5)) (3.19.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 6)) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 9)) (2021.11.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 9)) (1.3.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
      "     |████████████████████████████████| 451 kB 64.5 MB/s            \n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 9)) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers>=4.10.0->-r requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.10.0->-r requirements.txt (line 1)) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.10.0->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (21.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 9)) (5.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 9)) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 9)) (2.8.2)\n",
      "Installing collected packages: responses, tensorboardX, rouge, datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.14.0\n",
      "    Uninstalling datasets-1.14.0:\n",
      "      Successfully uninstalled datasets-1.14.0\n",
      "Successfully installed datasets-2.7.1 responses-0.18.0 rouge-1.0.0 tensorboardX-2.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a2737",
   "metadata": {},
   "source": [
    "# 1단계 작업 정의\n",
    "\n",
    "- 첫 번째 단계는 현재 NLP 작업을 결정하고 데이터가 어떻게 생겼는지, 데이터에서 원하는 것이 무엇인지 생각하는 것입니다! 즉, 이 단계의 본질은 작업의 classses와 를 결정하는 InputExample것입니다. 단순화를 위해 감정 분석을 예로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77fdf55f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.20.1\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "     |████████████████████████████████| 4.4 MB 6.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 65.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (3.4.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "     |████████████████████████████████| 182 kB 81.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (2021.11.10)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (1.21.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.20.1) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.20.1) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.20.1) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.20.1) (2021.10.8)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.19\n",
      "    Uninstalling huggingface-hub-0.0.19:\n",
      "      Successfully uninstalled huggingface-hub-0.0.19\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.11.3\n",
      "    Uninstalling transformers-4.11.3:\n",
      "      Successfully uninstalled transformers-4.11.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 1.14.0 requires huggingface-hub<0.1.0,>=0.0.19, but you have huggingface-hub 0.11.0 which is incompatible.\u001b[0m\n",
      "Successfully installed huggingface-hub-0.11.0 tokenizers-0.12.1 transformers-4.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ee34bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.20.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0306076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b08bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train_df = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/train_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b3beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "\n",
    "train_df.drop(columns = ['Id', 'Category'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951668b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (.) 제거\n",
    "    #sentence = re.sub(r'[#@]+[가-힣A-Za-z#]+', ' ', sentence)\n",
    "    sentence = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+[/ㄱ-ㅎㅏ-ㅣ]', '', sentence) # 여러개 자음과 모음을 삭제한다.\n",
    "    sentence = re.sub(\"[^가-힣a-z0-9-.,!?]\", \" \", sentence) # 지정한 문자 제외 공백으로 전환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
    "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1371665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279992/279992 [00:08<00:00, 31516.96it/s]\n",
      "100%|██████████| 279992/279992 [00:03<00:00, 91038.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 (1)\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "clean_text = []\n",
    "\n",
    "for s in tqdm(train_df['Text']):\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "train_df['Text'] = clean_text\n",
    "\n",
    "# 전체 headlines 데이터에 대한 전처리 \n",
    "clean_headlines = []\n",
    "\n",
    "for s in tqdm(train_df['Summary']):\n",
    "      clean_headlines.append(preprocess_sentence(s))\n",
    "        \n",
    "train_df['Summary'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff39ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "\n",
    "dataset = [ # For simplicity, there's only two examples\n",
    "    # text_a is the input text of the data, some other datasets may have multiple input sentences in one example.\n",
    "    InputExample(\n",
    "        guid = 0,\n",
    "        text_a = train_df['Text'][0],\n",
    "        text_b = train_df['Summary'][0]\n",
    "    ),\n",
    "    InputExample(\n",
    "        guid = 1,\n",
    "        text_a = train_df['Text'][1],\n",
    "        text_b = train_df['Summary'][1]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6ee93",
   "metadata": {},
   "source": [
    "# 2단계. PLM 확보\n",
    "\n",
    "- 작업을 지원하는 PLM을 선택하십시오. 모델마다 속성이 다르므로 OpenPrompt를 사용하여 다양한 PLM의 잠재력을 탐색하는 것이 좋습니다. OpenPrompt는 huggingface의 모델과 호환되며 다음 모델이 테스트되었습니다.\n",
    "\n",
    "- 마스킹된 언어 모델(MLM): BERT, RoBERTa,ALBERT\n",
    "- 자기회귀 언어 모델(LM): GPT,GPT2\n",
    "- 시퀀스 대 시퀀스 모델(Seq2Seq):T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3927d28",
   "metadata": {},
   "source": [
    "### 발생한 오류\n",
    "\n",
    "- ImportError: cannot import name 'OPTConfig' from 'transformers' (/opt/conda/lib/python3.9/site-packages/transformers/__init__.py)\n",
    "- 해결방법 : transformers version == 4.20.1로 수정\n",
    "- link : https://github.com/huggingface/transformers/issues/17790"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d077fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openprompt에서 사용할 수 있는 Model 및 토크나이저\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertModel, BertForMaskedLM, \\\n",
    "                         RobertaConfig, RobertaTokenizer, RobertaModel, RobertaForMaskedLM, \\\n",
    "                         AlbertTokenizer, AlbertConfig, AlbertModel, AlbertForMaskedLM, \\\n",
    "                         T5Config, T5Tokenizer, T5ForConditionalGeneration, \\\n",
    "                         OpenAIGPTTokenizer, OpenAIGPTLMHeadModel, OpenAIGPTConfig, \\\n",
    "                         GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, \\\n",
    "                         ElectraConfig, ElectraForMaskedLM, ElectraTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfbdaee",
   "metadata": {},
   "source": [
    "### 기존에 사용하던 Sk-KoGPT-2의 토크나이저가 적용이 되지 않아 kodialogpt2로 바꿔서 적용해보기로 하였다. 해당 Model은 대화문 data를 학습시킨 Model이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6dd820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a66c16356ac4e51a4088fb79d754a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4c481919b3422dafde21704ba21c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdc737875a74c66a36d0d9f352398c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcf36ebbc114e0b822515a7ff40e307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de5747d75fa427799d8d36ebc720035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c890165ed147509d9919e07265fdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from openprompt.plms import load_plm\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"gpt2\", \"taeminlee/kodialogpt2-base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c36ac4",
   "metadata": {},
   "source": [
    "# 3단계. 템플릿 정의\n",
    "\n",
    "- A Template는 원본 입력 텍스트의 수정자이며 프롬프트 학습에서 가장 중요한 모듈 중 하나이기도 합니다. 템플릿을 정의하는 고급 자습서는 템플릿 을 작성하는 방법에 있습니다.\n",
    "\n",
    "- 다음은 the가 in <text_a>으로 대체되고 the 가 레이블 단어를 예측하는 데 사용되는 예입니다.text_aInputExample<mask>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12ab8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import PtuningTemplate\n",
    "promptTemplate = PtuningTemplate(\n",
    "    model = plm,\n",
    "    tokenizer = tokenizer,\n",
    "    prompt_encoder_type = 'lstm',\n",
    "    text = '{\"placeholder\":\"text_a\"} summarization {\"mask\":\"text_b\"}',\n",
    "    placeholder_mapping = {'<text_a>': 'text_a', '<text_b>': 'text_b'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d9c538",
   "metadata": {},
   "source": [
    "# 4단계. Verbalizer 정의\n",
    "\n",
    "- A Verbalizer는 프롬프트 학습에서 또 다른 중요하지만(생성에서와 같이 필요하지는 않음) 원래 레이블(우리는 classes레이블 단어 집합으로 정의했습니다. 기억하십니까?)을 투사합니다. Verbalizer 를 정의하는 고급 자습서 는 Verbalizer를 작성하는 방법에 있습니다.\n",
    "\n",
    "- project the negative class to the word bad\n",
    "\n",
    "- project the positive class to the words good, wonderful, great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1356e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import GenerationVerbalizer\n",
    "promptVerbalizer = GenerationVerbalizer(\n",
    "    tokenizer = tokenizer,\n",
    "    #classes = classes,\n",
    "    is_rule = False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa27c3",
   "metadata": {},
   "source": [
    "# 5단계. PromptModel 구성\n",
    "\n",
    "- 작업이 주어지면 이제 우리는 a PLM, a Template및 a Verbalizer를 가지고 있습니다. 우리는 그것들을 a로 결합합니다 PromptModel.\n",
    "\n",
    "- 이 예제는 순진하게 세 개의 모듈을 결합하지만 실제로 이들 사이에서 몇 가지 복잡한 상호 작용을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2e72c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt import PromptModel\n",
    "promptModel = PromptModel(\n",
    "    template = promptTemplate,\n",
    "    plm = plm,\n",
    "    #verbalizer = promptVerbalizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bd8f4a",
   "metadata": {},
   "source": [
    "# 6단계. DataLoader 정의\n",
    "\n",
    "- A 는 기본적으로 a 및 a PromptDataLoader를 포함하는 pytorch Dataloader의 프롬프트 버전입니다 .TokenizerTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "551c9a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 2it [00:00, 93.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader\n",
    "data_loader = PromptDataLoader(\n",
    "    dataset = dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    template = promptTemplate,\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a2520",
   "metadata": {},
   "source": [
    "# 7단계. 학습 및 추론\n",
    "\n",
    "- 완료! Pytorch에서 다른 프로세스와 동일하게 학습 및 추론을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd15f0d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not CausalLMOutputWithCrossAttentions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141/4009281046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpromptModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# predictions would be 1, 0 for classes 'positive', 'negative'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not CausalLMOutputWithCrossAttentions"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# making zero-shot inference using pretrained MLM with prompt\n",
    "promptModel.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        logits = promptModel(batch)\n",
    "        preds = torch.argmax(logits, dim = -1)\n",
    "        print(tokenizer.decode(batch['input_ids'][0], skip_special_tokens=True))\n",
    "# predictions would be 1, 0 for classes 'positive', 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26d08c78",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not CausalLMOutputWithCrossAttentions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141/167971379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpromptModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not CausalLMOutputWithCrossAttentions"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# making zero-shot inference using pretrained MLM with prompt\n",
    "promptModel.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        logits = promptModel(batch)\n",
    "        preds = torch.argmax(logits, dim = -1)\n",
    "        print(classes[preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e98c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
