{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb84b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/skgpt-2\n"
     ]
    }
   ],
   "source": [
    "#%cd /aiffel/aiffel/aiffelthon/skgpt-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c789ec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoGPT2-summarization'...\n",
      "remote: Enumerating objects: 65, done.\u001b[K\n",
      "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
      "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
      "remote: Total 65 (delta 33), reused 46 (delta 18), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (65/65), 16.92 KiB | 559.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/seujung/KoGPT2-summarization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "391a96d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/skgpt-2/KoGPT2-summarization\n"
     ]
    }
   ],
   "source": [
    "%cd /aiffel/aiffel/aiffelthon/skgpt-2/KoGPT2-summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c28213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "dataset.py\t       __pycache__\t     run_train.sh\tutils.py\n",
      "generate_sample.ipynb  README.md\t     soft_embedding.py\n",
      "KoBART-summarization   requirements.txt      train_ptuning.py\n",
      "LICENSE\t\t       run_ptuning_train.sh  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458cdc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/skgpt-2-lora\n"
     ]
    }
   ],
   "source": [
    "# %cd /aiffel/aiffel/aiffelthon/skgpt-2-lora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ed5e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoGPT2-LoRA-summarization'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 11 (delta 1), reused 6 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (11/11), 8.99 KiB | 3.00 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/seujung/KoGPT2-LoRA-summarization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a25310",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.11.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers==4.5.1\n",
    "!pip install transformers\n",
    "#!pip install pytorch-lightning==1.1.0\n",
    "#!pip install streamlit==0.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ce2b39a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=068861fb8430dcc5f142665148c04bd3a1b8da49ed7803337503c4ff375a115c\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc9ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1+cu111\n",
      "4.11.3\n",
      "1.1.0\n",
      "4.11.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pytorch_lightning\n",
    "import streamlit\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(pytorch_lightning.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39871783",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp39-cp39-linux_x86_64.whl (1982.2 MB)\n",
      "     |████████████████████████████████| 1982.2 MB 1.3 kB/s              \n",
      "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp39-cp39-linux_x86_64.whl (17.6 MB)\n",
      "     |████████████████████████████████| 17.6 MB 44 kB/s              \n",
      "\u001b[?25hCollecting torchaudio==0.8.1\n",
      "  Downloading torchaudio-0.8.1-cp39-cp39-manylinux1_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 6.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch==1.8.1+cu111) (4.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torch==1.8.1+cu111) (1.21.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.9/site-packages (from torchvision==0.9.1+cu111) (8.3.2)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1+cu111\n",
      "    Uninstalling torch-1.9.1+cu111:\n",
      "      Successfully uninstalled torch-1.9.1+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.10.1+cu111\n",
      "    Uninstalling torchvision-0.10.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.10.1+cu111\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.9.1\n",
      "    Uninstalling torchaudio-0.9.1:\n",
      "      Successfully uninstalled torchaudio-0.9.1\n",
      "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263737a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pytorch_lightning as pl\n",
    "import re\n",
    "import torch\n",
    "#from pytorch_lightning import loggers as pl_loggers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "from transformers import GPT2TokenizerFast\n",
    "from transformers import AutoTokenizer \n",
    "from dataset import KoGPTSummaryDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d85736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch cash 초기화\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3dcd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "279992 35004\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train_df  = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/train_total.csv')\n",
    "val_df = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/val_total.csv')\n",
    "\n",
    "print(type(train_df), type(val_df))\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb1292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop : Id, Category\n",
    "\n",
    "train_df.drop(columns = ['Id','Category'], axis = 1, inplace = True)\n",
    "val_df.drop(columns = ['Id','Category'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cce632",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173173</th>\n",
       "      <td>['근데 좋겠따 중간에 자러갔다올수도있고 우리는 그런 공간이없어', '졸리댱ㅠㅠ 나...</td>\n",
       "      <td>이 회사는 중간에 자러 갔다 올 수 있는 공간이 없지만 매일 커피를 마시러 나갈 수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162108</th>\n",
       "      <td>['수욜은 오후7시에 퇴근해야해', '왜쥬', '도넛간담회2차', '한번 더 하는겨...</td>\n",
       "      <td>수요일에는 2차 도넛 간담회가 있어서 오후 7시에 퇴근해야 한다고 한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242190</th>\n",
       "      <td>['지하촐 사람 개마눔ㅍ ㅠ 잠실쓰.. 롯데월드 솔플각..?', '갑자기?ㅋㅋ', ...</td>\n",
       "      <td>지하철에 사람이 많고 버스도 오지 않아 삼십분째 기다리고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195865</th>\n",
       "      <td>['#@이름#! 파스타 접속해 너 자고있다고! 어쩔거야', '퇴출시켜', '뭐? 저...</td>\n",
       "      <td>파스타 게임에 접속하라고 하고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96799</th>\n",
       "      <td>['#@이름# 내일 출근해야대는데 언제 잘거야', '마죠ㅠㅠ 지금이순간!', '지금...</td>\n",
       "      <td>내일 출근을 해야 해서 지금 잠을 잘 것이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179179</th>\n",
       "      <td>['아씨 열두시에 토스 만보기 들어갈라했는데 시계 이제 봄... 45분까지 생각하고...</td>\n",
       "      <td>12시에 토스 만보기에 들어가지 못했다고 말했다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178688</th>\n",
       "      <td>['혼자 맥 사셨는데 저 맥은 어떻게 되는거지 나 주나 (잿밥관심)', 'ㅋㅋㅋㅋ맥...</td>\n",
       "      <td>혼자 맥 사셨는데 저 맥은 어떻게 되냐고 이야기하고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227554</th>\n",
       "      <td>['소파나 침대 옆으로 이동식 간이테이블이 잇었으면 좋겠어', '사이드 테이블을 말...</td>\n",
       "      <td>소파나 침대 옆에 간이 테이블이 있으면 편할 것 같다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217033</th>\n",
       "      <td>['아진짜 너무더워 더워죽겠네', '나는 이제 시원해졌어...후', '이따 위원님 ...</td>\n",
       "      <td>날씨가 너무 더워서 위원님이 가시면 에어컨 냉방을 다시 켤 것이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70104</th>\n",
       "      <td>['슬슬저녁먹을시간이네~~~', '이모가게와서감자먹었엉ㅋㅋㅋ', '감자~~~? 찐감...</td>\n",
       "      <td>이모 가게에 와서 찐 감자를 먹었다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "173173  ['근데 좋겠따 중간에 자러갔다올수도있고 우리는 그런 공간이없어', '졸리댱ㅠㅠ 나...   \n",
       "162108  ['수욜은 오후7시에 퇴근해야해', '왜쥬', '도넛간담회2차', '한번 더 하는겨...   \n",
       "242190  ['지하촐 사람 개마눔ㅍ ㅠ 잠실쓰.. 롯데월드 솔플각..?', '갑자기?ㅋㅋ', ...   \n",
       "195865  ['#@이름#! 파스타 접속해 너 자고있다고! 어쩔거야', '퇴출시켜', '뭐? 저...   \n",
       "96799   ['#@이름# 내일 출근해야대는데 언제 잘거야', '마죠ㅠㅠ 지금이순간!', '지금...   \n",
       "179179  ['아씨 열두시에 토스 만보기 들어갈라했는데 시계 이제 봄... 45분까지 생각하고...   \n",
       "178688  ['혼자 맥 사셨는데 저 맥은 어떻게 되는거지 나 주나 (잿밥관심)', 'ㅋㅋㅋㅋ맥...   \n",
       "227554  ['소파나 침대 옆으로 이동식 간이테이블이 잇었으면 좋겠어', '사이드 테이블을 말...   \n",
       "217033  ['아진짜 너무더워 더워죽겠네', '나는 이제 시원해졌어...후', '이따 위원님 ...   \n",
       "70104   ['슬슬저녁먹을시간이네~~~', '이모가게와서감자먹었엉ㅋㅋㅋ', '감자~~~? 찐감...   \n",
       "\n",
       "                                                  Summary  \n",
       "173173  이 회사는 중간에 자러 갔다 올 수 있는 공간이 없지만 매일 커피를 마시러 나갈 수...  \n",
       "162108           수요일에는 2차 도넛 간담회가 있어서 오후 7시에 퇴근해야 한다고 한다.  \n",
       "242190                지하철에 사람이 많고 버스도 오지 않아 삼십분째 기다리고 있다.  \n",
       "195865                               파스타 게임에 접속하라고 하고 있다.  \n",
       "96799                           내일 출근을 해야 해서 지금 잠을 잘 것이다.  \n",
       "179179                        12시에 토스 만보기에 들어가지 못했다고 말했다.  \n",
       "178688                   혼자 맥 사셨는데 저 맥은 어떻게 되냐고 이야기하고 있다.  \n",
       "227554                     소파나 침대 옆에 간이 테이블이 있으면 편할 것 같다.  \n",
       "217033              날씨가 너무 더워서 위원님이 가시면 에어컨 냉방을 다시 켤 것이다.  \n",
       "70104                                이모 가게에 와서 찐 감자를 먹었다.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 탐색 - train\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93770204",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26797</th>\n",
       "      <td>88a5ef59-b550-580e-bc10-b95636412bcc</td>\n",
       "      <td>['내 쟈기 뭐야 그걸', '그니까', '번역한 것도 웃겨', '영어로 는 그럴듯한...</td>\n",
       "      <td>영어로는 그럴듯한데 번역한 것이 웃기다.</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33942</th>\n",
       "      <td>9829e1d4-7d5e-5544-bf49-ed8f7f0232d7</td>\n",
       "      <td>['진짜 나 어재 머앙먹고 음식 만들고잇엇는데ㅔ머멋냐구 햇을때 억울!!', 'ㅎㅎㅎ...</td>\n",
       "      <td>어제 뭐 안 먹고 음식 만들고 있는데 뭐 먹냐고 해서 억울했다고 하니 달그락 소리 ...</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>d84cf094-2dc6-5e3c-a7d1-76e776476be9</td>\n",
       "      <td>['쯧 도서관이 개꿀이여 쉬다가 책만 찾으면돼 #@이모티콘#', '오늘 드뎌쉰다 ㅋ...</td>\n",
       "      <td>도서관에서 일하면 쉬다가 책만 찾으면 된다고 하며 내년 학기 중에 도서관 근로를 하...</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23917</th>\n",
       "      <td>97c45880-775d-53f3-8ddf-b81e2da4b875</td>\n",
       "      <td>['냄새나는거', '복도까지 다 들림', '먹지말라도 해놓고', '그니께...안된다...</td>\n",
       "      <td>아줌마들이 음식을 먹어서 냄새와 소리가 난다.</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>99b1d7fe-82e9-5812-950a-ac32ea7a2266</td>\n",
       "      <td>['아니 나 고민이야', '뭐 말만해', '인수인계 받는 애가 너무 느려서 일주일만...</td>\n",
       "      <td>인수인계받은 애가 너무 느려서 일주일만 더 일해달라고 하는데 더 일하기 싫지만 걱정...</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31082</th>\n",
       "      <td>7f2dcb99-9f55-5c30-8464-fb623c4df4c6</td>\n",
       "      <td>['누나누나 초콜릿 싫어해요?', '아뉘 ㅎㅎㅎ 나 초콜릿 좋아하는뎅 아 너가준거 ...</td>\n",
       "      <td>초콜릿 좋아하는데 살 뺀다고 안 먹었다고 하자 하리보는 잘 먹지 않았냐고 하니 듣고...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>9e6586be-9505-5838-a49a-20da9bf8ff92</td>\n",
       "      <td>['일단 그럼 투어를 해보는게 나을지도 모르겠다 어렵다 ㅋㅋ큐ㅠ', '우리가 렌탈하...</td>\n",
       "      <td>렌털을 하는 게 낫다고 생각하며 사진이 중요하긴 하다고 생각한다.</td>\n",
       "      <td>주거와 생활</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24152</th>\n",
       "      <td>cb6d45dd-1b4f-5b84-b124-df2b45f68a16</td>\n",
       "      <td>['요즘은 욕이지', 'ㅋㅋㅋㅋㅋㅋ돈을 누가 정하냐', 'ㅋㅋㅋ요즘 추세가 다 오여...</td>\n",
       "      <td>결혼식에 다녀오기 위해서 서울에서 대전까지 다녀왔다.</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>5f999500-db26-54d9-850f-2f417772ed2e</td>\n",
       "      <td>['아니 내일 뭐입늘거에여?', '움,, 춥겠디?̊̈ 셔츠입울래', '아 춥겠다 진...</td>\n",
       "      <td>추운 날씨를 고려해 내일 입을 옷을 결정하고 있다.</td>\n",
       "      <td>주거와 생활</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20357</th>\n",
       "      <td>0521646b-e9ce-5491-879a-98dfdd416ed3</td>\n",
       "      <td>['나오늘뿌염하러미용실갔는디 내옆머리잘ㅇ라놨어 아진짜 나울뻔 앞머리진짜상태대박이여'...</td>\n",
       "      <td>뿌리염색(뿌염)하러 미용실에 갔다가 앞머리가 생각보다 많이 잘렸다.</td>\n",
       "      <td>미용과 건강</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Id  \\\n",
       "26797  88a5ef59-b550-580e-bc10-b95636412bcc   \n",
       "33942  9829e1d4-7d5e-5544-bf49-ed8f7f0232d7   \n",
       "594    d84cf094-2dc6-5e3c-a7d1-76e776476be9   \n",
       "23917  97c45880-775d-53f3-8ddf-b81e2da4b875   \n",
       "444    99b1d7fe-82e9-5812-950a-ac32ea7a2266   \n",
       "31082  7f2dcb99-9f55-5c30-8464-fb623c4df4c6   \n",
       "3104   9e6586be-9505-5838-a49a-20da9bf8ff92   \n",
       "24152  cb6d45dd-1b4f-5b84-b124-df2b45f68a16   \n",
       "3820   5f999500-db26-54d9-850f-2f417772ed2e   \n",
       "20357  0521646b-e9ce-5491-879a-98dfdd416ed3   \n",
       "\n",
       "                                                    Text  \\\n",
       "26797  ['내 쟈기 뭐야 그걸', '그니까', '번역한 것도 웃겨', '영어로 는 그럴듯한...   \n",
       "33942  ['진짜 나 어재 머앙먹고 음식 만들고잇엇는데ㅔ머멋냐구 햇을때 억울!!', 'ㅎㅎㅎ...   \n",
       "594    ['쯧 도서관이 개꿀이여 쉬다가 책만 찾으면돼 #@이모티콘#', '오늘 드뎌쉰다 ㅋ...   \n",
       "23917  ['냄새나는거', '복도까지 다 들림', '먹지말라도 해놓고', '그니께...안된다...   \n",
       "444    ['아니 나 고민이야', '뭐 말만해', '인수인계 받는 애가 너무 느려서 일주일만...   \n",
       "31082  ['누나누나 초콜릿 싫어해요?', '아뉘 ㅎㅎㅎ 나 초콜릿 좋아하는뎅 아 너가준거 ...   \n",
       "3104   ['일단 그럼 투어를 해보는게 나을지도 모르겠다 어렵다 ㅋㅋ큐ㅠ', '우리가 렌탈하...   \n",
       "24152  ['요즘은 욕이지', 'ㅋㅋㅋㅋㅋㅋ돈을 누가 정하냐', 'ㅋㅋㅋ요즘 추세가 다 오여...   \n",
       "3820   ['아니 내일 뭐입늘거에여?', '움,, 춥겠디?̊̈ 셔츠입울래', '아 춥겠다 진...   \n",
       "20357  ['나오늘뿌염하러미용실갔는디 내옆머리잘ㅇ라놨어 아진짜 나울뻔 앞머리진짜상태대박이여'...   \n",
       "\n",
       "                                                 Summary Category  \n",
       "26797                             영어로는 그럴듯한데 번역한 것이 웃기다.  개인 및 관계  \n",
       "33942  어제 뭐 안 먹고 음식 만들고 있는데 뭐 먹냐고 해서 억울했다고 하니 달그락 소리 ...      식음료  \n",
       "594    도서관에서 일하면 쉬다가 책만 찾으면 된다고 하며 내년 학기 중에 도서관 근로를 하...    일과 직업  \n",
       "23917                          아줌마들이 음식을 먹어서 냄새와 소리가 난다.  개인 및 관계  \n",
       "444    인수인계받은 애가 너무 느려서 일주일만 더 일해달라고 하는데 더 일하기 싫지만 걱정...    일과 직업  \n",
       "31082  초콜릿 좋아하는데 살 뺀다고 안 먹었다고 하자 하리보는 잘 먹지 않았냐고 하니 듣고...  개인 및 관계  \n",
       "3104                렌털을 하는 게 낫다고 생각하며 사진이 중요하긴 하다고 생각한다.   주거와 생활  \n",
       "24152                      결혼식에 다녀오기 위해서 서울에서 대전까지 다녀왔다.  개인 및 관계  \n",
       "3820                        추운 날씨를 고려해 내일 입을 옷을 결정하고 있다.   주거와 생활  \n",
       "20357              뿌리염색(뿌염)하러 미용실에 갔다가 앞머리가 생각보다 많이 잘렸다.   미용과 건강  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 탐색 - val\n",
    "\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "368e776e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260509</th>\n",
       "      <td>73a4bfa8-1004-57cb-bd22-fee36f28e699</td>\n",
       "      <td>['#@이모티콘# 언니 이번주에 올림픽공원 갈래요?? #@이름# 미용해서 더 이뻐요...</td>\n",
       "      <td>이번주 목요일에 점심을 먹고 올림픽공원을 가기로 했다.</td>\n",
       "      <td>행사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10755</th>\n",
       "      <td>c501d27f-0b8c-5e70-bfff-84507ba4340d</td>\n",
       "      <td>['오빠 나오늘 백화점가서 모던하우스 구경햇거든 잠시 거기 너무 귀여운게 잇는거야ㅜ...</td>\n",
       "      <td>오늘 백화점에 가서 모던 하우스를 잠깐 구경했는데 손에 안 묻는 크레파스와 공룡 인...</td>\n",
       "      <td>상거래(쇼핑)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34008</th>\n",
       "      <td>ea47a37c-d9c0-57b7-a256-c17cd0904da7</td>\n",
       "      <td>['어플이야? 쌩인줄  암튼 괜차나!!!!!', '하 루비레이져 하고 그 우울한 마...</td>\n",
       "      <td>루비레이저 시술을 하고 우울한 마음이지만 눈 화장하니까 괜찮아 보여서 다음 주에 놀...</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273074</th>\n",
       "      <td>8d9c94cf-51f3-5470-bb80-a34b37d8033d</td>\n",
       "      <td>['누구는 시청광장이라 하구 광화문이겠지', '광화문 아녀,,??', '#@시스템#...</td>\n",
       "      <td>단체 시위가 시청광장에서 열리는지 광화문에서 열리는지에 대해 말한다.</td>\n",
       "      <td>행사</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249984</th>\n",
       "      <td>50a813de-06db-5e4e-bf57-4ee8de18a55b</td>\n",
       "      <td>['마전옴?', '#@시스템#사진# 마전행 놓치고 대전복합으로 왔다ㅎㅎ 나 오늘 수...</td>\n",
       "      <td>지하철을 30분을 기다렸는데 안 와서 포기하고 지금은 대전복합 터미널에 있다.</td>\n",
       "      <td>주거와 생활</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57049</th>\n",
       "      <td>48a94050-5061-5747-a85e-a0b7dc53dafe</td>\n",
       "      <td>['아 아 나 전현무지', '잊지마', '순간 잊었어... 반성할게 #@이모티콘#'...</td>\n",
       "      <td>전현무와 김호중을 닮았다고 하니 김호중보다 전현무가 낫다고 한다.</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156200</th>\n",
       "      <td>31c3ab8e-bdfc-5546-ae10-46f88b843e94</td>\n",
       "      <td>['#@시스템#사진#', '힛 살좀빠졌니?', '안재봣는딩 #@이모티콘#', '얼굴...</td>\n",
       "      <td>상대방이 보낸 사진을 보고 얼굴이 갸름해졌다며 살이 빠졌냐고 물어보고 있다.</td>\n",
       "      <td>미용과 건강</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244695</th>\n",
       "      <td>1b998847-99da-5c31-b4c1-279871ae95df</td>\n",
       "      <td>['11월 대면 바로 입겠쥐 ?패딩', '추운날 바로입자', 'ㅠㅠ', '왜냐면 오...</td>\n",
       "      <td>11월이 되면 패딩을 입을까 물으니 추운 날 바로 입자고 한다.</td>\n",
       "      <td>주거와 생활</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169735</th>\n",
       "      <td>3cb1eb1e-1b34-56ac-a5b4-f2beab05975b</td>\n",
       "      <td>['#@이름# 오픈하고 심심하면 이것 좀 추가해조(~˘▽˘)~♡', '아쥔짜 성가시...</td>\n",
       "      <td>오픈하고 시간이 남으면 노래를 추가해달라고 부탁에 이미 추가된 곡이 많다고 말하고 있다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73607</th>\n",
       "      <td>1e77a51e-b2cf-5209-9442-e3a47ffa2ec6</td>\n",
       "      <td>['네^^ 밥이 다 지어지기 4분 전 방문햇다고 저나가 오더군요^^ 울집에서 얘기해...</td>\n",
       "      <td>밥을 하는 동안에 에스케이(SK)를 설치를 하고 있다.</td>\n",
       "      <td>개인 및 관계</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Id  \\\n",
       "260509  73a4bfa8-1004-57cb-bd22-fee36f28e699   \n",
       "10755   c501d27f-0b8c-5e70-bfff-84507ba4340d   \n",
       "34008   ea47a37c-d9c0-57b7-a256-c17cd0904da7   \n",
       "273074  8d9c94cf-51f3-5470-bb80-a34b37d8033d   \n",
       "249984  50a813de-06db-5e4e-bf57-4ee8de18a55b   \n",
       "57049   48a94050-5061-5747-a85e-a0b7dc53dafe   \n",
       "156200  31c3ab8e-bdfc-5546-ae10-46f88b843e94   \n",
       "244695  1b998847-99da-5c31-b4c1-279871ae95df   \n",
       "169735  3cb1eb1e-1b34-56ac-a5b4-f2beab05975b   \n",
       "73607   1e77a51e-b2cf-5209-9442-e3a47ffa2ec6   \n",
       "\n",
       "                                                     Text  \\\n",
       "260509  ['#@이모티콘# 언니 이번주에 올림픽공원 갈래요?? #@이름# 미용해서 더 이뻐요...   \n",
       "10755   ['오빠 나오늘 백화점가서 모던하우스 구경햇거든 잠시 거기 너무 귀여운게 잇는거야ㅜ...   \n",
       "34008   ['어플이야? 쌩인줄  암튼 괜차나!!!!!', '하 루비레이져 하고 그 우울한 마...   \n",
       "273074  ['누구는 시청광장이라 하구 광화문이겠지', '광화문 아녀,,??', '#@시스템#...   \n",
       "249984  ['마전옴?', '#@시스템#사진# 마전행 놓치고 대전복합으로 왔다ㅎㅎ 나 오늘 수...   \n",
       "57049   ['아 아 나 전현무지', '잊지마', '순간 잊었어... 반성할게 #@이모티콘#'...   \n",
       "156200  ['#@시스템#사진#', '힛 살좀빠졌니?', '안재봣는딩 #@이모티콘#', '얼굴...   \n",
       "244695  ['11월 대면 바로 입겠쥐 ?패딩', '추운날 바로입자', 'ㅠㅠ', '왜냐면 오...   \n",
       "169735  ['#@이름# 오픈하고 심심하면 이것 좀 추가해조(~˘▽˘)~♡', '아쥔짜 성가시...   \n",
       "73607   ['네^^ 밥이 다 지어지기 4분 전 방문햇다고 저나가 오더군요^^ 울집에서 얘기해...   \n",
       "\n",
       "                                                  Summary Category  \n",
       "260509                     이번주 목요일에 점심을 먹고 올림픽공원을 가기로 했다.       행사  \n",
       "10755   오늘 백화점에 가서 모던 하우스를 잠깐 구경했는데 손에 안 묻는 크레파스와 공룡 인...  상거래(쇼핑)  \n",
       "34008   루비레이저 시술을 하고 우울한 마음이지만 눈 화장하니까 괜찮아 보여서 다음 주에 놀...  개인 및 관계  \n",
       "273074             단체 시위가 시청광장에서 열리는지 광화문에서 열리는지에 대해 말한다.       행사  \n",
       "249984        지하철을 30분을 기다렸는데 안 와서 포기하고 지금은 대전복합 터미널에 있다.   주거와 생활  \n",
       "57049                전현무와 김호중을 닮았다고 하니 김호중보다 전현무가 낫다고 한다.  개인 및 관계  \n",
       "156200         상대방이 보낸 사진을 보고 얼굴이 갸름해졌다며 살이 빠졌냐고 물어보고 있다.   미용과 건강  \n",
       "244695                11월이 되면 패딩을 입을까 물으니 추운 날 바로 입자고 한다.   주거와 생활  \n",
       "169735  오픈하고 시간이 남으면 노래를 추가해달라고 부탁에 이미 추가된 곡이 많다고 말하고 있다.    일과 직업  \n",
       "73607                      밥을 하는 동안에 에스케이(SK)를 설치를 하고 있다.  개인 및 관계  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Text'].str.contains(r'[#@]+[가-힣A-Za-z#]+')].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1dc8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (.) 제거\n",
    "    sentence = re.sub(r'[#@]+[가-힣A-Za-z#]+', ' ', sentence)\n",
    "    sentence = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+[/ㄱ-ㅎㅏ-ㅣ]', '', sentence) # 여러개 자음과 모음을 삭제한다.\n",
    "    sentence = re.sub(\"[^가-힣a-z0-9-.,!?]\", \" \", sentence) # 지정한 문자 제외 공백으로 전환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
    "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d50ef76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아 이거 뭐고'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = '#@시스템#사진# 아 이거 뭐고 ㅋㅋㅋㅋㅋ ㅏㅏㅏㅏㅏ(존웃 ㅅㅂ)'\n",
    "preprocess_sentence(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16569e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279992/279992 [00:10<00:00, 27300.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 (1)\n",
    "from tqdm import tqdm\n",
    "clean_text = []\n",
    "\n",
    "for s in tqdm(train_df['Text']):\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "train_df['Text'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684f2483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279992/279992 [00:03<00:00, 76776.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 headlines 데이터에 대한 전처리 \n",
    "clean_headlines = []\n",
    "\n",
    "for s in tqdm(train_df['Summary']):\n",
    "      clean_headlines.append(preprocess_sentence(s))\n",
    "        \n",
    "train_df['Summary'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ef855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35004/35004 [00:01<00:00, 27534.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 (1)\n",
    "\n",
    "clean_text_val = []\n",
    "\n",
    "for s in tqdm(val_df['Text']):\n",
    "    clean_text_val.append(preprocess_sentence(s))\n",
    "    \n",
    "val_df['Text'] = clean_text_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c84b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35004/35004 [00:00<00:00, 75388.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 headlines 데이터에 대한 전처리 \n",
    "clean_headlines_val = []\n",
    "\n",
    "for s in tqdm(val_df['Summary']):\n",
    "      clean_headlines_val.append(preprocess_sentence(s))\n",
    "        \n",
    "val_df['Summary'] = clean_headlines_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7524b19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그럼 날짜는 가격 큰 변동 없으면 6.28-7.13로 확정할까? , 우리 비행포함 ...</td>\n",
       "      <td>비행기 표 가격에 대해 이야기하며, 특가 이벤트를 기다리고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kf마스크만 5부제 하는거지? , 응. 면마스크는 아무때나 사도될껀? , 면마스크말...</td>\n",
       "      <td>비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 , ...</td>\n",
       "      <td>케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>칫솔사야하는데 쓱으로 살까? , 뭘 칫솔사는것까지 물어보시남 , 아 그 왕칫솔 또 ...</td>\n",
       "      <td>칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계 가자고 했다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잠도안오네 얼릉 고구마츄 먹고싶단 , 그게 그렇게 맛있었어??? 아주 여보 빼이보릿...</td>\n",
       "      <td>잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  그럼 날짜는 가격 큰 변동 없으면 6.28-7.13로 확정할까? , 우리 비행포함 ...   \n",
       "1  kf마스크만 5부제 하는거지? , 응. 면마스크는 아무때나 사도될껀? , 면마스크말...   \n",
       "2  아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 , ...   \n",
       "3  칫솔사야하는데 쓱으로 살까? , 뭘 칫솔사는것까지 물어보시남 , 아 그 왕칫솔 또 ...   \n",
       "4  잠도안오네 얼릉 고구마츄 먹고싶단 , 그게 그렇게 맛있었어??? 아주 여보 빼이보릿...   \n",
       "\n",
       "                                             Summary  \n",
       "0               비행기 표 가격에 대해 이야기하며, 특가 이벤트를 기다리고 있다.  \n",
       "1                비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다.  \n",
       "2  케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...  \n",
       "3               칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계 가자고 했다.  \n",
       "4                  잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다.  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "564b93f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그럼 날짜는 가격 큰 변동 없으면 6.28-7.13로 확정할까? 우리 비행포함 15일이야?? 16일! 아 너 나한테 돈 보내주면 지금 할 수 잇옹 얼마야 최종 결제액이? 잠시만 인당 952 900 합쳐서 1 905 800 근데 나중에 특가 뜰 수도 있으려나..? 좀 더 두고볼까? 뜨기야 뜨겠지 웅웅 보니까 아시아나는 특가 이벤트 꽤 하는 것 같아서 일단 두고보장 그래 구럼 일단 자자'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a7f640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Set으로 전환\n",
    "\n",
    "from datasets import Dataset\n",
    "train_data = Dataset.from_pandas(train_df) \n",
    "val_data = Dataset.from_pandas(val_df.iloc[::2, :])\n",
    "test_data = Dataset.from_pandas(val_df.iloc[1::2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67d0eb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Text', 'Summary'],\n",
      "    num_rows: 279992\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Text', 'Summary'],\n",
      "    num_rows: 17502\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Text', 'Summary'],\n",
      "    num_rows: 17502\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1aa5a2",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da71a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 체크포인트 만들기\n",
    "\n",
    "model_checkpoint = 'skt/kogpt2-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f5e6805",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/vocab.json from cache at None\n",
      "loading file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/merges.txt from cache at None\n",
      "loading file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/tokenizer.json from cache at /aiffel/.cache/huggingface/transformers/fd8418e6675550cbca8ad6c102d717aa89372eb7a632ad3168300c7fed43491c.db074bfdd88bec54455de5ee2400efdbc64d4acf449a44d5f314e79c1eadc611\n",
      "loading file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/skt/kogpt2-base-v2/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/13bb826cf24517d7849a701e02452715a67c5e560142be3d4735442b2a545809.6b384eec6effdd44287f67715cd55bd0dff2cf846d843b932b43ba7b632b8b1e\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72abc463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7c7f680c874744943ddf43537ed914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e50fbbcfb234a899562cfea0dbeaa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "822e6e5e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁안녕',\n",
       " '하',\n",
       " '세',\n",
       " '요.',\n",
       " '▁한국어',\n",
       " '▁G',\n",
       " 'P',\n",
       " 'T',\n",
       " '-2',\n",
       " '▁입',\n",
       " '니다.',\n",
       " '😤',\n",
       " ':)',\n",
       " 'l^o']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905ee693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(batch):\n",
    "    train_encode = tokenizer(\n",
    "      text = batch['Text'],\n",
    "      text_target = batch['Summary'],\n",
    "      truncation = True,\n",
    "      padding = 'max_length',\n",
    "      max_length=128)\n",
    "    train_encode['labels'] = train_encode['input_ids'].copy()\n",
    "    return train_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c64778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4399106f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Found existing installation: transformers 4.11.3\n",
      "Uninstalling transformers-4.11.3:\n",
      "  Successfully uninstalled transformers-4.11.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f3481c1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "     |████████████████████████████████| 5.5 MB 6.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.4.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "     |████████████████████████████████| 182 kB 82.9 MB/s            \n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "     |████████████████████████████████| 7.6 MB 56.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.19\n",
      "    Uninstalling huggingface-hub-0.0.19:\n",
      "      Successfully uninstalled huggingface-hub-0.0.19\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 1.14.0 requires huggingface-hub<0.1.0,>=0.0.19, but you have huggingface-hub 0.11.0 which is incompatible.\u001b[0m\n",
      "Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26cde61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4102bbd41ae45b59ac8b40fcf01ac01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279992 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc7fdd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 279992\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de39b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_val(batch):\n",
    "    val_encode =  tokenizer(\n",
    "      text = batch['Text'],\n",
    "      text_target = batch['Summary'],\n",
    "      truncation = True,\n",
    "      padding = 'max_length',\n",
    "      max_length=32)\n",
    "    val_encode['labels'] = val_encode['input_ids'].copy()\n",
    "    return val_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07d15abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9098c3ed795e4f2eace0d18cd4d83e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17502 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data = val_data.map(transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e901c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "# def beam_search_decoder(data, k):\n",
    "#     sequences = [[list(), 0.0]]\n",
    "#     # walk over each step in sequence\n",
    "#     for row in data:\n",
    "#         all_candidates = list()\n",
    "#         # expand each current candidate\n",
    "#         for i in range(len(sequences)):\n",
    "#             seq, score = sequences[i]\n",
    "#             for j in range(len(row)):\n",
    "#                 candidate = [seq + [j], score - log(row[j])]\n",
    "#                 all_candidates.append(candidate)\n",
    "#         # order all candidates by score\n",
    "#         ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "#         # select k best\n",
    "#         sequences = ordered[:k]\n",
    "#     return sequences\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # np.where(a < 0)\n",
    "\n",
    "    # print(labels_ids.shape, pred_ids.shape, type(labels_ids), type(pred_ids), sep = '\\n\\n')\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    \n",
    "    # beam search\n",
    "    # result = []\n",
    "    # for i in range(pred_ids.shape[0]):\n",
    "    #     result.append(beam_search_decoder(pred_ids[i], 3))\n",
    "\n",
    "    # print(result)\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(np.argmax(pred_ids, axis =2), skip_special_tokens=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer_gpt3.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6df4af79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c3604476f0497b81e2680aae047853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc377887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62a3014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53ddb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a975fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/aiffel/aiffel/aiffelthon/ch3000/\",\n",
    "    #num_train_epochs=1,  # demo\n",
    "    max_steps = 3000,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=8,  # demo\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=3e-05,\n",
    "    save_steps= 1000,\n",
    "    eval_steps= 1000,\n",
    "    warmup_steps=1000,\n",
    "    #weight_decay=0.1,\n",
    "    #label_smoothing_factor=0.1,\n",
    "    #predict_with_generate=True,\n",
    "    #logging_dir=\"/aiffel/aiffel/aiffelthon/logs\",\n",
    "    #logging_steps=8000,\n",
    "    save_total_limit=3,\n",
    "    fp16 = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7250e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                 # 학습시킬 model\n",
    "    args=training_args,          # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset=train_data,    # training dataset\n",
    "    eval_dataset=val_data,       # evaluation dataset\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ff1334",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: Text, Summary. If Text, Summary are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 279992\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3000\n",
      "  Number of trainable parameters = 125164032\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/trainer.py:1794: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.976100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.078100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/aiffelthon/ch3000/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/aiffelthon/ch3000/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffelthon/ch3000/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffelthon/ch3000/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/aiffelthon/ch3000/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffelthon/ch3000/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=1.4121619669596355, metrics={'train_runtime': 515.7014, 'train_samples_per_second': 46.539, 'train_steps_per_second': 5.817, 'total_flos': 1567752192000000.0, 'train_loss': 1.4121619669596355, 'epoch': 0.09})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a74e9cd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting pytorch-lightning==1.1.0\n",
      "  Downloading pytorch_lightning-1.1.0-py3-none-any.whl (665 kB)\n",
      "     |████████████████████████████████| 665 kB 7.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (1.21.4)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (2.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (6.0)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (1.9.1+cu111)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (0.18.2)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (2021.11.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.19.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.12.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (59.4.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.3->pytorch-lightning==1.1.0) (4.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.1.1)\n",
      "Installing collected packages: pytorch-lightning\n",
      "Successfully installed pytorch-lightning-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting streamlit==0.72.0\n",
      "  Downloading streamlit-0.72.0-py2.py3-none-any.whl (7.4 MB)\n",
      "     |████████████████████████████████| 7.4 MB 5.9 MB/s            \n",
      "\u001b[?25hCollecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (3.19.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (2.26.0)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (1.3.3)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (1.21.4)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (8.0.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (8.3.2)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 10.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (6.1)\n",
      "Requirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (4.2.4)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "     |████████████████████████████████| 812 kB 70.0 MB/s            \n",
      "\u001b[?25hCollecting gitpython\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "     |████████████████████████████████| 182 kB 78.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (21.3)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: validators in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (0.18.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting base58\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (2.8.2)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "     |████████████████████████████████| 4.7 MB 65.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==0.72.0) (3.0.3)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 7.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==0.72.0) (0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==0.72.0) (4.2.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.21.0->streamlit==0.72.0) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->streamlit==0.72.0) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "     |████████████████████████████████| 63 kB 3.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->streamlit==0.72.0) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (1.26.7)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from validators->streamlit==0.72.0) (4.4.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->altair>=3.2.0->streamlit==0.72.0) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.72.0) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.72.0) (21.2.0)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.6-py2.py3-none-any.whl (338 kB)\n",
      "     |████████████████████████████████| 338 kB 66.7 MB/s            \n",
      "\u001b[?25hInstalling collected packages: tzdata, smmap, toolz, pytz-deprecation-shim, gitdb, watchdog, tzlocal, toml, pydeck, gitpython, blinker, base58, astor, altair, streamlit\n",
      "Successfully installed altair-4.2.0 astor-0.8.1 base58-2.1.1 blinker-1.5 gitdb-4.0.9 gitpython-3.1.29 pydeck-0.8.0 pytz-deprecation-shim-0.1.0.post0 smmap-5.0.0 streamlit-0.72.0 toml-0.10.2 toolz-0.12.0 tzdata-2022.6 tzlocal-4.2 watchdog-2.1.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-lightning==1.1.0\n",
    "! pip install streamlit==0.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a3cc37",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/497336425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_ptuning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKoGPTConditionalGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_next_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/aiffel/aiffelthon/skgpt-2/KoGPT2-summarization/train_ptuning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloggers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl_loggers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from train_ptuning import KoGPTConditionalGeneration\n",
    "from utils import generate_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08472042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at None\n",
      "loading file merges.txt from cache at None\n",
      "loading file tokenizer.json from cache at /aiffel/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hparams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/3596764223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKoGPTConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hparams' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = KoGPTConditionalGeneration.load_from_checkpoint('~/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/', hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "232116b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at None\n",
      "loading file merges.txt from cache at None\n",
      "loading file tokenizer.json from cache at /aiffel/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--skt--kogpt2-base-v2/snapshots/d0c0df48bf2b2c9350dd855021a5b216f560c0c7/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aiffel/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/3699130236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKoGPTConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# map data correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1031\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/aiffel/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = KoGPTConditionalGeneration.load_from_checkpoint('~/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/', hparams=hparams)\n",
    "batch_size = 16\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=32, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"Text\"])\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54c875b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from train_ptuning import KoGPTConditionalGeneration\n",
    "from utils import generate_next_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdc1ff09",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"skt/kogpt2-base-v2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
      "  \"bos_token_id\": 0,\n",
      "  \"created_date\": \"2021-04-28\",\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"license\": \"CC-BY-NC-SA 4.0\",\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51200\n",
      "}\n",
      "\n",
      "loading weights file /aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at /aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "너는 잘가라... 안다고<pad><unk>다. 한다. 있다.한다.하고라고 이야기고<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('/aiffel/aiffel/aiffelthon/ch3000/checkpoint-3000/')\n",
    "text = '너는 잘가라...'\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "gen_ids = model.generate(input_ids,\n",
    "                          max_length=128,\n",
    "                          repetition_penalty=2.0,\n",
    "                          pad_token_id=tokenizer.pad_token_id,\n",
    "                          eos_token_id=tokenizer.eos_token_id,\n",
    "                          bos_token_id=tokenizer.bos_token_id,\n",
    "                          use_cache=True)\n",
    "generated = tokenizer.decode(gen_ids[0])\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcf5db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'너는 잘가라....회사.... 선택 잘해.. , 알겠어 많이 힘들구나... 나도 이제 이력서쓰고 영어도 해야해.. , 우리 똥갱애지.... 화이팅.... 첫 회사 잘들어가야한다! , 좋은 시절 다 지났다..'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['Text'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
