{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1732d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecab 설치\n",
    "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019f38fc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting pytorch-lightning==1.1.0\n",
      "  Downloading pytorch_lightning-1.1.0-py3-none-any.whl (665 kB)\n",
      "     |████████████████████████████████| 665 kB 6.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (4.62.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (2.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (6.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (1.21.4)\n",
      "Requirement already satisfied: fsspec>=0.8.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning==1.1.0) (2021.11.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.8.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.3.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (59.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.0.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.42.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.3->pytorch-lightning==1.1.0) (4.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (2.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.1.0) (3.1.1)\n",
      "Installing collected packages: pytorch-lightning\n",
      "Successfully installed pytorch-lightning-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting streamlit==0.72.0\n",
      "  Downloading streamlit-0.72.0-py2.py3-none-any.whl (7.4 MB)\n",
      "     |████████████████████████████████| 7.4 MB 6.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (6.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (8.0.3)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (2.8.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (21.3)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "     |████████████████████████████████| 812 kB 60.3 MB/s            \n",
      "\u001b[?25hCollecting blinker\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (2.26.0)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 11.7 MB/s            \n",
      "\u001b[?25hCollecting tzlocal\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: validators in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (0.18.2)\n",
      "Collecting gitpython\n",
      "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
      "     |████████████████████████████████| 182 kB 82.7 MB/s            \n",
      "\u001b[?25hCollecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (8.3.2)\n",
      "Requirement already satisfied: cachetools>=4.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (4.2.4)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (6.0.1)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |██████▋                         | 972 kB 73.4 MB/s eta 0:00:01\r",
      "     |██████▊                         | 983 kB 73.4 MB/s eta 0:00:01\r",
      "     |██████▊                         | 993 kB 73.4 MB/s eta 0:00:01\r",
      "     |██████▉                         | 1.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████                         | 1.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████                         | 1.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████                         | 1.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████                         | 1.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▏                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▎                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▎                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▍                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▌                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▌                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▋                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▋                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▊                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▉                        | 1.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████▉                        | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████                        | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████                        | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████                        | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▏                       | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▏                       | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▎                       | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▍                       | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▍                       | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▌                       | 1.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▋                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▋                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▊                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▉                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████▉                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████                       | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▏                      | 1.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▏                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▎                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▍                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▍                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▌                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▌                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▋                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▊                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▊                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████▉                      | 1.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████                      | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████                      | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████                      | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████                      | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▏                     | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▎                     | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▎                     | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▍                     | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▌                     | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▌                     | 1.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▋                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▋                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▊                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▉                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████▉                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████                     | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▏                    | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▏                    | 1.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▎                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▍                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▍                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▌                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▋                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▋                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▊                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▊                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████▉                    | 1.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████                    | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████                    | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████                    | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▏                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▏                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▎                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▎                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▍                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▌                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▌                   | 1.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▋                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▊                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▊                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████▉                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████                   | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▏                  | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▎                  | 1.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▎                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▍                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▌                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▌                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▋                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▋                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▊                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▉                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████▉                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████                  | 2.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████                  | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████                  | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▏                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▏                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▎                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▍                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▍                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▌                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▋                 | 2.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▋                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▊                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▊                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████▉                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████                 | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▏                | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▏                | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▎                | 2.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▎                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▍                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▌                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▌                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▋                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▊                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▊                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▉                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████▉                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████                | 2.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████                | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████                | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▏               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▎               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▎               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▍               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▍               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▌               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▋               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▋               | 2.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▊               | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▉               | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████▉               | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████               | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████               | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████               | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▏              | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▏              | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▎              | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▍              | 2.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▍              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▌              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▋              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▋              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▊              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▊              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████▉              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████              | 2.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████              | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▏             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▏             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▎             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▎             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▍             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▌             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▌             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▋             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▊             | 2.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▊             | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▉             | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████▉             | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████             | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████             | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████             | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▏            | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▎            | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▎            | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▍            | 2.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▍            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▌            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▋            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▋            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▊            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▉            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████▉            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████            | 2.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▏           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▏           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▎           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▍           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▍           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▌           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▌           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▋           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▊           | 3.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▊           | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████▉           | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████           | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████           | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████           | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▏          | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▏          | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▎          | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▎          | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▍          | 3.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▌          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▌          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▋          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▊          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▊          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▉          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████▉          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████          | 3.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▏         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▎         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▎         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▍         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▍         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▌         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▋         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▋         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▊         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▉         | 3.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████▉         | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████         | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████         | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████         | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▏        | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▏        | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▎        | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▍        | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▍        | 3.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▌        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▌        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▋        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▊        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▊        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████▉        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████        | 3.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▏       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▎       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▎       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▍       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▌       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▌       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▋       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▋       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▊       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▉       | 3.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████▉       | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████       | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████       | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████       | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▏      | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▎      | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▎      | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▍      | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▍      | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▌      | 3.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▋      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▋      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▊      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▉      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████▉      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████      | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▏     | 3.8 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▏     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▎     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▍     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▍     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▌     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▌     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▋     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▊     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▊     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████▉     | 3.9 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████     | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████     | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████     | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████     | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▏    | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▎    | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▎    | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▍    | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▌    | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▌    | 4.0 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▋    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▋    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▊    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▉    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████▉    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████    | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▏   | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▏   | 4.1 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▎   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▍   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▍   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▌   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▋   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▋   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▊   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▊   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████▉   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████   | 4.2 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████   | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████   | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▏  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▏  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▎  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▍  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▍  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▌  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▌  | 4.3 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▋  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▊  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▊  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |█████████████████████████████▉  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████  | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▏ | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▎ | 4.4 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▎ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▍ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▌ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▌ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▋ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▋ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▊ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▉ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |██████████████████████████████▉ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████ | 4.5 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████ | 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████ | 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▏| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▏| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▎| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▍| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▍| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▌| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▋| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▋| 4.6 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▊| 4.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▊| 4.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |███████████████████████████████▉| 4.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████████| 4.7 MB 73.4 MB/s eta 0:00:01\r",
      "     |████████████████████████████████| 4.7 MB 73.4 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     |████████████████████████████████| 4.7 MB 73.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.21.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (1.3.3)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (3.19.1)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from streamlit==0.72.0) (1.21.4)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 8.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==0.72.0) (4.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==0.72.0) (3.0.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.9/site-packages (from altair>=3.2.0->streamlit==0.72.0) (0.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.21.0->streamlit==0.72.0) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil->streamlit==0.72.0) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     |████████████████████████████████| 62 kB 2.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->streamlit==0.72.0) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->streamlit==0.72.0) (2.0.8)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from validators->streamlit==0.72.0) (4.4.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->altair>=3.2.0->streamlit==0.72.0) (2.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.72.0) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.72.0) (0.18.0)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.7-py2.py3-none-any.whl (340 kB)\n",
      "     |████████████████████████████████| 340 kB 74.5 MB/s            \n",
      "\u001b[?25hInstalling collected packages: tzdata, smmap, toolz, pytz-deprecation-shim, gitdb, watchdog, tzlocal, toml, pydeck, gitpython, blinker, base58, astor, altair, streamlit\n",
      "Successfully installed altair-4.2.0 astor-0.8.1 base58-2.1.1 blinker-1.5 gitdb-4.0.10 gitpython-3.1.29 pydeck-0.8.0 pytz-deprecation-shim-0.1.0.post0 smmap-5.0.0 streamlit-0.72.0 toml-0.10.2 toolz-0.12.0 tzdata-2022.7 tzlocal-4.2 watchdog-2.1.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install kogpt2_transformers\n",
    "!pip install rouge\n",
    "!pip install pytorch-lightning==1.1.0\n",
    "!pip install streamlit==0.72.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7640e579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aiffelthon/KoGPT2-summarization\n"
     ]
    }
   ],
   "source": [
    "%cd /aiffel/aiffel/aiffelthon/KoGPT2-summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from kogpt2_transformers import get_kogpt2_model, get_kogpt2_tokenizer\n",
    "from soft_embedding import SoftEmbedding\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from rouge import Rouge\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42422550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
    "from dataset_summary import KoGPTSummaryDataset\n",
    "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
    "from soft_embedding import SoftEmbedding\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe09c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category별 DataFrame을 출력 (train)\n",
    "train = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/train.tsv', delimiter = '\\t')\n",
    "Category = train['Category'].unique()\n",
    "data_path = '/aiffel/aiffel/aiffelthon/csv/'\n",
    "def train_categori_ext(data):\n",
    "    df = pd.DataFrame()\n",
    "    for c in Category:\n",
    "        df = pd.concat([df, data[data['Category'] == c].iloc[0:int(len(data[data['Category'] == c])*0.2)]], axis = 0)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        df.to_csv(data_path+'train_20%.tsv', sep = '\\t', encoding = 'utf-8', index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe17fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_categori_ext(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category별 DataFrame을 출력\n",
    "val = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/val.tsv', delimiter = '\\t')\n",
    "Category = val['Category'].unique()\n",
    "data_path = '/aiffel/aiffel/aiffelthon/csv/'\n",
    "def val_categori_ext(data):\n",
    "    df = pd.DataFrame()\n",
    "    for c in Category:\n",
    "        df = pd.concat([df, data[data['Category'] == c].iloc[0:int(len(data[data['Category'] == c])*0.2)]], axis = 0)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        df.to_csv(data_path+'val_20%.tsv', sep = '\\t', encoding = 'utf-8', index = False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9a0aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3492d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/aiffel/aiffel/aiffelthon/KoGPT2-summarization/data/test.tsv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f9af4cb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9effd65e-e18f-5510-8866-d6a677314c9c</td>\n",
       "      <td>['웅', '영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙...</td>\n",
       "      <td>팀장님이 출장 가서 머물 숙소를 계속해서 더 싼 데로 하게 한다고 이야기하고 있다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49b9f9b7-a79d-5283-9553-95b8f156ff90</td>\n",
       "      <td>['너는 잘가라....회사.... 선택 잘해..', '알겠어 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 많...</td>\n",
       "      <td>이제 이력서를 쓰고 영어도 해야 한다고 해서 첫 회사를 잘 들어가라고 했다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df6b6bac-648b-5d32-86a3-9b8b215e5f95</td>\n",
       "      <td>['느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 ㅋㅋㅋ', '그러면서',...</td>\n",
       "      <td>느낌상 대통령까지는 아니고 오시면 여사님 정도 오시지 않을까라며 이에 대해 이야기하...</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3043293f-7bb5-5edb-9b1f-85120e305c3d</td>\n",
       "      <td>['숨만수이ㅓ도 숨만쉬어도 100 이내', '한달안에 일 무조건 해야대', '아 딱...</td>\n",
       "      <td>한 달 안에 무조건 일을 시작해서 돈을 벌어야 한다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2b9b9c39-2721-50e6-af3e-e5c00138f43d</td>\n",
       "      <td>['목요일은 외근이구 금요일은 출장!!!', '금요일이 당진이양?', '아닝아닝 1...</td>\n",
       "      <td>목요일에 외근이고 금요일에 출장인데 당진은 10일에 간다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>b03b9ad0-62fa-54a5-b552-69049bd642ee</td>\n",
       "      <td>['엄마 점심식사 뭐먹었어요??', '우린 중국집 시켜먹었다', '오오 짜장면 탕수...</td>\n",
       "      <td>엄마에게 오늘 점심 뭐 먹었냐고 묻고 엄마가 중국집에서 볶음밥, 잡채밥 시켜 먹었다...</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>ec83f40a-3c01-581d-962c-80fd62a5c888</td>\n",
       "      <td>['매운거', '담에 점심 엽떡', '자신있음', '엽떡 먹는 사람', '오 저색기...</td>\n",
       "      <td>엽떡(엽기 떡볶이) 제일 매운맛을 3명에서 도전하기로 했다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2b8dad32-cb6a-5d2a-89c4-06ba5f8dc8f8</td>\n",
       "      <td>['아 술마시고싶다 취할줄알았는데 ㅋㅋㅋㅋㅋㅋ', '누룩오자 누룩 군고구마막걸리 존...</td>\n",
       "      <td>군고구마막걸리가 맛있다고 하니 빨리 마셔보고 싶다고 한다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>bd803ef5-c166-54ad-8d96-ac73fb055b3d</td>\n",
       "      <td>['종촌동에서 뭘 주워먹어야겠다... 어른들 저녁먹고 가신대 뭐사먹지,.....',...</td>\n",
       "      <td>어른들이 저녁 먹고 가신다고 해서 뭘 사 먹을까 하니 근처에 국수나무가 맛있다고 한다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>feb1cb05-67c9-5638-80d4-ca2b1c8f4ef0</td>\n",
       "      <td>['오늘은 맛있는 게 먹고싶네요', '집에가서 먹어염....', 'ㅜㅜ', '얼른가...</td>\n",
       "      <td>아까는 김밥을 사 먹으려고 했지만 지금은 맛있는 게먹고 싶어졌다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1746 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Id  \\\n",
       "0     9effd65e-e18f-5510-8866-d6a677314c9c   \n",
       "1     49b9f9b7-a79d-5283-9553-95b8f156ff90   \n",
       "2     df6b6bac-648b-5d32-86a3-9b8b215e5f95   \n",
       "3     3043293f-7bb5-5edb-9b1f-85120e305c3d   \n",
       "4     2b9b9c39-2721-50e6-af3e-e5c00138f43d   \n",
       "...                                    ...   \n",
       "1741  b03b9ad0-62fa-54a5-b552-69049bd642ee   \n",
       "1742  ec83f40a-3c01-581d-962c-80fd62a5c888   \n",
       "1743  2b8dad32-cb6a-5d2a-89c4-06ba5f8dc8f8   \n",
       "1744  bd803ef5-c166-54ad-8d96-ac73fb055b3d   \n",
       "1745  feb1cb05-67c9-5638-80d4-ca2b1c8f4ef0   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     ['웅', '영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙...   \n",
       "1     ['너는 잘가라....회사.... 선택 잘해..', '알겠어 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 많...   \n",
       "2     ['느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 ㅋㅋㅋ', '그러면서',...   \n",
       "3     ['숨만수이ㅓ도 숨만쉬어도 100 이내', '한달안에 일 무조건 해야대', '아 딱...   \n",
       "4     ['목요일은 외근이구 금요일은 출장!!!', '금요일이 당진이양?', '아닝아닝 1...   \n",
       "...                                                 ...   \n",
       "1741  ['엄마 점심식사 뭐먹었어요??', '우린 중국집 시켜먹었다', '오오 짜장면 탕수...   \n",
       "1742  ['매운거', '담에 점심 엽떡', '자신있음', '엽떡 먹는 사람', '오 저색기...   \n",
       "1743  ['아 술마시고싶다 취할줄알았는데 ㅋㅋㅋㅋㅋㅋ', '누룩오자 누룩 군고구마막걸리 존...   \n",
       "1744  ['종촌동에서 뭘 주워먹어야겠다... 어른들 저녁먹고 가신대 뭐사먹지,.....',...   \n",
       "1745  ['오늘은 맛있는 게 먹고싶네요', '집에가서 먹어염....', 'ㅜㅜ', '얼른가...   \n",
       "\n",
       "                                                Summary Category  \n",
       "0        팀장님이 출장 가서 머물 숙소를 계속해서 더 싼 데로 하게 한다고 이야기하고 있다.    일과 직업  \n",
       "1            이제 이력서를 쓰고 영어도 해야 한다고 해서 첫 회사를 잘 들어가라고 했다.    일과 직업  \n",
       "2     느낌상 대통령까지는 아니고 오시면 여사님 정도 오시지 않을까라며 이에 대해 이야기하...    일과 직업  \n",
       "3                         한 달 안에 무조건 일을 시작해서 돈을 벌어야 한다.    일과 직업  \n",
       "4                      목요일에 외근이고 금요일에 출장인데 당진은 10일에 간다.    일과 직업  \n",
       "...                                                 ...      ...  \n",
       "1741  엄마에게 오늘 점심 뭐 먹었냐고 묻고 엄마가 중국집에서 볶음밥, 잡채밥 시켜 먹었다...      식음료  \n",
       "1742                  엽떡(엽기 떡볶이) 제일 매운맛을 3명에서 도전하기로 했다.      식음료  \n",
       "1743                   군고구마막걸리가 맛있다고 하니 빨리 마셔보고 싶다고 한다.      식음료  \n",
       "1744   어른들이 저녁 먹고 가신다고 해서 뭘 사 먹을까 하니 근처에 국수나무가 맛있다고 한다.      식음료  \n",
       "1745               아까는 김밥을 사 먹으려고 했지만 지금은 맛있는 게먹고 싶어졌다.      식음료  \n",
       "\n",
       "[1746 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c46f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_categori_ext(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f0fa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch cash 초기화\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8d2fe",
   "metadata": {},
   "source": [
    "Model : KoGPT-2\n",
    "\n",
    "Parametors size : \n",
    "\n",
    "[How to use GPT2LMHeadModel for conditional generation](https://github.com/huggingface/transformers/issues/970)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805bfc09",
   "metadata": {},
   "source": [
    "Data NAME : Ai_hub 대화문 요약 Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00551cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (.) 제거\n",
    "    sentence = re.sub(r'[ㄱ-ㅎㅏ-ㅣ.,?!]+[/ㄱ-ㅎㅏ-ㅣ.,?!]', '', sentence) # 여러개 자음, 모음, 구두점에서 마지막 1개만 남긴다\n",
    "    sentence = re.sub(\"[^가-힣a-z0-9-.,!?]\", \" \", sentence) # 지정한 문자 제외 공백으로 전환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
    "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리와 메타데이터 적용 \n",
    "\n",
    "def data_load(data_path = '/aiffel/aiffel/aiffelthon/csv/train_5%.tsv'):\n",
    "    data = []\n",
    "    train_df = pd.read_csv(data_path, delimiter = '\\t')\n",
    "    #train_df = train_df.iloc[::2, :] # 짝수 row data만 추출한다.\n",
    "    #train_df.reset_index(drop=True, inplace = True) # 인덱스 초기화\n",
    "    \n",
    "    # 전처리 적용\n",
    "    clean_text = []\n",
    "    \n",
    "    for s in tqdm(train_df['Text']):\n",
    "        clean_text.append(preprocess_sentence(s))\n",
    "                          \n",
    "    train_df['Text'] = clean_text\n",
    "    \n",
    "    clean_headlines = []\n",
    "                          \n",
    "    for s in tqdm(train_df['Summary']):\n",
    "        clean_headlines.append(preprocess_sentence(s))\n",
    "        \n",
    "    train_df['Summary'] = clean_headlines \n",
    "    \n",
    "#     # 메타데이터 적용\n",
    "#     def metadata_train(train_df): \n",
    "#         meta = '#'+train_df['Category']+'# '\n",
    "#         train_df['Text'] = meta + train_df['Text']\n",
    "#         return train_df['Text']\n",
    "    \n",
    "#     metadata_train(train_df)\n",
    "    \n",
    "    # Series > list\n",
    "    train_df['Text'].tolist()\n",
    "    train_df['Summary'].tolist()\n",
    "    \n",
    "    return train_df['Text'], train_df['Summary']\n",
    "\n",
    "def val_load(data_path = '/aiffel/aiffel/aiffelthon/csv/val_5%.tsv'):\n",
    "    data = []\n",
    "    val_df = pd.read_csv(data_path, delimiter = '\\t')\n",
    "    #val_df = val_df.iloc[::2, :]\n",
    "    #val_df.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "\n",
    "    # 전처리 적용\n",
    "    clean_text_val = []\n",
    "                          \n",
    "    for s in tqdm(val_df['Text']):\n",
    "        clean_text_val.append(preprocess_sentence(s))\n",
    "    \n",
    "    val_df['Text'] = clean_text_val\n",
    "    \n",
    "    clean_headlines_val = []\n",
    "                          \n",
    "    for s in tqdm(val_df['Summary']):\n",
    "        clean_headlines_val.append(preprocess_sentence(s))\n",
    "        \n",
    "    val_df['Summary'] = clean_headlines_val \n",
    "    \n",
    "    # 메타데이터 적용\n",
    "#     def metadata_val(val_df): \n",
    "#         meta = '#'+val_df['Category']+'# '\n",
    "#         val_df['Text'] = meta + val_df['Text']\n",
    "#         return val_df['Text']\n",
    "    \n",
    "#     metadata_val(val_df)\n",
    "                          \n",
    "    # Series > list\n",
    "    val_df['Text'].tolist()\n",
    "    val_df['Summary'].tolist()\n",
    "    \n",
    "    return val_df['Text'], val_df['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1be2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc84d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = val_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62020202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2dd13",
   "metadata": {},
   "source": [
    "### hyparam은 Code를 가져올 때 설정을 유지중입니다. GPT-2  학습이 제대로 이루어진게 어제부터라서 수정하지는 못했습니다.\n",
    "\n",
    "### 그래도 수정을 한 부분은 문장을 생성할 때 eos_token, pad_token이 생성되어 이 부분을 출력하지 않도록 bad_words_index를 사용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e84d40a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2682299943.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_462/2682299943.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    def initialize_embedding(self, wte : nn.Embedding, prompt_length : int = 10, random_range : float = 0.5, initialize_from_vocab: bool = True)\u001b[0m\n\u001b[0m                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# # Soft_embedding 제작\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Soft_embedding Class\n",
    "# class SoftEmbedding(nn.Module):\n",
    "#     def __init__(self, wte : nn.Embedding, prompt_length : int = 20, random_range : float = 0.5, initialize_from_vocab: bool = True):\n",
    "#         \"\"\"appends learned embedding to \n",
    "#         Args:\n",
    "#             wte (nn.Embedding): original transformer word embedding (기존 트랜스포머의 word embedding)\n",
    "#             prompt_length (int, optional): number of tokens for task. Defaults to 10. (테스크 토큰 수, 기본 값 10개)\n",
    "#             random_range (float, optional): range to init embedding (if not initialize from vocab). Defaults to 0.5.\n",
    "#             (만약 vocab에서 초기화하지 않으면 기본 값 0.5)\n",
    "#             initialize_from_vocab (bool, optional): initalizes from default vocab. Defaults to True. (기본 vocab에서 초기화)\n",
    "#         \"\"\"\n",
    "#         super(SoftEmbedding, self).__init__()\n",
    "#         self.wte = wte\n",
    "#         slef.prompt_length = prompt_length\n",
    "#         self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(\n",
    "#         wte, prompt_length, random_range, initialize_from_vocab))\n",
    "        \n",
    "#     def initialize_embedding(self, wte : nn.Embedding, prompt_length : int = 10, random_range : float = 0.5, initialize_from_vocab: bool = True)\n",
    "#         \"\"\"initializes learned embedding\n",
    "#         Args:\n",
    "#             same as __init__\n",
    "#         Returns:\n",
    "#             torch.float: initialized using original schemes\n",
    "#         \"\"\"\n",
    "#         if initialize_from_vocab:\n",
    "#             return self.wte.weight[:prompt_length].clone().detach()\n",
    "#         return torch.FloatTensor(prompt_length, wte.weight.size(1)).uniform_(-random_range, random_range)\n",
    "    \n",
    "#     def forward(self, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96be895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "train_set = KoGPTSummaryDataset(file = '/aiffel/aiffel/aiffelthon/csv/train_5%.tsv', tok = get_kogpt2_tokenizer(), max_len = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ceec11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "val_set = KoGPTSummaryDataset(file = '/aiffel/aiffel/aiffelthon/csv/val_5%.tsv', tok = get_kogpt2_tokenizer(), max_len = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec26774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm 제작\n",
    "\n",
    "parser = argparse.ArgumentParser(description='KoGPT2 Summarization')\n",
    "\n",
    "parser.add_argument('--checkpoint_path',\n",
    "                    type=str,\n",
    "                    help='checkpoint path')\n",
    "\n",
    "class ArgsBase():\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = argparse.ArgumentParser(\n",
    "            parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--train_file',\n",
    "                            type=str,\n",
    "                            default='data/train.tsv',\n",
    "                            help='train file')\n",
    "\n",
    "        parser.add_argument('--test_file',\n",
    "                            type=str,\n",
    "                            default='data/test.tsv',\n",
    "                            help='test file')\n",
    "\n",
    "        parser.add_argument('--batch_size',\n",
    "                            type=int,\n",
    "                            default=4,\n",
    "                            help='')\n",
    "        parser.add_argument('--max_len',\n",
    "                            type=int,\n",
    "                            default=256,\n",
    "                            help='max seq len')\n",
    "        return parser\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "        \n",
    "class AbstractiveKoGPT2(pl.LightningDataModule):\n",
    "    def __init__(self, train_file,\n",
    "                 test_file, tok,\n",
    "                 max_len=256,\n",
    "                 batch_size=4,\n",
    "                 num_workers=4,\n",
    "                 prompt_length=0):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.train_file_path = train_file\n",
    "        self.test_file_path = test_file\n",
    "        self.prompt_length = prompt_length\n",
    "        if tok is None:\n",
    "            self.tok = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "                       bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                       pad_token='<pad>', mask_token='<mask>') \n",
    "        else:\n",
    "            self.tok = tok  \n",
    "        self.num_workers = num_workers\n",
    "            \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = argparse.ArgumentParser(\n",
    "            parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--num_workers',\n",
    "                            type=int,\n",
    "                            default=5,\n",
    "                            help='num of worker for dataloader')\n",
    "        return parser\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        # split dataset\n",
    "        self.train = KoGPTSummaryDataset(file=self.train_file_path,\n",
    "                                 tok=self.tok,\n",
    "                                 max_len=self.max_len,\n",
    "                                 prompt_length=self.prompt_length)\n",
    "        \n",
    "        self.test = KoGPTSummaryDataset(file=self.test_file_path,\n",
    "                                tok=self.tok,\n",
    "                                max_len=self.max_len,\n",
    "                                prompt_length=self.prompt_length)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train = DataLoader(self.train,\n",
    "                           batch_size=self.batch_size,\n",
    "                           num_workers=self.num_workers, shuffle=True)\n",
    "        return train\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val = DataLoader(self.test,\n",
    "                         batch_size=self.batch_size,\n",
    "                         num_workers=self.num_workers, shuffle=False)\n",
    "        return val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test = DataLoader(self.test,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=self.num_workers, shuffle=False)\n",
    "        return test\n",
    "            \n",
    "class Base(pl.LightningModule):\n",
    "    def __init__(self, hparams, **kwargs) -> None:\n",
    "        super(Base, self).__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        # add model specific args\n",
    "        parser = argparse.ArgumentParser(\n",
    "            parents=[parent_parser], add_help=False)\n",
    "\n",
    "        parser.add_argument('--lr',\n",
    "                            type=float,\n",
    "                            default=3e-5,\n",
    "                            help='The initial learning rate')\n",
    "\n",
    "        parser.add_argument('--warmup_ratio',\n",
    "                            type=float,\n",
    "                            default=0.1,\n",
    "                            help='warmup ratio')\n",
    "\n",
    "        parser.add_argument('--model_path',\n",
    "                            type=str,\n",
    "                            default=None,\n",
    "                            help='kobart model path')\n",
    "        \n",
    "        parser.add_argument('--prompt_length',\n",
    "                            type=int,\n",
    "                            default=20,\n",
    "                            help='number of trainable parameters')\n",
    "        \n",
    "        return parser\n",
    "       \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        prompt_parameters = self.model.get_input_embeddings().learned_embedding\n",
    "        optimizer = AdamW([prompt_parameters],\n",
    "                          lr=self.hparams.lr, correct_bias=False)\n",
    "        # warm up lr\n",
    "        num_workers = self.hparams.num_workers\n",
    "        data_len = len(self.train_dataloader().dataset)\n",
    "        logging.info(f'number of workers {num_workers}, data length {data_len}')\n",
    "        num_train_steps = int(data_len / (self.hparams.batch_size * num_workers) * self.hparams.max_epochs)\n",
    "        logging.info(f'num_train_steps : {num_train_steps}')\n",
    "        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n",
    "        logging.info(f'num_warmup_steps : {num_warmup_steps}')\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n",
    "        lr_scheduler = {'scheduler': scheduler, \n",
    "                        'monitor': 'loss', 'interval': 'step',\n",
    "                        'frequency': 1}\n",
    "        return [optimizer], [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e0199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class KoGPTConditionalGeneration(Base):\n",
    "    def __init__(self, hparams, **kwargs):\n",
    "        super(KoGPTConditionalGeneration, self).__init__(hparams, **kwargs)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "        \n",
    "        for p in self.model.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.update_embedding()\n",
    "        self.pad_token_id = 0\n",
    "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "                       bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                       pad_token='<pad>', mask_token='<mask>')\n",
    "        \n",
    "        self.neg = 0\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "    def update_embedding(self):\n",
    "        s_wte = SoftEmbedding(self.model.get_input_embeddings(), \n",
    "                      prompt_length=self.hparams.prompt_length, \n",
    "                      initialize_from_vocab=True)\n",
    "        self.model.set_input_embeddings(s_wte)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs, return_dict=True)\n",
    "        return output.logits    \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        token_ids = batch['input']\n",
    "        mask = batch['mask']\n",
    "        label = batch['label']\n",
    "\n",
    "        out = self(token_ids)        \n",
    "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "        mask_out = torch.where(mask_3d == 1, out, self.neg * torch.ones_like(out))\n",
    "        loss = self.loss_function(mask_out.transpose(2, 1), label)\n",
    "        loss_avg = loss.sum() / mask.sum()\n",
    "        self.log('train_loss', loss_avg)\n",
    "        return loss_avg\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        token_ids = batch['input']\n",
    "        mask = batch['mask']\n",
    "        label = batch['label']\n",
    "        \n",
    "        out = self(token_ids)\n",
    "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
    "        mask_out = torch.where(mask_3d == 1, out, self.neg * torch.ones_like(out))\n",
    "        loss = self.loss_function(mask_out.transpose(2, 1), label)\n",
    "        loss_avg = loss.sum() / mask.sum()\n",
    "        return (loss_avg)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        losses = []\n",
    "        for loss in outputs:\n",
    "            losses.append(loss)\n",
    "        self.log('val_loss', torch.stack(losses).mean(), prog_bar=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1fe6cf",
   "metadata": {},
   "source": [
    "# 오류 해결\n",
    "\n",
    "[parse 오류 해결]https://uding.tistory.com/49\n",
    "\n",
    "[TypeError: expected str, bytes or os.PathLike object, not NoneType]\n",
    "- checkpoint_path 연결\n",
    "\n",
    "[MisconfigurationException: No `train_dataloader()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446c4d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(checkpoint_path=None, lr=3e-05, warmup_ratio=0.1, model_path=None, prompt_length=20, train_file='data/train.tsv', test_file='data/test.tsv', batch_size=4, max_len=256, num_workers=5, logger=True, checkpoint_callback=True, default_root_dir=None, gradient_clip_val=0, process_position=0, num_nodes=1, num_processes=1, gpus=<function _gpus_arg_default at 0x7f91379f13a0>, auto_select_gpus=False, tpu_cores=<function _gpus_arg_default at 0x7f91379f13a0>, log_gpu_memory=None, progress_bar_refresh_rate=1, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=1000, min_epochs=1, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=True)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory /aiffel/aiffel/aiffelthon/checkpoint_4 exists and is not empty. With save_top_k=3, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: False\n",
      "INFO:lightning:GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: None, using: 0 TPU cores\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "INFO:root:number of workers 5, data length 13994\n",
      "INFO:root:num_train_steps : 699700\n",
      "INFO:root:num_warmup_steps : 69970\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | GPT2LMHeadModel  | 125 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "125 M     Non-trainable params\n",
      "125 M     Total params\n",
      "INFO:lightning:\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | GPT2LMHeadModel  | 125 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "125 M     Non-trainable params\n",
      "125 M     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70024e7245647efb1464ac9c75df33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Saving latest checkpoint...\n",
      "INFO:lightning:Saving latest checkpoint...\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "ModelCheckpoint(monitor='val_loss') not found in the returned metrics: ['train_loss']. HINT: Did you call self.log('val_loss', tensor) in the LightningModule?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1159/1550105225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                             callbacks=[checkpoint_callback, lr_logger])\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# when a checkpoint was saved at the last step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mcheck_checkpoint_callback\u001b[0;34m(self, should_save, is_last)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_validation_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_epoch_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcheckpoints\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msaved\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mval\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_backward_monitor_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_monitor_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# track epoch when ckpt was last checked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_validate_monitor_key\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;34mf\"HINT: Did you call self.log('{self.monitor}', tensor) in the LightningModule?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             )\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_metric_interpolated_filepath_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name_metrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ModelCheckpoint(monitor='val_loss') not found in the returned metrics: ['train_loss']. HINT: Did you call self.log('val_loss', tensor) in the LightningModule?"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = Base.add_model_specific_args(parser)\n",
    "    parser = ArgsBase.add_model_specific_args(parser)\n",
    "    parser = AbstractiveKoGPT2.add_model_specific_args(parser)\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    args,_ = parser.parse_known_args()\n",
    "    logging.info(args)\n",
    "    \n",
    "    checkpoint_path = \"/aiffel/aiffel/aiffelthon/checkpoint_4\"\n",
    "    save_ckpt_path = f\"{checkpoint_path}/kogpt2-abstractive_1epoch.pth\"\n",
    "    \n",
    "    model = KoGPTConditionalGeneration(args)\n",
    "    \n",
    "    dm = AbstractiveKoGPT2(args.train_file,\n",
    "                        args.test_file,\n",
    "                        None,\n",
    "                        batch_size=args.batch_size,\n",
    "                        max_len=args.max_len,\n",
    "                        num_workers=args.num_workers,\n",
    "                        prompt_length=args.prompt_length)\n",
    "    \n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss',\n",
    "                                                       dirpath=checkpoint_path,\n",
    "                                                       filename='model_chp/{epoch:02d}-{val_loss:.3f}',\n",
    "                                                       verbose=True,\n",
    "                                                       save_last=True,\n",
    "                                                       mode='min',\n",
    "                                                       save_top_k=3)\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(os.path.join(checkpoint_path, 'tb_logs'))\n",
    "    lr_logger = pl.callbacks.LearningRateMonitor()\n",
    "    trainer = pl.Trainer.from_argparse_args(args, logger=tb_logger,\n",
    "                                            callbacks=[checkpoint_callback, lr_logger])\n",
    "    \n",
    "    trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3667a3d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(checkpoint_path=None, lr=3e-05, warmup_ratio=0.1, model_path=None, prompt_length=20, train_file='data/train.tsv', test_file='data/test.tsv', batch_size=4, max_len=258, num_workers=4, logger=True, checkpoint_callback=True, default_root_dir='logs', gradient_clip_val=1.0, process_position=0, num_nodes=1, num_processes=1, gpus=1, auto_select_gpus=False, tpu_cores=<function _gpus_arg_default at 0x7f85d60c0a60>, log_gpu_memory=None, progress_bar_refresh_rate=1, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=1, min_epochs=1, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=True)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:number of workers 4, data length 13994\n",
      "INFO:root:num_train_steps : 874\n",
      "INFO:root:num_warmup_steps : 87\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | GPT2LMHeadModel  | 125 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "125 M     Non-trainable params\n",
      "125 M     Total params\n",
      "INFO:lightning:\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | GPT2LMHeadModel  | 125 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "125 M     Non-trainable params\n",
      "125 M     Total params\n",
      "Epoch 0:  89%|▉| 3499/3936 [20:08<02:30,  2.89it/s, loss=3.43, v_num=0, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3501/3936 [20:09<02:30,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   0%|▏                              | 2/437 [00:00<01:30,  4.82it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3503/3936 [20:09<02:29,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   1%|▎                              | 4/437 [00:00<01:17,  5.59it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3505/3936 [20:09<02:28,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   1%|▍                              | 6/437 [00:01<01:13,  5.84it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3507/3936 [20:10<02:28,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   2%|▌                              | 8/437 [00:01<01:12,  5.95it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3509/3936 [20:10<02:27,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   2%|▋                             | 10/437 [00:01<01:11,  6.01it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3511/3936 [20:10<02:26,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   3%|▊                             | 12/437 [00:02<01:10,  6.03it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3513/3936 [20:11<02:25,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   3%|▉                             | 14/437 [00:02<01:10,  6.03it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3515/3936 [20:11<02:25,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   4%|█                             | 16/437 [00:02<01:09,  6.03it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3517/3936 [20:11<02:24,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   4%|█▏                            | 18/437 [00:03<01:09,  6.04it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3519/3936 [20:12<02:23,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   5%|█▎                            | 20/437 [00:03<01:09,  6.02it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3521/3936 [20:12<02:22,  2.90it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   5%|█▌                            | 22/437 [00:03<01:08,  6.04it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3523/3936 [20:12<02:22,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   5%|█▋                            | 24/437 [00:04<01:08,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3525/3936 [20:13<02:21,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   6%|█▊                            | 26/437 [00:04<01:07,  6.04it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3527/3936 [20:13<02:20,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   6%|█▉                            | 28/437 [00:04<01:07,  6.04it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3529/3936 [20:13<02:19,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   7%|██                            | 30/437 [00:05<01:07,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3531/3936 [20:14<02:19,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   7%|██▏                           | 32/437 [00:05<01:07,  6.04it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3533/3936 [20:14<02:18,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   8%|██▎                           | 34/437 [00:05<01:06,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3535/3936 [20:14<02:17,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   8%|██▍                           | 36/437 [00:06<01:06,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3537/3936 [20:15<02:17,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   9%|██▌                           | 38/437 [00:06<01:05,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3539/3936 [20:15<02:16,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:   9%|██▋                           | 40/437 [00:06<01:05,  6.02it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3541/3936 [20:15<02:15,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  10%|██▉                           | 42/437 [00:07<01:05,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3543/3936 [20:16<02:14,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  10%|███                           | 44/437 [00:07<01:04,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3545/3936 [20:16<02:14,  2.91it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  11%|███▏                          | 46/437 [00:07<01:04,  6.04it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3547/3936 [20:16<02:13,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  11%|███▎                          | 48/437 [00:08<01:04,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3549/3936 [20:17<02:12,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  11%|███▍                          | 50/437 [00:08<01:03,  6.06it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3551/3936 [20:17<02:11,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  12%|███▌                          | 52/437 [00:08<01:03,  6.06it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3553/3936 [20:17<02:11,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  12%|███▋                          | 54/437 [00:09<01:03,  6.05it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3555/3936 [20:18<02:10,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  13%|███▊                          | 56/437 [00:09<01:02,  6.06it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3557/3936 [20:18<02:09,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  13%|███▉                          | 58/437 [00:09<01:02,  6.07it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3559/3936 [20:18<02:09,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  14%|████                          | 60/437 [00:10<01:02,  6.04it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3561/3936 [20:18<02:08,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  14%|████▎                         | 62/437 [00:10<01:01,  6.05it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3563/3936 [20:19<02:07,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  15%|████▍                         | 64/437 [00:10<01:01,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3565/3936 [20:19<02:06,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  15%|████▌                         | 66/437 [00:11<01:01,  6.07it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3567/3936 [20:19<02:06,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  16%|████▋                         | 68/437 [00:11<01:00,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3569/3936 [20:20<02:05,  2.92it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  16%|████▊                         | 70/437 [00:11<01:00,  6.08it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3571/3936 [20:20<02:04,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  16%|████▉                         | 72/437 [00:11<01:00,  6.08it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3573/3936 [20:20<02:04,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  17%|█████                         | 74/437 [00:12<00:59,  6.09it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3575/3936 [20:21<02:03,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  17%|█████▏                        | 76/437 [00:12<00:59,  6.07it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3577/3936 [20:21<02:02,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  18%|█████▎                        | 78/437 [00:12<00:59,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3579/3936 [20:21<02:01,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  18%|█████▍                        | 80/437 [00:13<00:58,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3581/3936 [20:22<02:01,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  19%|█████▋                        | 82/437 [00:13<00:58,  6.07it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3583/3936 [20:22<02:00,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  19%|█████▊                        | 84/437 [00:13<00:58,  6.08it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3585/3936 [20:22<01:59,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  20%|█████▉                        | 86/437 [00:14<00:57,  6.05it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3587/3936 [20:23<01:59,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  20%|██████                        | 88/437 [00:14<00:57,  6.04it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3589/3936 [20:23<01:58,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  21%|██████▏                       | 90/437 [00:14<00:57,  6.07it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3591/3936 [20:23<01:57,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  21%|██████▎                       | 92/437 [00:15<00:56,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3593/3936 [20:24<01:56,  2.93it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  22%|██████▍                       | 94/437 [00:15<00:56,  6.05it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3595/3936 [20:24<01:56,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  22%|██████▌                       | 96/437 [00:15<00:56,  6.05it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3597/3936 [20:24<01:55,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  22%|██████▋                       | 98/437 [00:16<00:55,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3599/3936 [20:25<01:54,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  23%|██████▋                      | 100/437 [00:16<00:55,  6.06it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3601/3936 [20:25<01:54,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  23%|██████▊                      | 102/437 [00:16<00:55,  6.04it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3603/3936 [20:25<01:53,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  24%|██████▉                      | 104/437 [00:17<00:54,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3605/3936 [20:26<01:52,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  24%|███████                      | 106/437 [00:17<00:54,  6.08it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3607/3936 [20:26<01:51,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  25%|███████▏                     | 108/437 [00:17<00:54,  6.05it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3609/3936 [20:26<01:51,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  25%|███████▎                     | 110/437 [00:18<00:53,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3611/3936 [20:27<01:50,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  26%|███████▍                     | 112/437 [00:18<00:53,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3613/3936 [20:27<01:49,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  26%|███████▌                     | 114/437 [00:18<00:53,  6.07it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3615/3936 [20:27<01:49,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  27%|███████▋                     | 116/437 [00:19<00:52,  6.08it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3617/3936 [20:28<01:48,  2.94it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  27%|███████▊                     | 118/437 [00:19<00:52,  6.07it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3619/3936 [20:28<01:47,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  27%|███████▉                     | 120/437 [00:19<00:52,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3621/3936 [20:28<01:46,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  28%|████████                     | 122/437 [00:20<00:51,  6.07it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3623/3936 [20:29<01:46,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  28%|████████▏                    | 124/437 [00:20<00:51,  6.09it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3625/3936 [20:29<01:45,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  29%|████████▎                    | 126/437 [00:20<00:51,  6.08it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3627/3936 [20:29<01:44,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  29%|████████▍                    | 128/437 [00:21<00:50,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3629/3936 [20:30<01:44,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  30%|████████▋                    | 130/437 [00:21<00:50,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3631/3936 [20:30<01:43,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  30%|████████▊                    | 132/437 [00:21<00:50,  6.07it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3633/3936 [20:30<01:42,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  31%|████████▉                    | 134/437 [00:22<00:50,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3635/3936 [20:31<01:41,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  31%|█████████                    | 136/437 [00:22<00:49,  6.06it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3637/3936 [20:31<01:41,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  32%|█████████▏                   | 138/437 [00:22<00:49,  6.05it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3639/3936 [20:31<01:40,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  32%|█████████▎                   | 140/437 [00:23<00:49,  6.05it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3641/3936 [20:32<01:39,  2.95it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  32%|█████████▍                   | 142/437 [00:23<00:48,  6.08it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3643/3936 [20:32<01:39,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  33%|█████████▌                   | 144/437 [00:23<00:48,  6.09it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3645/3936 [20:32<01:38,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  33%|█████████▋                   | 146/437 [00:24<00:47,  6.08it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3647/3936 [20:33<01:37,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  34%|█████████▊                   | 148/437 [00:24<00:47,  6.06it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3649/3936 [20:33<01:37,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  34%|█████████▉                   | 150/437 [00:24<00:47,  6.05it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3651/3936 [20:33<01:36,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  35%|██████████                   | 152/437 [00:25<00:46,  6.08it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3653/3936 [20:34<01:35,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  35%|██████████▏                  | 154/437 [00:25<00:46,  6.09it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3655/3936 [20:34<01:34,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  36%|██████████▎                  | 156/437 [00:25<00:46,  6.06it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3657/3936 [20:34<01:34,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  36%|██████████▍                  | 158/437 [00:26<00:46,  6.05it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3659/3936 [20:35<01:33,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  37%|██████████▌                  | 160/437 [00:26<00:45,  6.06it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3661/3936 [20:35<01:32,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  37%|██████████▊                  | 162/437 [00:26<00:45,  6.09it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3663/3936 [20:35<01:32,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  38%|██████████▉                  | 164/437 [00:27<00:44,  6.08it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3665/3936 [20:36<01:31,  2.96it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  38%|███████████                  | 166/437 [00:27<00:44,  6.07it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3667/3936 [20:36<01:30,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  38%|███████████▏                 | 168/437 [00:27<00:44,  6.06it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3669/3936 [20:36<01:30,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  39%|███████████▎                 | 170/437 [00:28<00:44,  6.07it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3671/3936 [20:37<01:29,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  39%|███████████▍                 | 172/437 [00:28<00:43,  6.08it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3673/3936 [20:37<01:28,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  40%|███████████▌                 | 174/437 [00:28<00:43,  6.08it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3675/3936 [20:37<01:27,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  40%|███████████▋                 | 176/437 [00:29<00:42,  6.07it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3677/3936 [20:38<01:27,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  41%|███████████▊                 | 178/437 [00:29<00:42,  6.05it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3679/3936 [20:38<01:26,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  41%|███████████▉                 | 180/437 [00:29<00:42,  6.09it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3681/3936 [20:38<01:25,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  42%|████████████                 | 182/437 [00:30<00:41,  6.09it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3683/3936 [20:39<01:25,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  42%|████████████▏                | 184/437 [00:30<00:41,  6.10it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3685/3936 [20:39<01:24,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  43%|████████████▎                | 186/437 [00:30<00:41,  6.10it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3687/3936 [20:39<01:23,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  43%|████████████▍                | 188/437 [00:31<00:40,  6.11it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3689/3936 [20:40<01:23,  2.97it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  43%|████████████▌                | 190/437 [00:31<00:40,  6.08it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3691/3936 [20:40<01:22,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  44%|████████████▋                | 192/437 [00:31<00:40,  6.06it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3693/3936 [20:40<01:21,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  44%|████████████▊                | 194/437 [00:32<00:40,  6.06it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3695/3936 [20:41<01:20,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  45%|█████████████                | 196/437 [00:32<00:39,  6.10it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3697/3936 [20:41<01:20,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  45%|█████████████▏               | 198/437 [00:32<00:39,  6.11it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3699/3936 [20:41<01:19,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  46%|█████████████▎               | 200/437 [00:33<00:38,  6.10it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3701/3936 [20:42<01:18,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  46%|█████████████▍               | 202/437 [00:33<00:38,  6.09it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3703/3936 [20:42<01:18,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  47%|█████████████▌               | 204/437 [00:33<00:38,  6.07it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3705/3936 [20:42<01:17,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  47%|█████████████▋               | 206/437 [00:34<00:37,  6.08it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3707/3936 [20:43<01:16,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  48%|█████████████▊               | 208/437 [00:34<00:37,  6.09it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3709/3936 [20:43<01:16,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  48%|█████████████▉               | 210/437 [00:34<00:37,  6.07it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3711/3936 [20:43<01:15,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  49%|██████████████               | 212/437 [00:35<00:37,  6.05it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3713/3936 [20:44<01:14,  2.98it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  49%|██████████████▏              | 214/437 [00:35<00:36,  6.06it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3715/3936 [20:44<01:14,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  49%|██████████████▎              | 216/437 [00:35<00:36,  6.10it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3717/3936 [20:44<01:13,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  50%|██████████████▍              | 218/437 [00:36<00:35,  6.11it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3719/3936 [20:45<01:12,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  50%|██████████████▌              | 220/437 [00:36<00:35,  6.10it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3721/3936 [20:45<01:11,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  51%|██████████████▋              | 222/437 [00:36<00:35,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3723/3936 [20:45<01:11,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  51%|██████████████▊              | 224/437 [00:37<00:35,  6.07it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3725/3936 [20:46<01:10,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  52%|██████████████▉              | 226/437 [00:37<00:34,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3727/3936 [20:46<01:09,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  52%|███████████████▏             | 228/437 [00:37<00:34,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3729/3936 [20:46<01:09,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  53%|███████████████▎             | 230/437 [00:38<00:34,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3731/3936 [20:46<01:08,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  53%|███████████████▍             | 232/437 [00:38<00:33,  6.07it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3733/3936 [20:47<01:07,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  54%|███████████████▌             | 234/437 [00:38<00:33,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3735/3936 [20:47<01:07,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  54%|███████████████▋             | 236/437 [00:39<00:32,  6.09it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3737/3936 [20:47<01:06,  2.99it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  54%|███████████████▊             | 238/437 [00:39<00:32,  6.10it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3739/3936 [20:48<01:05,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  55%|███████████████▉             | 240/437 [00:39<00:32,  6.10it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3741/3936 [20:48<01:05,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  55%|████████████████             | 242/437 [00:39<00:32,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3743/3936 [20:48<01:04,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  56%|████████████████▏            | 244/437 [00:40<00:31,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3745/3936 [20:49<01:03,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  56%|████████████████▎            | 246/437 [00:40<00:31,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3747/3936 [20:49<01:03,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  57%|████████████████▍            | 248/437 [00:40<00:30,  6.10it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3749/3936 [20:49<01:02,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  57%|████████████████▌            | 250/437 [00:41<00:30,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3751/3936 [20:50<01:01,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  58%|████████████████▋            | 252/437 [00:41<00:30,  6.07it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3753/3936 [20:50<01:00,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  58%|████████████████▊            | 254/437 [00:41<00:30,  6.08it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3755/3936 [20:50<01:00,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  59%|████████████████▉            | 256/437 [00:42<00:29,  6.09it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3757/3936 [20:51<00:59,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  59%|█████████████████            | 258/437 [00:42<00:29,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3759/3936 [20:51<00:58,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  59%|█████████████████▎           | 260/437 [00:42<00:29,  6.10it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3761/3936 [20:51<00:58,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  60%|█████████████████▍           | 262/437 [00:43<00:28,  6.07it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3763/3936 [20:52<00:57,  3.00it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  60%|█████████████████▌           | 264/437 [00:43<00:28,  6.08it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3765/3936 [20:52<00:56,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  61%|█████████████████▋           | 266/437 [00:43<00:28,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3767/3936 [20:52<00:56,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  61%|█████████████████▊           | 268/437 [00:44<00:27,  6.11it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3769/3936 [20:53<00:55,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  62%|█████████████████▉           | 270/437 [00:44<00:27,  6.11it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3771/3936 [20:53<00:54,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  62%|██████████████████           | 272/437 [00:44<00:27,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3773/3936 [20:53<00:54,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  63%|██████████████████▏          | 274/437 [00:45<00:26,  6.07it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3775/3936 [20:54<00:53,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  63%|██████████████████▎          | 276/437 [00:45<00:26,  6.08it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3777/3936 [20:54<00:52,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  64%|██████████████████▍          | 278/437 [00:45<00:26,  6.08it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3779/3936 [20:54<00:52,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  64%|██████████████████▌          | 280/437 [00:46<00:25,  6.07it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3781/3936 [20:55<00:51,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  65%|██████████████████▋          | 282/437 [00:46<00:25,  6.07it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3783/3936 [20:55<00:50,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  65%|██████████████████▊          | 284/437 [00:46<00:25,  6.07it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3785/3936 [20:55<00:50,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  65%|██████████████████▉          | 286/437 [00:47<00:24,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3787/3936 [20:56<00:49,  3.01it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  66%|███████████████████          | 288/437 [00:47<00:24,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3789/3936 [20:56<00:48,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  66%|███████████████████▏         | 290/437 [00:47<00:24,  6.08it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3791/3936 [20:56<00:48,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  67%|███████████████████▍         | 292/437 [00:48<00:23,  6.06it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3793/3936 [20:57<00:47,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  67%|███████████████████▌         | 294/437 [00:48<00:23,  6.07it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3795/3936 [20:57<00:46,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  68%|███████████████████▋         | 296/437 [00:48<00:23,  6.09it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3797/3936 [20:57<00:46,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  68%|███████████████████▊         | 298/437 [00:49<00:22,  6.09it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3799/3936 [20:58<00:45,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  69%|███████████████████▉         | 300/437 [00:49<00:22,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3801/3936 [20:58<00:44,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  69%|████████████████████         | 302/437 [00:49<00:22,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3803/3936 [20:58<00:44,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  70%|████████████████████▏        | 304/437 [00:50<00:21,  6.08it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3805/3936 [20:59<00:43,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  70%|████████████████████▎        | 306/437 [00:50<00:21,  6.09it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3807/3936 [20:59<00:42,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  70%|████████████████████▍        | 308/437 [00:50<00:21,  6.08it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3809/3936 [20:59<00:42,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  71%|████████████████████▌        | 310/437 [00:51<00:20,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3811/3936 [21:00<00:41,  3.02it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  71%|████████████████████▋        | 312/437 [00:51<00:20,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3813/3936 [21:00<00:40,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  72%|████████████████████▊        | 314/437 [00:51<00:20,  6.09it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3815/3936 [21:00<00:39,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  72%|████████████████████▉        | 316/437 [00:52<00:19,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3817/3936 [21:01<00:39,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  73%|█████████████████████        | 318/437 [00:52<00:19,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3819/3936 [21:01<00:38,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  73%|█████████████████████▏       | 320/437 [00:52<00:19,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3821/3936 [21:01<00:37,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  74%|█████████████████████▎       | 322/437 [00:53<00:18,  6.11it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3823/3936 [21:02<00:37,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  74%|█████████████████████▌       | 324/437 [00:53<00:18,  6.11it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3825/3936 [21:02<00:36,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  75%|█████████████████████▋       | 326/437 [00:53<00:18,  6.10it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3827/3936 [21:02<00:35,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  75%|█████████████████████▊       | 328/437 [00:54<00:17,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3829/3936 [21:03<00:35,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  76%|█████████████████████▉       | 330/437 [00:54<00:17,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3831/3936 [21:03<00:34,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  76%|██████████████████████       | 332/437 [00:54<00:17,  6.08it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3833/3936 [21:03<00:33,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  76%|██████████████████████▏      | 334/437 [00:55<00:16,  6.06it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3835/3936 [21:04<00:33,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  77%|██████████████████████▎      | 336/437 [00:55<00:16,  6.07it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3837/3936 [21:04<00:32,  3.03it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  77%|██████████████████████▍      | 338/437 [00:55<00:16,  6.06it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3839/3936 [21:04<00:31,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  78%|██████████████████████▌      | 340/437 [00:56<00:15,  6.08it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3841/3936 [21:05<00:31,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  78%|██████████████████████▋      | 342/437 [00:56<00:15,  6.10it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3843/3936 [21:05<00:30,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  79%|██████████████████████▊      | 344/437 [00:56<00:15,  6.09it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3845/3936 [21:05<00:29,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  79%|██████████████████████▉      | 346/437 [00:57<00:14,  6.07it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3847/3936 [21:06<00:29,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  80%|███████████████████████      | 348/437 [00:57<00:14,  6.05it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3849/3936 [21:06<00:28,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  80%|███████████████████████▏     | 350/437 [00:57<00:14,  6.06it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3851/3936 [21:06<00:27,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  81%|███████████████████████▎     | 352/437 [00:58<00:14,  6.05it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3853/3936 [21:07<00:27,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  81%|███████████████████████▍     | 354/437 [00:58<00:13,  6.04it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3855/3936 [21:07<00:26,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  81%|███████████████████████▌     | 356/437 [00:58<00:13,  6.06it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3857/3936 [21:07<00:25,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  82%|███████████████████████▊     | 358/437 [00:59<00:13,  6.07it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3859/3936 [21:08<00:25,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  82%|███████████████████████▉     | 360/437 [00:59<00:12,  6.06it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3861/3936 [21:08<00:24,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  83%|████████████████████████     | 362/437 [00:59<00:12,  6.05it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3863/3936 [21:08<00:23,  3.04it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  83%|████████████████████████▏    | 364/437 [01:00<00:12,  6.08it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3865/3936 [21:09<00:23,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  84%|████████████████████████▎    | 366/437 [01:00<00:11,  6.06it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3867/3936 [21:09<00:22,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  84%|████████████████████████▍    | 368/437 [01:00<00:11,  6.04it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3869/3936 [21:09<00:21,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  85%|████████████████████████▌    | 370/437 [01:01<00:11,  6.05it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3871/3936 [21:10<00:21,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  85%|████████████████████████▋    | 372/437 [01:01<00:10,  6.07it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3873/3936 [21:10<00:20,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  86%|████████████████████████▊    | 374/437 [01:01<00:10,  6.04it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3875/3936 [21:10<00:20,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  86%|████████████████████████▉    | 376/437 [01:02<00:10,  6.04it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3877/3936 [21:11<00:19,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  86%|█████████████████████████    | 378/437 [01:02<00:09,  6.07it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3879/3936 [21:11<00:18,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  87%|█████████████████████████▏   | 380/437 [01:02<00:09,  6.08it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3881/3936 [21:11<00:18,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  87%|█████████████████████████▎   | 382/437 [01:03<00:09,  6.07it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3883/3936 [21:12<00:17,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  88%|█████████████████████████▍   | 384/437 [01:03<00:08,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3885/3936 [21:12<00:16,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  88%|█████████████████████████▌   | 386/437 [01:03<00:08,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3887/3936 [21:12<00:16,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  89%|█████████████████████████▋   | 388/437 [01:04<00:08,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3889/3936 [21:13<00:15,  3.05it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  89%|█████████████████████████▉   | 390/437 [01:04<00:07,  6.03it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3891/3936 [21:13<00:14,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  90%|██████████████████████████   | 392/437 [01:04<00:07,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3893/3936 [21:13<00:14,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  90%|██████████████████████████▏  | 394/437 [01:05<00:07,  6.07it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3895/3936 [21:13<00:13,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  91%|██████████████████████████▎  | 396/437 [01:05<00:06,  6.06it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3897/3936 [21:14<00:12,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  91%|██████████████████████████▍  | 398/437 [01:05<00:06,  6.04it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3899/3936 [21:14<00:12,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  92%|██████████████████████████▌  | 400/437 [01:06<00:06,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3901/3936 [21:14<00:11,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  92%|██████████████████████████▋  | 402/437 [01:06<00:05,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3903/3936 [21:15<00:10,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  92%|██████████████████████████▊  | 404/437 [01:06<00:05,  6.02it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3905/3936 [21:15<00:10,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  93%|██████████████████████████▉  | 406/437 [01:07<00:05,  6.04it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3907/3936 [21:15<00:09,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  93%|███████████████████████████  | 408/437 [01:07<00:04,  6.04it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3909/3936 [21:16<00:08,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  94%|███████████████████████████▏ | 410/437 [01:07<00:04,  6.03it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3911/3936 [21:16<00:08,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  94%|███████████████████████████▎ | 412/437 [01:08<00:04,  6.05it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3913/3936 [21:16<00:07,  3.06it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  95%|███████████████████████████▍ | 414/437 [01:08<00:03,  6.07it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3915/3936 [21:17<00:06,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  95%|███████████████████████████▌ | 416/437 [01:08<00:03,  6.04it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3917/3936 [21:17<00:06,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  96%|███████████████████████████▋ | 418/437 [01:08<00:03,  6.04it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3919/3936 [21:17<00:05,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  96%|███████████████████████████▊ | 420/437 [01:09<00:02,  6.07it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3921/3936 [21:18<00:04,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  97%|████████████████████████████ | 422/437 [01:09<00:02,  6.05it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3923/3936 [21:18<00:04,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  97%|████████████████████████████▏| 424/437 [01:09<00:02,  6.05it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3925/3936 [21:18<00:03,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  97%|████████████████████████████▎| 426/437 [01:10<00:01,  6.04it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3927/3936 [21:19<00:02,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  98%|████████████████████████████▍| 428/437 [01:10<00:01,  6.06it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3929/3936 [21:19<00:02,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  98%|████████████████████████████▌| 430/437 [01:10<00:01,  6.05it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3931/3936 [21:19<00:01,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  99%|████████████████████████████▋| 432/437 [01:11<00:00,  6.04it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3933/3936 [21:20<00:00,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating:  99%|████████████████████████████▊| 434/437 [01:11<00:00,  6.06it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3935/3936 [21:20<00:00,  3.07it/s, loss=3.43, v_num=0, val_loss\u001b[A\n",
      "Validating: 100%|████████████████████████████▉| 436/437 [01:11<00:00,  6.06it/s]\u001b[A\n",
      "Validating: 100%|█████████████████████████████| 437/437 [01:12<00:00,  6.58it/s]\u001b[AEpoch 0, global step 3498: val_loss reached 2.96854 (best 2.96854), saving model to \"/aiffel/aiffel/aiffelthon/KoGPT2-summarization/logs/model_chp/epoch=00-val_loss=2.969.ckpt\" as top 3\n",
      "INFO:lightning:Epoch 0, global step 3498: val_loss reached 2.96854 (best 2.96854), saving model to \"/aiffel/aiffel/aiffelthon/KoGPT2-summarization/logs/model_chp/epoch=00-val_loss=2.969.ckpt\" as top 3\n",
      "Epoch 0: 100%|█| 3936/3936 [21:23<00:00,  3.07it/s, loss=3.43, v_num=0, val_loss\n",
      "                                                                                \u001b[ASaving latest checkpoint...\n",
      "INFO:lightning:Saving latest checkpoint...\n",
      "Epoch 0: 100%|█| 3936/3936 [21:23<00:00,  3.07it/s, loss=3.43, v_num=0, val_loss\n"
     ]
    }
   ],
   "source": [
    "!python train_ptuning.py  --gradient_clip_val 1.0 --max_epochs 1 --default_root_dir logs  --gpus 1 --batch_size 4 --num_workers 4 --max_len 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab09132",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(checkpoint_path=None, lr=3e-05, warmup_ratio=0.1, model_path=None, train_file='data/train.tsv', test_file='data/test.tsv', batch_size=4, max_len=256, num_workers=4, logger=True, checkpoint_callback=True, default_root_dir='logs', gradient_clip_val=1.0, process_position=0, num_nodes=1, num_processes=1, gpus=1, auto_select_gpus=False, tpu_cores=<function _gpus_arg_default at 0x7fdcab1ad9d0>, log_gpu_memory=None, progress_bar_refresh_rate=1, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=1, min_epochs=1, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=True)\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n",
      "/opt/conda/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: Checkpoint directory logs exists and is not empty. With save_top_k=3, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:root:number of workers 4, data length 13994\n",
      "INFO:root:num_train_steps : 874\n",
      "INFO:root:num_warmup_steps : 87\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | GPT2LMHeadModel  | 125 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "INFO:lightning:\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | GPT2LMHeadModel  | 125 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "Epoch 0:  89%|▉| 3499/3936 [25:48<03:13,  2.26it/s, loss=2.56, v_num=2, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3501/3936 [25:48<03:12,  2.26it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   0%|▏                              | 2/437 [00:00<01:35,  4.54it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3503/3936 [25:48<03:11,  2.26it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   1%|▎                              | 4/437 [00:00<01:16,  5.70it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3505/3936 [25:48<03:10,  2.26it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   1%|▍                              | 6/437 [00:01<01:11,  6.06it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3507/3936 [25:49<03:09,  2.26it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   2%|▌                              | 8/437 [00:01<01:08,  6.24it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3509/3936 [25:49<03:08,  2.26it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   2%|▋                             | 10/437 [00:01<01:07,  6.36it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3511/3936 [25:49<03:07,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   3%|▊                             | 12/437 [00:02<01:06,  6.39it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3513/3936 [25:50<03:06,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   3%|▉                             | 14/437 [00:02<01:05,  6.41it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3515/3936 [25:50<03:05,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   4%|█                             | 16/437 [00:02<01:05,  6.41it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3517/3936 [25:50<03:04,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   4%|█▏                            | 18/437 [00:02<01:05,  6.41it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3519/3936 [25:51<03:03,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   5%|█▎                            | 20/437 [00:03<01:05,  6.40it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 3521/3936 [25:51<03:02,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   5%|█▌                            | 22/437 [00:03<01:04,  6.42it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3523/3936 [25:51<03:01,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   5%|█▋                            | 24/437 [00:03<01:04,  6.39it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3525/3936 [25:52<03:00,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   6%|█▊                            | 26/437 [00:04<01:03,  6.44it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3527/3936 [25:52<03:00,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   6%|█▉                            | 28/437 [00:04<01:03,  6.47it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3529/3936 [25:52<02:59,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   7%|██                            | 30/437 [00:04<01:03,  6.42it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3531/3936 [25:52<02:58,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   7%|██▏                           | 32/437 [00:05<01:03,  6.43it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3533/3936 [25:53<02:57,  2.27it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   8%|██▎                           | 34/437 [00:05<01:03,  6.38it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3535/3936 [25:53<02:56,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   8%|██▍                           | 36/437 [00:05<01:02,  6.40it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3537/3936 [25:53<02:55,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   9%|██▌                           | 38/437 [00:06<01:01,  6.46it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3539/3936 [25:54<02:54,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:   9%|██▋                           | 40/437 [00:06<01:01,  6.49it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3541/3936 [25:54<02:53,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  10%|██▉                           | 42/437 [00:06<01:00,  6.48it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3543/3936 [25:54<02:52,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  10%|███                           | 44/437 [00:06<01:00,  6.46it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3545/3936 [25:55<02:51,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  11%|███▏                          | 46/437 [00:07<01:00,  6.44it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3547/3936 [25:55<02:50,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  11%|███▎                          | 48/437 [00:07<01:00,  6.48it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3549/3936 [25:55<02:49,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  11%|███▍                          | 50/437 [00:07<00:59,  6.48it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3551/3936 [25:56<02:48,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  12%|███▌                          | 52/437 [00:08<00:59,  6.46it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3553/3936 [25:56<02:47,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  12%|███▋                          | 54/437 [00:08<00:59,  6.45it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3555/3936 [25:56<02:46,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  13%|███▊                          | 56/437 [00:08<00:58,  6.46it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3557/3936 [25:57<02:45,  2.28it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  13%|███▉                          | 58/437 [00:09<00:58,  6.44it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3559/3936 [25:57<02:44,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  14%|████                          | 60/437 [00:09<00:58,  6.49it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 3561/3936 [25:57<02:44,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  14%|████▎                         | 62/437 [00:09<00:58,  6.46it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3563/3936 [25:57<02:43,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  15%|████▍                         | 64/437 [00:10<00:57,  6.49it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3565/3936 [25:58<02:42,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  15%|████▌                         | 66/437 [00:10<00:57,  6.44it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3567/3936 [25:58<02:41,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  16%|████▋                         | 68/437 [00:10<00:57,  6.46it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3569/3936 [25:58<02:40,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  16%|████▊                         | 70/437 [00:11<00:56,  6.46it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3571/3936 [25:59<02:39,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  16%|████▉                         | 72/437 [00:11<00:56,  6.41it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3573/3936 [25:59<02:38,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  17%|█████                         | 74/437 [00:11<00:56,  6.39it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3575/3936 [25:59<02:37,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  17%|█████▏                        | 76/437 [00:11<00:56,  6.41it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3577/3936 [26:00<02:36,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  18%|█████▎                        | 78/437 [00:12<00:56,  6.41it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3579/3936 [26:00<02:35,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  18%|█████▍                        | 80/437 [00:12<00:55,  6.42it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3581/3936 [26:00<02:34,  2.29it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  19%|█████▋                        | 82/437 [00:12<00:55,  6.45it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3583/3936 [26:01<02:33,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  19%|█████▊                        | 84/437 [00:13<00:54,  6.44it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3585/3936 [26:01<02:32,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  20%|█████▉                        | 86/437 [00:13<00:54,  6.46it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3587/3936 [26:01<02:31,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  20%|██████                        | 88/437 [00:13<00:54,  6.43it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3589/3936 [26:01<02:31,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  21%|██████▏                       | 90/437 [00:14<00:54,  6.42it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3591/3936 [26:02<02:30,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  21%|██████▎                       | 92/437 [00:14<00:53,  6.42it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3593/3936 [26:02<02:29,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  22%|██████▍                       | 94/437 [00:14<00:53,  6.42it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3595/3936 [26:02<02:28,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  22%|██████▌                       | 96/437 [00:15<00:53,  6.43it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3597/3936 [26:03<02:27,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  22%|██████▋                       | 98/437 [00:15<00:52,  6.42it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3599/3936 [26:03<02:26,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  23%|██████▋                      | 100/437 [00:15<00:52,  6.42it/s]\u001b[A\n",
      "Epoch 0:  91%|▉| 3601/3936 [26:03<02:25,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  23%|██████▊                      | 102/437 [00:16<00:51,  6.45it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3603/3936 [26:04<02:24,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  24%|██████▉                      | 104/437 [00:16<00:51,  6.44it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3605/3936 [26:04<02:23,  2.30it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  24%|███████                      | 106/437 [00:16<00:51,  6.48it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3607/3936 [26:04<02:22,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  25%|███████▏                     | 108/437 [00:16<00:51,  6.44it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3609/3936 [26:05<02:21,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  25%|███████▎                     | 110/437 [00:17<00:50,  6.47it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3611/3936 [26:05<02:20,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  26%|███████▍                     | 112/437 [00:17<00:50,  6.49it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3613/3936 [26:05<02:19,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  26%|███████▌                     | 114/437 [00:17<00:49,  6.46it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3615/3936 [26:06<02:19,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  27%|███████▋                     | 116/437 [00:18<00:49,  6.45it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3617/3936 [26:06<02:18,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  27%|███████▊                     | 118/437 [00:18<00:49,  6.45it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3619/3936 [26:06<02:17,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  27%|███████▉                     | 120/437 [00:18<00:49,  6.46it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3621/3936 [26:06<02:16,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  28%|████████                     | 122/437 [00:19<00:48,  6.45it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3623/3936 [26:07<02:15,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  28%|████████▏                    | 124/437 [00:19<00:48,  6.45it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3625/3936 [26:07<02:14,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  29%|████████▎                    | 126/437 [00:19<00:48,  6.47it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3627/3936 [26:07<02:13,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  29%|████████▍                    | 128/437 [00:20<00:47,  6.45it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3629/3936 [26:08<02:12,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  30%|████████▋                    | 130/437 [00:20<00:47,  6.46it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3631/3936 [26:08<02:11,  2.31it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  30%|████████▊                    | 132/437 [00:20<00:47,  6.47it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3633/3936 [26:08<02:10,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  31%|████████▉                    | 134/437 [00:20<00:47,  6.40it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3635/3936 [26:09<02:09,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  31%|█████████                    | 136/437 [00:21<00:47,  6.40it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3637/3936 [26:09<02:09,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  32%|█████████▏                   | 138/437 [00:21<00:46,  6.40it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 3639/3936 [26:09<02:08,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  32%|█████████▎                   | 140/437 [00:21<00:46,  6.40it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3641/3936 [26:10<02:07,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  32%|█████████▍                   | 142/437 [00:22<00:45,  6.41it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3643/3936 [26:10<02:06,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  33%|█████████▌                   | 144/437 [00:22<00:45,  6.41it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3645/3936 [26:10<02:05,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  33%|█████████▋                   | 146/437 [00:22<00:45,  6.43it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3647/3936 [26:10<02:04,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  34%|█████████▊                   | 148/437 [00:23<00:44,  6.46it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3649/3936 [26:11<02:03,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  34%|█████████▉                   | 150/437 [00:23<00:44,  6.47it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3651/3936 [26:11<02:02,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  35%|██████████                   | 152/437 [00:23<00:44,  6.45it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3653/3936 [26:11<02:01,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  35%|██████████▏                  | 154/437 [00:24<00:44,  6.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  93%|▉| 3655/3936 [26:12<02:00,  2.32it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  36%|██████████▎                  | 156/437 [00:24<00:43,  6.43it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3657/3936 [26:12<01:59,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  36%|██████████▍                  | 158/437 [00:24<00:43,  6.39it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3659/3936 [26:12<01:59,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  37%|██████████▌                  | 160/437 [00:25<00:43,  6.42it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3661/3936 [26:13<01:58,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  37%|██████████▊                  | 162/437 [00:25<00:42,  6.44it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3663/3936 [26:13<01:57,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  38%|██████████▉                  | 164/437 [00:25<00:42,  6.48it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3665/3936 [26:13<01:56,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  38%|███████████                  | 166/437 [00:25<00:42,  6.43it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3667/3936 [26:14<01:55,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  38%|███████████▏                 | 168/437 [00:26<00:41,  6.45it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3669/3936 [26:14<01:54,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  39%|███████████▎                 | 170/437 [00:26<00:41,  6.49it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3671/3936 [26:14<01:53,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  39%|███████████▍                 | 172/437 [00:26<00:41,  6.43it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3673/3936 [26:15<01:52,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  40%|███████████▌                 | 174/437 [00:27<00:40,  6.43it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3675/3936 [26:15<01:51,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  40%|███████████▋                 | 176/437 [00:27<00:40,  6.47it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3677/3936 [26:15<01:50,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  41%|███████████▊                 | 178/437 [00:27<00:39,  6.48it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 3679/3936 [26:15<01:50,  2.33it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  41%|███████████▉                 | 180/437 [00:28<00:40,  6.42it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3681/3936 [26:16<01:49,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  42%|████████████                 | 182/437 [00:28<00:39,  6.47it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3683/3936 [26:16<01:48,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  42%|████████████▏                | 184/437 [00:28<00:39,  6.47it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3685/3936 [26:16<01:47,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  43%|████████████▎                | 186/437 [00:29<00:38,  6.52it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3687/3936 [26:17<01:46,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  43%|████████████▍                | 188/437 [00:29<00:38,  6.47it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3689/3936 [26:17<01:45,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  43%|████████████▌                | 190/437 [00:29<00:38,  6.47it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3691/3936 [26:17<01:44,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  44%|████████████▋                | 192/437 [00:29<00:38,  6.44it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3693/3936 [26:18<01:43,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  44%|████████████▊                | 194/437 [00:30<00:37,  6.40it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3695/3936 [26:18<01:42,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  45%|█████████████                | 196/437 [00:30<00:37,  6.45it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3697/3936 [26:18<01:42,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  45%|█████████████▏               | 198/437 [00:30<00:37,  6.44it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3699/3936 [26:19<01:41,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  46%|█████████████▎               | 200/437 [00:31<00:36,  6.42it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3701/3936 [26:19<01:40,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  46%|█████████████▍               | 202/437 [00:31<00:36,  6.45it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3703/3936 [26:19<01:39,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  47%|█████████████▌               | 204/437 [00:31<00:36,  6.43it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3705/3936 [26:19<01:38,  2.34it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  47%|█████████████▋               | 206/437 [00:32<00:35,  6.47it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3707/3936 [26:20<01:37,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  48%|█████████████▊               | 208/437 [00:32<00:35,  6.43it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3709/3936 [26:20<01:36,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  48%|█████████████▉               | 210/437 [00:32<00:35,  6.41it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3711/3936 [26:20<01:35,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  49%|██████████████               | 212/437 [00:33<00:35,  6.41it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3713/3936 [26:21<01:34,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  49%|██████████████▏              | 214/437 [00:33<00:34,  6.44it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3715/3936 [26:21<01:34,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  49%|██████████████▎              | 216/437 [00:33<00:34,  6.44it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3717/3936 [26:21<01:33,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  50%|██████████████▍              | 218/437 [00:33<00:33,  6.45it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 3719/3936 [26:22<01:32,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  50%|██████████████▌              | 220/437 [00:34<00:33,  6.42it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3721/3936 [26:22<01:31,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  51%|██████████████▋              | 222/437 [00:34<00:33,  6.41it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3723/3936 [26:22<01:30,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  51%|██████████████▊              | 224/437 [00:34<00:33,  6.45it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3725/3936 [26:23<01:29,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  52%|██████████████▉              | 226/437 [00:35<00:32,  6.40it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3727/3936 [26:23<01:28,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  52%|███████████████▏             | 228/437 [00:35<00:32,  6.44it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3729/3936 [26:23<01:27,  2.35it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  53%|███████████████▎             | 230/437 [00:35<00:32,  6.44it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3731/3936 [26:24<01:27,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  53%|███████████████▍             | 232/437 [00:36<00:31,  6.46it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3733/3936 [26:24<01:26,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  54%|███████████████▌             | 234/437 [00:36<00:31,  6.44it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3735/3936 [26:24<01:25,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  54%|███████████████▋             | 236/437 [00:36<00:31,  6.42it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3737/3936 [26:24<01:24,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  54%|███████████████▊             | 238/437 [00:37<00:30,  6.44it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3739/3936 [26:25<01:23,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  55%|███████████████▉             | 240/437 [00:37<00:30,  6.44it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3741/3936 [26:25<01:22,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  55%|████████████████             | 242/437 [00:37<00:30,  6.45it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3743/3936 [26:25<01:21,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  56%|████████████████▏            | 244/437 [00:38<00:30,  6.43it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3745/3936 [26:26<01:20,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  56%|████████████████▎            | 246/437 [00:38<00:29,  6.41it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3747/3936 [26:26<01:20,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  57%|████████████████▍            | 248/437 [00:38<00:29,  6.39it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3749/3936 [26:26<01:19,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  57%|████████████████▌            | 250/437 [00:38<00:29,  6.43it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3751/3936 [26:27<01:18,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  58%|████████████████▋            | 252/437 [00:39<00:28,  6.43it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3753/3936 [26:27<01:17,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  58%|████████████████▊            | 254/437 [00:39<00:28,  6.43it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3755/3936 [26:27<01:16,  2.36it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  59%|████████████████▉            | 256/437 [00:39<00:28,  6.46it/s]\u001b[A\n",
      "Epoch 0:  95%|▉| 3757/3936 [26:28<01:15,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  59%|█████████████████            | 258/437 [00:40<00:27,  6.46it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3759/3936 [26:28<01:14,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  59%|█████████████████▎           | 260/437 [00:40<00:27,  6.45it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3761/3936 [26:28<01:13,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  60%|█████████████████▍           | 262/437 [00:40<00:27,  6.44it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3763/3936 [26:28<01:13,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  60%|█████████████████▌           | 264/437 [00:41<00:26,  6.44it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3765/3936 [26:29<01:12,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  61%|█████████████████▋           | 266/437 [00:41<00:26,  6.48it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3767/3936 [26:29<01:11,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  61%|█████████████████▊           | 268/437 [00:41<00:26,  6.47it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3769/3936 [26:29<01:10,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  62%|█████████████████▉           | 270/437 [00:42<00:25,  6.43it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3771/3936 [26:30<01:09,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  62%|██████████████████           | 272/437 [00:42<00:25,  6.48it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3773/3936 [26:30<01:08,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  63%|██████████████████▏          | 274/437 [00:42<00:25,  6.44it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3775/3936 [26:30<01:07,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  63%|██████████████████▎          | 276/437 [00:43<00:24,  6.46it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3777/3936 [26:31<01:06,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  64%|██████████████████▍          | 278/437 [00:43<00:24,  6.48it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3779/3936 [26:31<01:06,  2.37it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  64%|██████████████████▌          | 280/437 [00:43<00:24,  6.45it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3781/3936 [26:31<01:05,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  65%|██████████████████▋          | 282/437 [00:43<00:23,  6.48it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3783/3936 [26:32<01:04,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  65%|██████████████████▊          | 284/437 [00:44<00:23,  6.45it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3785/3936 [26:32<01:03,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  65%|██████████████████▉          | 286/437 [00:44<00:23,  6.47it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3787/3936 [26:32<01:02,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  66%|███████████████████          | 288/437 [00:44<00:22,  6.50it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3789/3936 [26:33<01:01,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  66%|███████████████████▏         | 290/437 [00:45<00:22,  6.46it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3791/3936 [26:33<01:00,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  67%|███████████████████▍         | 292/437 [00:45<00:22,  6.43it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3793/3936 [26:33<01:00,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  67%|███████████████████▌         | 294/437 [00:45<00:21,  6.51it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3795/3936 [26:33<00:59,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  68%|███████████████████▋         | 296/437 [00:46<00:21,  6.44it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 3797/3936 [26:34<00:58,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  68%|███████████████████▊         | 298/437 [00:46<00:21,  6.44it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3799/3936 [26:34<00:57,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  69%|███████████████████▉         | 300/437 [00:46<00:21,  6.48it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3801/3936 [26:34<00:56,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  69%|████████████████████         | 302/437 [00:47<00:20,  6.47it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3803/3936 [26:35<00:55,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  70%|████████████████████▏        | 304/437 [00:47<00:20,  6.46it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3805/3936 [26:35<00:54,  2.38it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  70%|████████████████████▎        | 306/437 [00:47<00:20,  6.46it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3807/3936 [26:35<00:54,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  70%|████████████████████▍        | 308/437 [00:47<00:20,  6.43it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3809/3936 [26:36<00:53,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  71%|████████████████████▌        | 310/437 [00:48<00:19,  6.44it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3811/3936 [26:36<00:52,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  71%|████████████████████▋        | 312/437 [00:48<00:19,  6.45it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3813/3936 [26:36<00:51,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  72%|████████████████████▊        | 314/437 [00:48<00:19,  6.45it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3815/3936 [26:37<00:50,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  72%|████████████████████▉        | 316/437 [00:49<00:18,  6.42it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3817/3936 [26:37<00:49,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  73%|█████████████████████        | 318/437 [00:49<00:18,  6.46it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3819/3936 [26:37<00:48,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  73%|█████████████████████▏       | 320/437 [00:49<00:18,  6.42it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3821/3936 [26:37<00:48,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  74%|█████████████████████▎       | 322/437 [00:50<00:17,  6.43it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3823/3936 [26:38<00:47,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  74%|█████████████████████▌       | 324/437 [00:50<00:17,  6.44it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3825/3936 [26:38<00:46,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  75%|█████████████████████▋       | 326/437 [00:50<00:17,  6.47it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3827/3936 [26:38<00:45,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  75%|█████████████████████▊       | 328/437 [00:51<00:16,  6.47it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3829/3936 [26:39<00:44,  2.39it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  76%|█████████████████████▉       | 330/437 [00:51<00:16,  6.48it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3831/3936 [26:39<00:43,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  76%|██████████████████████       | 332/437 [00:51<00:16,  6.49it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3833/3936 [26:39<00:42,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  76%|██████████████████████▏      | 334/437 [00:51<00:15,  6.48it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3835/3936 [26:40<00:42,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  77%|██████████████████████▎      | 336/437 [00:52<00:15,  6.41it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 3837/3936 [26:40<00:41,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  77%|██████████████████████▍      | 338/437 [00:52<00:15,  6.39it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3839/3936 [26:40<00:40,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  78%|██████████████████████▌      | 340/437 [00:52<00:15,  6.42it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3841/3936 [26:41<00:39,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  78%|██████████████████████▋      | 342/437 [00:53<00:14,  6.43it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3843/3936 [26:41<00:38,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  79%|██████████████████████▊      | 344/437 [00:53<00:14,  6.46it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3845/3936 [26:41<00:37,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  79%|██████████████████████▉      | 346/437 [00:53<00:14,  6.45it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3847/3936 [26:42<00:37,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  80%|███████████████████████      | 348/437 [00:54<00:13,  6.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  98%|▉| 3849/3936 [26:42<00:36,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  80%|███████████████████████▏     | 350/437 [00:54<00:13,  6.42it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3851/3936 [26:42<00:35,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  81%|███████████████████████▎     | 352/437 [00:54<00:13,  6.44it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3853/3936 [26:42<00:34,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  81%|███████████████████████▍     | 354/437 [00:55<00:12,  6.47it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3855/3936 [26:43<00:33,  2.40it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  81%|███████████████████████▌     | 356/437 [00:55<00:12,  6.49it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3857/3936 [26:43<00:32,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  82%|███████████████████████▊     | 358/437 [00:55<00:12,  6.49it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3859/3936 [26:43<00:32,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  82%|███████████████████████▉     | 360/437 [00:56<00:11,  6.50it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3861/3936 [26:44<00:31,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  83%|████████████████████████     | 362/437 [00:56<00:11,  6.46it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3863/3936 [26:44<00:30,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  83%|████████████████████████▏    | 364/437 [00:56<00:11,  6.43it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3865/3936 [26:44<00:29,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  84%|████████████████████████▎    | 366/437 [00:56<00:11,  6.44it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3867/3936 [26:45<00:28,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  84%|████████████████████████▍    | 368/437 [00:57<00:10,  6.41it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3869/3936 [26:45<00:27,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  85%|████████████████████████▌    | 370/437 [00:57<00:10,  6.44it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3871/3936 [26:45<00:26,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  85%|████████████████████████▋    | 372/437 [00:57<00:10,  6.42it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3873/3936 [26:46<00:26,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  86%|████████████████████████▊    | 374/437 [00:58<00:09,  6.44it/s]\u001b[A\n",
      "Epoch 0:  98%|▉| 3875/3936 [26:46<00:25,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  86%|████████████████████████▉    | 376/437 [00:58<00:09,  6.45it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3877/3936 [26:46<00:24,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  86%|█████████████████████████    | 378/437 [00:58<00:09,  6.46it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3879/3936 [26:46<00:23,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  87%|█████████████████████████▏   | 380/437 [00:59<00:08,  6.44it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3881/3936 [26:47<00:22,  2.41it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  87%|█████████████████████████▎   | 382/437 [00:59<00:08,  6.46it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3883/3936 [26:47<00:21,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  88%|█████████████████████████▍   | 384/437 [00:59<00:08,  6.46it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3885/3936 [26:47<00:21,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  88%|█████████████████████████▌   | 386/437 [01:00<00:07,  6.40it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3887/3936 [26:48<00:20,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  89%|█████████████████████████▋   | 388/437 [01:00<00:07,  6.45it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3889/3936 [26:48<00:19,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  89%|█████████████████████████▉   | 390/437 [01:00<00:07,  6.49it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3891/3936 [26:48<00:18,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  90%|██████████████████████████   | 392/437 [01:00<00:06,  6.46it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3893/3936 [26:49<00:17,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  90%|██████████████████████████▏  | 394/437 [01:01<00:06,  6.44it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3895/3936 [26:49<00:16,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  91%|██████████████████████████▎  | 396/437 [01:01<00:06,  6.46it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3897/3936 [26:49<00:16,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  91%|██████████████████████████▍  | 398/437 [01:01<00:06,  6.49it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3899/3936 [26:50<00:15,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  92%|██████████████████████████▌  | 400/437 [01:02<00:05,  6.49it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3901/3936 [26:50<00:14,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  92%|██████████████████████████▋  | 402/437 [01:02<00:05,  6.50it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3903/3936 [26:50<00:13,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  92%|██████████████████████████▊  | 404/437 [01:02<00:05,  6.45it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3905/3936 [26:50<00:12,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  93%|██████████████████████████▉  | 406/437 [01:03<00:04,  6.45it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3907/3936 [26:51<00:11,  2.42it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  93%|███████████████████████████  | 408/437 [01:03<00:04,  6.43it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3909/3936 [26:51<00:11,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  94%|███████████████████████████▏ | 410/437 [01:03<00:04,  6.42it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3911/3936 [26:51<00:10,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  94%|███████████████████████████▎ | 412/437 [01:04<00:03,  6.42it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3913/3936 [26:52<00:09,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  95%|███████████████████████████▍ | 414/437 [01:04<00:03,  6.44it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 3915/3936 [26:52<00:08,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  95%|███████████████████████████▌ | 416/437 [01:04<00:03,  6.45it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3917/3936 [26:52<00:07,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  96%|███████████████████████████▋ | 418/437 [01:05<00:02,  6.44it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3919/3936 [26:53<00:06,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  96%|███████████████████████████▊ | 420/437 [01:05<00:02,  6.45it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3921/3936 [26:53<00:06,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  97%|████████████████████████████ | 422/437 [01:05<00:02,  6.46it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3923/3936 [26:53<00:05,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  97%|████████████████████████████▏| 424/437 [01:05<00:02,  6.45it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3925/3936 [26:54<00:04,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  97%|████████████████████████████▎| 426/437 [01:06<00:01,  6.48it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3927/3936 [26:54<00:03,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  98%|████████████████████████████▍| 428/437 [01:06<00:01,  6.46it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3929/3936 [26:54<00:02,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  98%|████████████████████████████▌| 430/437 [01:06<00:01,  6.49it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3931/3936 [26:55<00:02,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  99%|████████████████████████████▋| 432/437 [01:07<00:00,  6.45it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3933/3936 [26:55<00:01,  2.43it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating:  99%|████████████████████████████▊| 434/437 [01:07<00:00,  6.46it/s]\u001b[A\n",
      "Epoch 0: 100%|▉| 3935/3936 [26:55<00:00,  2.44it/s, loss=2.56, v_num=2, val_loss\u001b[A\n",
      "Validating: 100%|████████████████████████████▉| 436/437 [01:07<00:00,  6.45it/s]\u001b[A\n",
      "Validating: 100%|█████████████████████████████| 437/437 [01:07<00:00,  7.03it/s]\u001b[AEpoch 0, global step 3498: val_loss reached 2.40468 (best 2.40468), saving model to \"/aiffel/aiffel/aiffelthon/KoGPT2-summarization/logs/model_chp/epoch=00-val_loss=2.405.ckpt\" as top 3\n",
      "INFO:lightning:Epoch 0, global step 3498: val_loss reached 2.40468 (best 2.40468), saving model to \"/aiffel/aiffel/aiffelthon/KoGPT2-summarization/logs/model_chp/epoch=00-val_loss=2.405.ckpt\" as top 3\n",
      "Epoch 0: 100%|█| 3936/3936 [27:18<00:00,  2.40it/s, loss=2.56, v_num=2, val_loss\n",
      "                                                                                \u001b[ASaving latest checkpoint...\n",
      "INFO:lightning:Saving latest checkpoint...\n",
      "Epoch 0: 100%|█| 3936/3936 [27:18<00:00,  2.40it/s, loss=2.56, v_num=2, val_loss\n"
     ]
    }
   ],
   "source": [
    "!python train.py  --gradient_clip_val 1.0 --max_epochs 1 --default_root_dir logs  --gpus 1 --batch_size 4 --num_workers 4 --max_len 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20bb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "import re\n",
    "import pandas as pd\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (.) 제거\n",
    "    sentence = re.sub(r'[ㄱ-ㅎㅏ-ㅣ.,?!]+[/ㄱ-ㅎㅏ-ㅣ.,?!]', '', sentence) # 여러개 자음, 모음, 구두점에서 마지막 1개만 남긴다\n",
    "    sentence = re.sub(\"[^가-힣a-z0-9-.,!?]\", \" \", sentence) # 지정한 문자 제외 공백으로 전환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
    "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9a766d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/aiffel/aiffel/aiffelthon/KoGPT2-summarization/data/train.tsv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c59ccdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/aiffel/aiffel/aiffelthon/KoGPT2-summarization/data/test.tsv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "620fedbb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9effd65e-e18f-5510-8866-d6a677314c9c</td>\n",
       "      <td>웅 , 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 ...</td>\n",
       "      <td>팀장님이 출장 가서 머물 숙소를 계속해서 더 싼 데로 하게 한다고 이야기하고 있다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>49b9f9b7-a79d-5283-9553-95b8f156ff90</td>\n",
       "      <td>너는 잘가라회사 선택 잘해 , 알겠어 많이 힘들구나 나도 이제 이력서쓰고 영어도 해...</td>\n",
       "      <td>이제 이력서를 쓰고 영어도 해야 한다고 해서 첫 회사를 잘 들어가라고 했다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>df6b6bac-648b-5d32-86a3-9b8b215e5f95</td>\n",
       "      <td>느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 , 그러면서 , 샘 여기있었...</td>\n",
       "      <td>느낌상 대통령까지는 아니고 오시면 여사님 정도 오시지 않을까라며 이에 대해 이야기하...</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3043293f-7bb5-5edb-9b1f-85120e305c3d</td>\n",
       "      <td>숨만수이 도 숨만쉬어도 100 이내 , 한달안에 일 무조건 해야대 , 아 딱한달 ,...</td>\n",
       "      <td>한 달 안에 무조건 일을 시작해서 돈을 벌어야 한다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2b9b9c39-2721-50e6-af3e-e5c00138f43d</td>\n",
       "      <td>목요일은 외근이구 금요일은 출장 , 금요일이 당진이양? , 아닝아닝 10일이 당진이...</td>\n",
       "      <td>목요일에 외근이고 금요일에 출장인데 당진은 10일에 간다.</td>\n",
       "      <td>일과 직업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1741</td>\n",
       "      <td>b03b9ad0-62fa-54a5-b552-69049bd642ee</td>\n",
       "      <td>엄마 점심식사 뭐먹었어요 , 우린 중국집 시켜먹었다 , 오오 짜장면 탕수육?이에요 ...</td>\n",
       "      <td>엄마에게 오늘 점심 뭐 먹었냐고 묻고 엄마가 중국집에서 볶음밥, 잡채밥 시켜 먹었다...</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1742</td>\n",
       "      <td>ec83f40a-3c01-581d-962c-80fd62a5c888</td>\n",
       "      <td>매운거 , 담에 점심 엽떡 , 자신있음 , 엽떡 먹는 사람 , 오 저색기 또지랄이네...</td>\n",
       "      <td>엽떡 제일 매운맛을 3명에서 도전하기로 했다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1743</td>\n",
       "      <td>2b8dad32-cb6a-5d2a-89c4-06ba5f8dc8f8</td>\n",
       "      <td>아 술마시고싶다 취할줄알았는데 , 누룩오자 누룩 군고구마막걸리 존맛임 고구마케이크 ...</td>\n",
       "      <td>군고구마막걸리가 맛있다고 하니 빨리 마셔보고 싶다고 한다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1744</td>\n",
       "      <td>bd803ef5-c166-54ad-8d96-ac73fb055b3d</td>\n",
       "      <td>종촌동에서 뭘 주워먹어야겠다 어른들 저녁먹고 가신대 뭐사먹지 , 근처에 뭐있나요 국...</td>\n",
       "      <td>어른들이 저녁 먹고 가신다고 해서 뭘 사 먹을까 하니 근처에 국수나무가 맛있다고 한다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>1745</td>\n",
       "      <td>feb1cb05-67c9-5638-80d4-ca2b1c8f4ef0</td>\n",
       "      <td>오늘은 맛있는 게 먹고싶네요 , 집에가서 먹어염 , , 얼른가야먹을텐데 드디어 배가...</td>\n",
       "      <td>아까는 김밥을 사 먹으려고 했지만 지금은 맛있는 게먹고 싶어졌다.</td>\n",
       "      <td>식음료</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1746 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                    Id  \\\n",
       "0              0  9effd65e-e18f-5510-8866-d6a677314c9c   \n",
       "1              1  49b9f9b7-a79d-5283-9553-95b8f156ff90   \n",
       "2              2  df6b6bac-648b-5d32-86a3-9b8b215e5f95   \n",
       "3              3  3043293f-7bb5-5edb-9b1f-85120e305c3d   \n",
       "4              4  2b9b9c39-2721-50e6-af3e-e5c00138f43d   \n",
       "...          ...                                   ...   \n",
       "1741        1741  b03b9ad0-62fa-54a5-b552-69049bd642ee   \n",
       "1742        1742  ec83f40a-3c01-581d-962c-80fd62a5c888   \n",
       "1743        1743  2b8dad32-cb6a-5d2a-89c4-06ba5f8dc8f8   \n",
       "1744        1744  bd803ef5-c166-54ad-8d96-ac73fb055b3d   \n",
       "1745        1745  feb1cb05-67c9-5638-80d4-ca2b1c8f4ef0   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     웅 , 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 ...   \n",
       "1     너는 잘가라회사 선택 잘해 , 알겠어 많이 힘들구나 나도 이제 이력서쓰고 영어도 해...   \n",
       "2     느낌상 대통령까지는 아니고 오시면 여사님정도오시지않을까 , 그러면서 , 샘 여기있었...   \n",
       "3     숨만수이 도 숨만쉬어도 100 이내 , 한달안에 일 무조건 해야대 , 아 딱한달 ,...   \n",
       "4     목요일은 외근이구 금요일은 출장 , 금요일이 당진이양? , 아닝아닝 10일이 당진이...   \n",
       "...                                                 ...   \n",
       "1741  엄마 점심식사 뭐먹었어요 , 우린 중국집 시켜먹었다 , 오오 짜장면 탕수육?이에요 ...   \n",
       "1742  매운거 , 담에 점심 엽떡 , 자신있음 , 엽떡 먹는 사람 , 오 저색기 또지랄이네...   \n",
       "1743  아 술마시고싶다 취할줄알았는데 , 누룩오자 누룩 군고구마막걸리 존맛임 고구마케이크 ...   \n",
       "1744  종촌동에서 뭘 주워먹어야겠다 어른들 저녁먹고 가신대 뭐사먹지 , 근처에 뭐있나요 국...   \n",
       "1745  오늘은 맛있는 게 먹고싶네요 , 집에가서 먹어염 , , 얼른가야먹을텐데 드디어 배가...   \n",
       "\n",
       "                                                Summary Category  \n",
       "0        팀장님이 출장 가서 머물 숙소를 계속해서 더 싼 데로 하게 한다고 이야기하고 있다.    일과 직업  \n",
       "1            이제 이력서를 쓰고 영어도 해야 한다고 해서 첫 회사를 잘 들어가라고 했다.    일과 직업  \n",
       "2     느낌상 대통령까지는 아니고 오시면 여사님 정도 오시지 않을까라며 이에 대해 이야기하...    일과 직업  \n",
       "3                         한 달 안에 무조건 일을 시작해서 돈을 벌어야 한다.    일과 직업  \n",
       "4                      목요일에 외근이고 금요일에 출장인데 당진은 10일에 간다.    일과 직업  \n",
       "...                                                 ...      ...  \n",
       "1741  엄마에게 오늘 점심 뭐 먹었냐고 묻고 엄마가 중국집에서 볶음밥, 잡채밥 시켜 먹었다...      식음료  \n",
       "1742                          엽떡 제일 매운맛을 3명에서 도전하기로 했다.      식음료  \n",
       "1743                   군고구마막걸리가 맛있다고 하니 빨리 마셔보고 싶다고 한다.      식음료  \n",
       "1744   어른들이 저녁 먹고 가신다고 해서 뭘 사 먹을까 하니 근처에 국수나무가 맛있다고 한다.      식음료  \n",
       "1745               아까는 김밥을 사 먹으려고 했지만 지금은 맛있는 게먹고 싶어졌다.      식음료  \n",
       "\n",
       "[1746 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b02888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13994/13994 [00:00<00:00, 31768.22it/s]\n",
      "100%|██████████| 13994/13994 [00:00<00:00, 94756.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전처리 적용\n",
    "clean_text_val = []\n",
    "\n",
    "for s in tqdm(train['Text']):\n",
    "    clean_text_val.append(preprocess_sentence(s))\n",
    "\n",
    "train['Text'] = clean_text_val\n",
    "\n",
    "clean_headlines_val = []\n",
    "\n",
    "for s in tqdm(train['Summary']):\n",
    "    clean_headlines_val.append(preprocess_sentence(s))\n",
    "\n",
    "train['Summary'] = clean_headlines_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6507e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#from train_ptuning import KoGPTConditionalGeneration\n",
    "from train import KoGPTConditionalGeneration\n",
    "from utils import generate_next_token\n",
    "path = '/aiffel/aiffel/aiffelthon/KoGPT2-summarization/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e847365",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_file = path+'/tb_logs/default/version_2/hparams.yaml'\n",
    "with open(hparams_file) as f:\n",
    "    hparams = yaml.full_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45fb5a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "inf = KoGPTConditionalGeneration.load_from_checkpoint(path+'/model_chp/epoch=00-val_loss=2.405.ckpt', hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187f0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = inf.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65849338",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Text = list(test['Text'])\n",
    "Real_Sum = list(test['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "930bff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1746/1746 [08:26<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# 요약 결과 만들기\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "my_summaries=[]\n",
    "tensor = []\n",
    "SUMMARY = '<unused1>'\n",
    "PTUNING = '<unused2>'\n",
    "EOS = '</s>'\n",
    "\n",
    "for text in tqdm(Input_Text):\n",
    "    input_ids = text\n",
    "    input_tokens = tokenizer.encode(PTUNING)* 10 + tokenizer.encode(text) + tokenizer.encode(SUMMARY)\n",
    "    input_tensor = torch.tensor(input_tokens).unsqueeze(0)\n",
    "    eos_id = tokenizer.encode(EOS)\n",
    "    #my_summaries.append(input_tensor)\n",
    "    #while True:\n",
    "    pred = inf.model(input_tensor)\n",
    "    #next_token = generate_next_token(pred.logits, temperature=1.0, top_p=0.8)\n",
    "    next_token = generate_next_token(pred.logits, temperature=1.0, top_p=0.92)\n",
    "\n",
    "    if next_token.item() == eos_id:\n",
    "        break\n",
    "    else:\n",
    "        input_tensor = torch.cat([input_tensor, next_token.unsqueeze(0)],1)\n",
    "\n",
    "    tensor.append(input_tensor)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26bb5fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1746/1746 [00:00<00:00, 89273.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for ten in tqdm(tensor):\n",
    "    summary = tokenizer.decode(ten[0][0]).split('<unused1>')[-1].strip()\n",
    "\n",
    "    my_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee319811",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<unused2><unused2><unused2><unused2><unused2><unused2><unused2><unused2><unused2><unused2> ['오늘은 맛있는 게 먹고싶네요', '집에가서 먹어염....', 'ㅜㅜ ', '얼른가야먹을텐데... 드디어 배가고파졌어요?? ᄏᄏᄏᄏ', 'ᄏᄏᄏᄏᄏ 근데 아까는 아 김밥 사먹어야지 했는데 지금은 또 아니에요', '김밥먹어여,,,,']<unused1> 아\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ten[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd91b0da",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['웅', '영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 엄청 싸워서', '웅 흥 4개월가는거도아니고 3일가는데 좀해주지 거 얼마한다구', '내말이... 아니 해봤자 3일 다 합해도 몇만원 차이인데 너무해 그때는 2일이었는데도 만원 더 싼데에서 자꾸 자라고... 넘 시러..', '일단']\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "33caeb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_tensor[0]).split('<unused1>')[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b87d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY = '<unused1>'\n",
    "PTUNING = '<unused2>'\n",
    "EOS = '</s>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41fa4e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'웅 , 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 엄청 싸워서 , 웅 흥 4개월가는거도아니고 3일가는데 좀해주지 거 얼마한다구 , 내말이 아니 해봤자 3일 다 합해도 몇만원 차이인데 너무해 그때는 2일이었는데도 만원 더 싼데에서 자꾸 자라고 넘 시러 , 일단'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef33c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"웅 , 영업팀과장님이 보내줬는데 팀장님이 해줄지 모르겠다 저번에 부산갈때도 숙소로 엄청 싸워서 , \n",
    "웅 흥 4개월가는거도아니고 3일가는데 좀해주지 거 얼마한다구 , \n",
    "내말이 아니 해봤자 3일 다 합해도 몇만원 차이인데 너무해 그때는 2일이었는데도 만원 더 싼데에서 자꾸 자라고 넘 시러 , 일단\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d21ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer.encode(PTUNING)* 10 + tokenizer.encode(text) + tokenizer.encode(SUMMARY)\n",
    "input_tensor = torch.tensor(input_tokens).unsqueeze(0)\n",
    "\n",
    "eos_id = tokenizer.encode(EOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2208718",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11786,\n",
       " 11481,\n",
       " 12564,\n",
       " 8612,\n",
       " 6903,\n",
       " 8168,\n",
       " 20337,\n",
       " 11219,\n",
       " 8245,\n",
       " 9668,\n",
       " 13717,\n",
       " 8168,\n",
       " 20337,\n",
       " 9098,\n",
       " 8239,\n",
       " 8263,\n",
       " 42138,\n",
       " 7182,\n",
       " 9265,\n",
       " 18554,\n",
       " 11528,\n",
       " 6828,\n",
       " 7312,\n",
       " 7235,\n",
       " 10337,\n",
       " 11750,\n",
       " 15546,\n",
       " 10406,\n",
       " 19647,\n",
       " 11481,\n",
       " 9051,\n",
       " 8101,\n",
       " 10390,\n",
       " 9130,\n",
       " 11179,\n",
       " 9932,\n",
       " 6853,\n",
       " 7235,\n",
       " 7965,\n",
       " 7172,\n",
       " 6889,\n",
       " 14147,\n",
       " 6824,\n",
       " 9668,\n",
       " 11732,\n",
       " 15084,\n",
       " 8263,\n",
       " 9122,\n",
       " 11474,\n",
       " 10013,\n",
       " 6919,\n",
       " 11481,\n",
       " 9051,\n",
       " 7071,\n",
       " 21323,\n",
       " 9320,\n",
       " 9098,\n",
       " 7662,\n",
       " 8159,\n",
       " 14147,\n",
       " 9054,\n",
       " 9318,\n",
       " 12704,\n",
       " 9774,\n",
       " 7489,\n",
       " 8104,\n",
       " 15106,\n",
       " 11848,\n",
       " 12371,\n",
       " 8711,\n",
       " 12858,\n",
       " 7162,\n",
       " 16989,\n",
       " 36322,\n",
       " 7235,\n",
       " 9103,\n",
       " 8104,\n",
       " 9267,\n",
       " 24365,\n",
       " 7220,\n",
       " 9023,\n",
       " 9042,\n",
       " 7019,\n",
       " 18136,\n",
       " 9901,\n",
       " 9039,\n",
       " 7397,\n",
       " 11481,\n",
       " 15063,\n",
       " 10]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965468ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    pred = inf.model(input_tensor)\n",
    "    next_token = generate_next_token(pred.logits, temperature=1.0, top_p=0.8)\n",
    "\n",
    "    if next_token.item() == eos_id:\n",
    "        break\n",
    "    else:\n",
    "        input_tensor = torch.cat([input_tensor, next_token.unsqueeze(0)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5ec4770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<unused2><unused2><unused2><unused2><unused2><unused2><unused2><unused2><unused2><unused2> ['목요일은 외근이구 금요일은 출장!!!', '금요일이 당진이양?', '아닝아닝 10일이 당진이야', '그럼 금요일은 어디로가...?', '의왕! 철기연으로 가', '오홍?']<unused1> 비즈니스를 하기 위해 국내여행 심사가 많은데 그 심사에 관심이 많다.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3859d22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'비즈니스를 하기 위해 국내여행 심사가 많은데 그 심사에 관심이 많다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_tensor[0]).split('<unused1>')[-1].strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
