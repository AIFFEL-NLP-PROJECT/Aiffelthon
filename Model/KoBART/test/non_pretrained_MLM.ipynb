{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8335cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.10.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.10.0)\n",
      "Requirement already satisfied: rouge_score in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: datasets in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.0.2)\n",
      "Requirement already satisfied: transformers==4.24.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.24.0)\n",
      "Requirement already satisfied: transformer-utils in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: packaging in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: wandb in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.13.5)\n",
      "Requirement already satisfied: pandas in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.3.5)\n",
      "Requirement already satisfied: numpy in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (1.21.6)\n",
      "Requirement already satisfied: matplotlib in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (3.5.3)\n",
      "Requirement already satisfied: dataclasses in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (0.6)\n",
      "Requirement already satisfied: tqdm in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
      "Requirement already satisfied: rouge in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from torch==1.10.0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (5.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: filelock in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: nltk in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from rouge_score->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: dill in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.4)\n",
      "Requirement already satisfied: xxhash in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (10.0.1)\n",
      "Requirement already satisfied: colorcet in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformer-utils->-r requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: seaborn in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformer-utils->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from packaging->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (2.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (1.11.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (1.0.11)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (5.9.4)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (4.21.9)\n",
      "Requirement already satisfied: setproctitle in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: pathtools in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (65.5.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (3.1.29)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 8)) (2022.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (4.38.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 7)) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (1.26.13)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyct>=0.4.4 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from colorcet->transformer-utils->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from importlib-metadata->transformers==4.24.0->-r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: joblib in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from nltk->rouge_score->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: param>=1.7.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from pyct>=0.4.4->colorcet->transformer-utils->-r requirements.txt (line 5)) (1.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab5d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from rouge import Rouge\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    LineByLineTextDataset,\n",
    "    EarlyStoppingCallback,\n",
    "    BartConfig,\n",
    "    BartForConditionalGeneration\n",
    "\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532f3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "chckpoint = \"alaggung/bart-pretrained\"\n",
    "config = BartConfig.from_pretrained(chckpoint)\n",
    "model = BartForConditionalGeneration(config)\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(chckpoint) \n",
    "tokenizer = AutoTokenizer.from_pretrained(chckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c2bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # í…ìŠ¤íŠ¸ ì†Œë¬¸ìí™”\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # ê´„í˜¸ë¡œ ë‹«íŒ ë¬¸ìì—´ (..) ì œê±°\n",
    "    #sentence = re.sub(r'[#@]+[ê°€-í£A-Za-z#]+', ' ', sentence)\n",
    "    sentence = re.sub(r'[ã„±-ã…ã…-ã…£]+[/ã„±-ã…ã…-ã…£]', '', sentence) # ì—¬ëŸ¬ê°œ ììŒê³¼ ëª¨ìŒì„ ì‚­ì œí•œë‹¤.\n",
    "    sentence = re.sub(\"[^ê°€-í£a-z0-9#@]\", \" \", sentence) # ì˜ì–´ ì™¸ ë¬¸ì(ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì ë“±) ê³µë°±ìœ¼ë¡œ ë³€í™˜\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # ì—¬ëŸ¬ê°œ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤.\n",
    "    sentence = sentence.strip() # ë¬¸ì¥ ì–‘ìª½ ê³µë°± ì œê±°\n",
    "    # ìŠ¤íì…œ í† í° ì ìš©í•  ê±°ë©´ ì—¬ê¸° ìœ„ì— ì˜ì–´ ì™¸ ë¬¸ì ê³µë°±ìœ¼ë¡œ ë§Œë“¤ë•Œ ìŠ¤íì…œ í† í°ì„ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ì§€ì •í•´ì£¼ë©´ëœë‹¤.\n",
    "    # ê·¸ë¦¬ê³  ì„¸ë²ˆì§¸ ì •ê·œí‘œí˜„ì‹ì„ ì§€ì›Œì•¼ ||í•  ê²ƒì´ë‹¤. \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b781e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_total.csv')\n",
    "val_df = pd.read_csv('data/val_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186c435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd321028-d5b4-55f7-9e20-2eaa262f9154</td>\n",
       "      <td>['ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6.28-7.13ë¡œ í™•ì •í• ê¹Œ?', 'ìš°ë¦¬ ë¹„í–‰...</td>\n",
       "      <td>ë¹„í–‰ê¸° í‘œ ê°€ê²©ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë©°, íŠ¹ê°€ ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c51be2e4-c8d0-5cea-b1ae-cde1fe8f8ab6</td>\n",
       "      <td>['Kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€?', 'ì‘. ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€?', 'ë©´...</td>\n",
       "      <td>ë¹„ì—¼ì´ ìˆì–´ì„œ ì‹¸ê²Œ ë‚˜ì˜¨ ì¼íšŒìš© ë¶€ì§í¬ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ë‘ë ¤ê³  í•œë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e90e721f-00d1-5114-aa5d-5f1061472a29</td>\n",
       "      <td>['ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ê·¸ëƒ¥ê·¸ëŸ°ê²ƒê°™ì• '...</td>\n",
       "      <td>ì¼€ì´í¬ ì—…ì²´ ì¤‘ ì¤‘ì•™ë™ ìª½ì€ ë§›ë§Œ ìˆê³  ë””ìì¸ì€ ë³„ë¡œê³  ê³ ì”ë™ ì¼€ì´í¬ ì—…ì²´ëŠ” ë°°ë‹¬ë„...</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b215f3a2-d647-59f9-8410-1274ee5edd97</td>\n",
       "      <td>['ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ?', 'ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ã…‹ã…‹ã…‹', 'ì•„ ê·¸...</td>\n",
       "      <td>ì¹«ì†”ì„ 3ê°œì›”ì— í•˜ë‚˜ì”© ë°”ê¿”ì„œ ì™• ì¹«ì†” ì‚¬ëŸ¬ ì‹ ì„¸ê³„(ì“±) ê°€ìê³  í–ˆë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0bda61b6-1396-5a2a-a049-0b4035e40d59</td>\n",
       "      <td>['ì ë„ì•ˆì˜¤ë„¤ã…ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨', 'ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´??? ì•„ì£¼ ì—¬ë³´ ë¹¼...</td>\n",
       "      <td>ì ë„ ì•ˆ ì™€ì„œ ê³ êµ¬ë§ˆ ë§ë­ì´ë¥¼ ì–‘ì‹¬ìƒ í•˜ë‚˜ë§Œ ë¨¹ìœ¼ë ¤ê³  í•œë‹¤.</td>\n",
       "      <td>ìƒê±°ë˜(ì‡¼í•‘)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  fd321028-d5b4-55f7-9e20-2eaa262f9154   \n",
       "1  c51be2e4-c8d0-5cea-b1ae-cde1fe8f8ab6   \n",
       "2  e90e721f-00d1-5114-aa5d-5f1061472a29   \n",
       "3  b215f3a2-d647-59f9-8410-1274ee5edd97   \n",
       "4  0bda61b6-1396-5a2a-a049-0b4035e40d59   \n",
       "\n",
       "                                                Text  \\\n",
       "0  ['ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6.28-7.13ë¡œ í™•ì •í• ê¹Œ?', 'ìš°ë¦¬ ë¹„í–‰...   \n",
       "1  ['Kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€?', 'ì‘. ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€?', 'ë©´...   \n",
       "2  ['ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ê·¸ëƒ¥ê·¸ëŸ°ê²ƒê°™ì• '...   \n",
       "3  ['ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ?', 'ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ã…‹ã…‹ã…‹', 'ì•„ ê·¸...   \n",
       "4  ['ì ë„ì•ˆì˜¤ë„¤ã…ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨', 'ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´??? ì•„ì£¼ ì—¬ë³´ ë¹¼...   \n",
       "\n",
       "                                             Summary Category  \n",
       "0               ë¹„í–‰ê¸° í‘œ ê°€ê²©ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ë©°, íŠ¹ê°€ ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "1                ë¹„ì—¼ì´ ìˆì–´ì„œ ì‹¸ê²Œ ë‚˜ì˜¨ ì¼íšŒìš© ë¶€ì§í¬ ë§ˆìŠ¤í¬ë¥¼ ì‚¬ë‘ë ¤ê³  í•œë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "2  ì¼€ì´í¬ ì—…ì²´ ì¤‘ ì¤‘ì•™ë™ ìª½ì€ ë§›ë§Œ ìˆê³  ë””ìì¸ì€ ë³„ë¡œê³  ê³ ì”ë™ ì¼€ì´í¬ ì—…ì²´ëŠ” ë°°ë‹¬ë„...  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "3            ì¹«ì†”ì„ 3ê°œì›”ì— í•˜ë‚˜ì”© ë°”ê¿”ì„œ ì™• ì¹«ì†” ì‚¬ëŸ¬ ì‹ ì„¸ê³„(ì“±) ê°€ìê³  í–ˆë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  \n",
       "4                  ì ë„ ì•ˆ ì™€ì„œ ê³ êµ¬ë§ˆ ë§ë­ì´ë¥¼ ì–‘ì‹¬ìƒ í•˜ë‚˜ë§Œ ë¨¹ìœ¼ë ¤ê³  í•œë‹¤.  ìƒê±°ë˜(ì‡¼í•‘)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682a438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279992/279992 [00:08<00:00, 31278.52it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35004/35004 [00:01<00:00, 31481.95it/s]\n"
     ]
    }
   ],
   "source": [
    "train_text = []\n",
    "val_text = []\n",
    "\n",
    "for tt in tqdm(train_df['Text']):\n",
    "    train_text.append(preprocess_sentence(tt))\n",
    "\n",
    "for vt in tqdm(val_df['Text']):\n",
    "    val_text.append(preprocess_sentence(vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28dddfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279992/279992 [00:00<00:00, 2572369.50it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35004/35004 [00:00<00:00, 2451205.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train_Category = []\n",
    "val_Category= []\n",
    "\n",
    "for tc in tqdm(train_df['Category']):\n",
    "    train_Category.append(tc)\n",
    "\n",
    "for vc in tqdm(val_df['Category']):\n",
    "    val_Category.append(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3afe768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_text)):\n",
    "    temp_cat = \"#\"+val_Category[i]+\"# \"\n",
    "    val_text[i] = temp_cat+val_text[i]\n",
    "    \n",
    "for i in range(len(train_text)):\n",
    "    temp_cat = \"#\"+train_Category[i]+\"# \"\n",
    "    train_text[i] = temp_cat+train_text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebff30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(zip(train_text), columns=['Text'])\n",
    "val_df = pd.DataFrame(zip(val_text), columns=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07fe640c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#ìƒê±°ë˜(ì‡¼í•‘)# ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6 28 7 13ë¡œ í™•ì •í• ê¹Œ ìš°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ìƒê±°ë˜(ì‡¼í•‘)# kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€ ì‘ ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€ ë©´ë§ˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#ìƒê±°ë˜(ì‡¼í•‘)# ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ìƒê±°ë˜(ì‡¼í•‘)# ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ ì•„ ê·¸ ì™•...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ìƒê±°ë˜(ì‡¼í•‘)# ì ë„ì•ˆì˜¤ë„¤ ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨ ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´ ì•„ì£¼ ì—¬ë³´...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  #ìƒê±°ë˜(ì‡¼í•‘)# ê·¸ëŸ¼ ë‚ ì§œëŠ” ê°€ê²© í° ë³€ë™ ì—†ìœ¼ë©´ 6 28 7 13ë¡œ í™•ì •í• ê¹Œ ìš°...\n",
       "1  #ìƒê±°ë˜(ì‡¼í•‘)# kfë§ˆìŠ¤í¬ë§Œ 5ë¶€ì œ í•˜ëŠ”ê±°ì§€ ì‘ ë©´ë§ˆìŠ¤í¬ëŠ” ì•„ë¬´ë•Œë‚˜ ì‚¬ë„ë ê»€ ë©´ë§ˆ...\n",
       "2  #ìƒê±°ë˜(ì‡¼í•‘)# ì•„ ê·¼ë° ì¼€ì´í¬ ì—…ì²´ë“¤ ë´¤ëŠ”ë° ì¤‘ì•™ë™ìª½ ê±°ê¸°ëŠ” ë§›ë§Œìˆê³  ë””ìì¸ì€ ...\n",
       "3  #ìƒê±°ë˜(ì‡¼í•‘)# ì¹«ì†”ì‚¬ì•¼í•˜ëŠ”ë° ì“±ìœ¼ë¡œ ì‚´ê¹Œ ë­˜ ì¹«ì†”ì‚¬ëŠ”ê²ƒê¹Œì§€ ë¬¼ì–´ë³´ì‹œë‚¨ ì•„ ê·¸ ì™•...\n",
       "4  #ìƒê±°ë˜(ì‡¼í•‘)# ì ë„ì•ˆì˜¤ë„¤ ì–¼ë¦‰ ê³ êµ¬ë§ˆì¸„ ë¨¹ê³ ì‹¶ë‹¨ ê·¸ê²Œ ê·¸ë ‡ê²Œ ë§›ìˆì—ˆì–´ ì•„ì£¼ ì—¬ë³´..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8df6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df) \n",
    "val_data = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba441156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Text': Value(dtype='string', id=None)}, num_rows: 279992)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None)}, num_rows: 35004)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ce03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 128\n",
    "max_target = 128\n",
    "batch_size = 4\n",
    "ignore_index = -100# tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269fbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ignored_data(inputs, max_len, ignore_index):\n",
    "        if len(inputs) < max_len:\n",
    "            pad = [ignore_index] *(max_len - len(inputs)) # ignore_indexì¦‰ -100ìœ¼ë¡œ íŒ¨ë”©ì„ ë§Œë“¤ ê²ƒì¸ë° max_len - lne(inpu)\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:max_len]\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009d6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_data(inputs, max_len):\n",
    "        pad_index = tokenizer.pad_token_id\n",
    "        if len(inputs) < max_len:\n",
    "            pad = [pad_index] *(max_len - len(inputs))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:max_len]\n",
    "\n",
    "        return inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c0bfa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "    label_id= []\n",
    "    label_ids = []\n",
    "    dec_input_ids = []\n",
    "    input_ids = []\n",
    "\n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        input_ids.append(add_padding_data(tokenizer.encode(data_to_process['Text'][i], add_special_tokens=False), max_input))\n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        label_id.append(tokenizer.encode(data_to_process['Text'][i]))  \n",
    "        label_id[i].append(tokenizer.eos_token_id)  \n",
    "    for i in range(len(data_to_process['Text'])):  \n",
    "        dec_input_id = [tokenizer.eos_token_id]\n",
    "        dec_input_id += label_id[i][:-1]\n",
    "        dec_input_ids.append(add_padding_data(dec_input_id, max_target))  \n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        label_ids.append(add_ignored_data(label_id[i], max_target, ignore_index))\n",
    "   \n",
    "    return {'input_ids': input_ids,\n",
    "            'attention_mask' : (np.array(input_ids) != tokenizer.pad_token_id).astype(int),\n",
    "            'decoder_input_ids': dec_input_ids,\n",
    "            'decoder_attention_mask': (np.array(dec_input_ids) != tokenizer.pad_token_id).astype(int),\n",
    "            'labels': label_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac034cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_words = [\n",
    "                \"#@ì£¼ì†Œ#\", \"#@ì´ëª¨í‹°ì½˜#\", \"#@ì´ë¦„#\", \"#@URL#\", \"#@ì†Œì†#\",\n",
    "                \"#@ê¸°íƒ€#\", \"#@ì „ë²ˆ#\", \"#@ê³„ì •#\", \"#@url#\", \"#@ë²ˆí˜¸#\", \"#@ê¸ˆìœµ#\", \"#@ì‹ ì›#\",\n",
    "                \"#@ì¥ì†Œ#\", \"#@ì‹œìŠ¤í…œ#ì‚¬ì§„#\", \"#@ì‹œìŠ¤í…œ#ë™ì˜ìƒ#\", \"#@ì‹œìŠ¤í…œ#ê¸°íƒ€#\", \"#@ì‹œìŠ¤í…œ#ê²€ìƒ‰#\",\n",
    "                \"#@ì‹œìŠ¤í…œ#ì§€ë„#\", \"#@ì‹œìŠ¤í…œ#ì‚­ì œ#\", \"#@ì‹œìŠ¤í…œ#íŒŒì¼#\", \"#@ì‹œìŠ¤í…œ#ì†¡ê¸ˆ#\", \"#@ì‹œìŠ¤í…œ#\",\n",
    "                \"#ê°œì¸ ë° ê´€ê³„#\", \"#ë¯¸ìš©ê³¼ ê±´ê°•#\", \"#ìƒê±°ë˜(ì‡¼í•‘)#\", \"#ì‹œì‚¬/êµìœ¡#\", \"#ì‹ìŒë£Œ#\", \n",
    "                \"#ì—¬ê°€ ìƒí™œ#\", \"#ì¼ê³¼ ì§ì—…#\", \"#ì£¼ê±°ì™€ ìƒí™œ#\", \"#í–‰ì‚¬#\",\n",
    "                ]\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": special_words})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "model.config.max_length = 128 \n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec916142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835f9a12d6764992a5ce57aa65755b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a76b963502043eea59dcde53f4a49ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text'])\n",
    "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6631905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "#     print(\"labels_ids\",labels_ids)\n",
    "#     print(\"labels_ids[labels_ids == -100]\",labels_ids[labels_ids == -100])\n",
    "#     print(\"tokenizer.pad_token_id\",tokenizer.pad_token_id)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].high\n",
    "    rouge_output2 = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].high\n",
    "    rouge_outputL = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].high\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \n",
    "        \"rouge2_precision\": round(rouge_output2.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output2.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output2.fmeasure, 4), \n",
    "        \n",
    "        \"rougeL_precision\": round(rouge_outputL.precision, 4),\n",
    "        \"rougeL_recall\": round(rouge_outputL.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(rouge_outputL.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d621c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"checkpoint/non_MLM_totaldata_test\",\n",
    "    num_train_epochs=50, # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.1,\n",
    "    #label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True, # ìƒì„±ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ê³  ì§€ì •í•œë‹¤.\n",
    "    logging_dir=\"logs2\",\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end = True,\n",
    "    logging_strategy = 'epoch',\n",
    "    evaluation_strategy  = 'epoch',\n",
    "    save_strategy ='epoch'\n",
    "\n",
    "\n",
    "    #evaluation_strategy = \"steps\",# stepë³„ë¡œ 2ë²„ lossê°€ ì˜¤ë¥´ëŠ”ê±° ì•„ë‹ˆë©´ ê³„ì† ë°˜ë³µí•˜ëŠ”ë“¯\n",
    "    #load_best_model_at_end = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6550c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25426aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_tokenize_data,\n",
    "    eval_dataset=val_tokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "156bda6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 279992\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 875000\n",
      "  Number of trainable parameters = 46719488\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jx7789/Download/koBART/wandb/run-20221207_103225-1ph3qpnt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/1ph3qpnt\" target=\"_blank\">checkpoint/non_MLM_totaldata_test</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='875000' max='875000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [875000/875000 27:47:22, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.518200</td>\n",
       "      <td>5.007161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.437700</td>\n",
       "      <td>3.814587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.721400</td>\n",
       "      <td>3.442432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.433800</td>\n",
       "      <td>3.220051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.248200</td>\n",
       "      <td>3.066302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.113700</td>\n",
       "      <td>2.954711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.012800</td>\n",
       "      <td>2.872719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.931500</td>\n",
       "      <td>2.799126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.863500</td>\n",
       "      <td>2.743554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.810500</td>\n",
       "      <td>2.697537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.760400</td>\n",
       "      <td>2.661138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.722700</td>\n",
       "      <td>2.621130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.682800</td>\n",
       "      <td>2.580369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.652700</td>\n",
       "      <td>2.557314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.624000</td>\n",
       "      <td>2.541231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.597300</td>\n",
       "      <td>2.522768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.577300</td>\n",
       "      <td>2.492622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.554200</td>\n",
       "      <td>2.468729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.534600</td>\n",
       "      <td>2.458127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.514800</td>\n",
       "      <td>2.430806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.499300</td>\n",
       "      <td>2.431366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.480900</td>\n",
       "      <td>2.406846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.467900</td>\n",
       "      <td>2.390478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.454700</td>\n",
       "      <td>2.385585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.441100</td>\n",
       "      <td>2.364872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.429500</td>\n",
       "      <td>2.361667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.415700</td>\n",
       "      <td>2.358271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.403200</td>\n",
       "      <td>2.342292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.393600</td>\n",
       "      <td>2.334556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.383800</td>\n",
       "      <td>2.328155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.373900</td>\n",
       "      <td>2.314498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.363900</td>\n",
       "      <td>2.298274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.354500</td>\n",
       "      <td>2.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.345400</td>\n",
       "      <td>2.291085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.339400</td>\n",
       "      <td>2.281003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.330200</td>\n",
       "      <td>2.278737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.322700</td>\n",
       "      <td>2.268388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.317000</td>\n",
       "      <td>2.260029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.308400</td>\n",
       "      <td>2.263413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.304000</td>\n",
       "      <td>2.250375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.297600</td>\n",
       "      <td>2.252296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.289400</td>\n",
       "      <td>2.235816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.285300</td>\n",
       "      <td>2.233239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>2.235661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.275700</td>\n",
       "      <td>2.234229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.271900</td>\n",
       "      <td>2.235857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.267400</td>\n",
       "      <td>2.225313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.262900</td>\n",
       "      <td>2.227303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.261200</td>\n",
       "      <td>2.219316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.256600</td>\n",
       "      <td>2.217865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-17500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-17500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-17500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-35000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-35000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-35000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-52500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-52500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-52500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-70000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-70000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-17500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-87500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-87500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-87500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-87500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-87500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-105000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-105000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-52500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-122500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-122500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-122500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-122500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-122500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-140000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-140000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-87500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-157500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-157500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-157500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-157500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-157500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-175000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-175000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-175000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-175000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-175000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-122500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-192500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-192500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-192500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-192500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-192500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-210000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-210000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-210000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-210000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-157500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-227500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-227500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-227500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-227500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-227500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-175000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-245000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-245000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-245000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-245000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-245000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-192500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-262500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-262500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-262500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-262500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-262500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-210000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-280000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-280000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-280000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-280000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-280000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-227500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-297500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-297500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-297500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-297500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-297500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-245000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-315000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-315000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-315000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-315000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-315000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-262500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-332500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-332500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-332500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-332500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-332500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-280000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-350000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-350000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-350000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-350000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-350000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-297500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-367500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-367500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-367500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-367500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-367500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-315000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-385000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-385000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-385000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-385000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-385000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-332500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-402500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-402500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-402500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-402500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-402500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-350000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-420000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-420000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-420000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-420000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-420000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-367500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-437500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-437500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-437500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-437500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-437500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-385000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-455000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-455000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-455000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-455000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-455000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-402500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-472500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-472500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-472500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-472500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-472500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-420000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-490000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-490000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-490000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-490000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-490000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-437500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-507500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-507500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-507500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-507500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-507500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-455000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-525000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-525000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-525000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-525000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-525000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-472500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-542500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-542500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-542500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-542500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-542500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-490000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-560000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-560000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-560000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-560000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-560000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-507500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-577500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-577500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-577500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-577500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-577500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-525000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-595000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-595000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-595000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-595000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-595000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-542500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-612500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-612500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-612500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-612500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-612500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-560000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-630000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-630000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-630000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-630000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-630000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-577500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-647500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-647500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-647500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-647500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-647500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-595000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-665000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-665000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-665000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-665000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-665000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-612500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-682500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-682500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-682500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-682500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-682500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-630000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-700000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-700000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-700000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-700000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-700000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-647500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-717500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-717500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-717500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-717500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-717500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-665000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-735000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-735000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-735000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-735000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-735000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-682500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-752500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-752500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-752500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-752500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-752500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-700000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-770000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-770000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-770000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-770000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-770000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-717500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-787500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-787500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-787500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-787500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-787500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-735000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-805000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-805000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-805000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-805000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-805000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-770000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-822500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-822500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-822500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-822500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-822500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-752500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-840000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-840000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-840000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-840000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-840000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-787500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-857500\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-857500/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-857500/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-857500/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-857500/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-805000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 35004\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to checkpoint/non_MLM_totaldata_test/checkpoint-875000\n",
      "Configuration saved in checkpoint/non_MLM_totaldata_test/checkpoint-875000/config.json\n",
      "Model weights saved in checkpoint/non_MLM_totaldata_test/checkpoint-875000/pytorch_model.bin\n",
      "tokenizer config file saved in checkpoint/non_MLM_totaldata_test/checkpoint-875000/tokenizer_config.json\n",
      "Special tokens file saved in checkpoint/non_MLM_totaldata_test/checkpoint-875000/special_tokens_map.json\n",
      "Deleting older checkpoint [checkpoint/non_MLM_totaldata_test/checkpoint-822500] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoint/non_MLM_totaldata_test/checkpoint-875000 (score: 2.217864751815796).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=875000, training_loss=2.635788450892857, metrics={'train_runtime': 100047.073, 'train_samples_per_second': 139.93, 'train_steps_per_second': 8.746, 'total_flos': 4.745855691128832e+17, 'train_loss': 2.635788450892857, 'epoch': 50.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e0a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
