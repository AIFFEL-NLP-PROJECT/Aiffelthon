{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67661338",
   "metadata": {},
   "source": [
    "# MLM_finetuning_checkpoint_test\n",
    "- 다른 ipynb 파일에서 전처리를 진행후 생성된 csv 파일로 본 학습이 진행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5f89c",
   "metadata": {},
   "source": [
    "## 1. Import 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d94ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da5d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /opt/conda/lib/python3.9/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: datasets==1.0.2 in /opt/conda/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (4.62.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.3.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.21.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (3.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers==4.24.0 in /opt/conda/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (0.11.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (4.62.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (1.21.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.24.0) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (1.26.13)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformer-utils in /opt/conda/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.24.0)\n",
      "Requirement already satisfied: colorcet in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (3.0.1)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (0.11.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (1.9.1+cu111)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.62.3)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /opt/conda/lib/python3.9/site-packages (from colorcet->transformer-utils) (0.4.8)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.21.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->transformer-utils) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (3.0.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->seaborn->transformer-utils) (2021.3)\n",
      "Requirement already satisfied: param>=1.7.0 in /opt/conda/lib/python3.9/site-packages (from pyct>=0.4.4->colorcet->transformer-utils) (1.12.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.0.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn->transformer-utils) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.9/site-packages (0.13.5)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.11.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (3.1.29)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.9/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb) (59.4.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.0.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install datasets==1.0.2\n",
    "!pip install transformers==4.24.0\n",
    "!pip install transformer-utils\n",
    "!pip install packaging\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ad90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mecab 설치\n",
    "# !curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e360be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    LineByLineTextDataset,\n",
    "    BartTokenizer,\n",
    "    BartForConditionalGeneration,\n",
    "    EarlyStoppingCallback,\n",
    "    PreTrainedTokenizerFast,\n",
    "    PreTrainedTokenizer\n",
    "    \n",
    "\n",
    ")\n",
    "\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import EncoderDecoderModel\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "#from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a683f",
   "metadata": {},
   "source": [
    "## 2. 모델 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5616e",
   "metadata": {},
   "source": [
    "### 1) 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cd4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_tokenizer=PreTrainedTokenizer(\n",
    "#                                            bos_token=BOS,\n",
    "#                                             eos_token=EOS,\n",
    "#                                             cls_token=BOS,\n",
    "#                                             unk_token=UNK,\n",
    "#                                             sep_token=SEP,\n",
    "#                                             pad_token=PAD,\n",
    "#                                             mask_token=MASK,\n",
    "#                                            additional_special_tokens=special_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5944428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_words = [\n",
    "#     \"#@주소#\",\n",
    "#     \"#@이모티콘#\",\n",
    "#     \"#@이름#\",\n",
    "#     \"#@URL#\",\n",
    "#     \"#@소속#\",\n",
    "#     \"#@기타#\",\n",
    "#     \"#@전번#\",\n",
    "#     \"#@계정#\",\n",
    "#     \"#@url#\",\n",
    "#     \"#@번호#\",\n",
    "#     \"#@금융#\",\n",
    "#     \"#@신원#\",\n",
    "#     \"#@장소#\",\n",
    "#     \"#@시스템#사진#\",\n",
    "#     \"#@시스템#동영상#\",\n",
    "#     \"#@시스템#기타#\",\n",
    "#     \"#@시스템#검색#\",\n",
    "#     \"#@시스템#지도#\",\n",
    "#     \"#@시스템#삭제#\",\n",
    "#     \"#@시스템#파일#\",\n",
    "#     \"#@시스템#송금#\",\n",
    "#     \"#@시스템#\",\n",
    "# ]\n",
    "# PAD = \"[PAD]\"\n",
    "# UNK = \"[UNK]\"\n",
    "# BOS = \"[BOS]\"\n",
    "# EOS = \"[EOS]\"\n",
    "# MASK = \"[MASK]\"\n",
    "# SEP = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac403fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoints = \"/aiffel/aiffel/Korean_Conversation_Summary/MLM_35epoch_test/checkpoint-21500\" #MLM_ft_freez_tf/checkpoint-MLM-35epoch\"#\"/aiffel/aiffel/Korean_Conversation_Summary/MLM_ft_freez_4/checkpoint-17500\"#\"/aiffel/aiffel/Korean_Conversation_Summary/MLM_ft_freez/checkpoint-21500\"#\"/aiffel/aiffel/Korean_Conversation_Summary/MLM_pretrain_basev2_freezing/checkpoint-175000\"#\"/aiffel/aiffel/Korean_Conversation_Summary/MLM_pretrain_basev2_total10ep_3/checkpoint-133500\" #MLM_ft2/checkpoint-4000\" #MLM_pretrain_basev2_total10ep/checkpoint-14000\" #/MLM_ft/checkpoint-4000\"#\"/aiffel/aiffel/Korean_Conversation_Summary/MLM_pretrain_5ep_221120_2/checkpoint-87500\"#\"gogamza/kobart-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23754918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputtest=tokenizer(special_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89791deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode = inputtest['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4811707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff061a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def freeze_params(model):\n",
    "#     for par in model.parameters():\n",
    "#         par.requires_grad = False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb82549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_params(model.get_encoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97aacfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_layers = model.get_decoder().layers\n",
    "# for i in range(2):\n",
    "#     freeze_params(dec_layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c53ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.parameters():\n",
    "#     print(i.requires_grad)\n",
    "# train_p = [p for p in model.parameters() if p.requires_grad] \n",
    "# print(f'Length of train params in Summarization Model : {len(train_p)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175a6952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.parameters():\n",
    "#     print(i.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ac68cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in model.parameters():\n",
    "#     i.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e63b0cb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in model.parameters():\n",
    "#     print(i.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a89e9f",
   "metadata": {},
   "source": [
    "### 2) 데이터 불러오기 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f3b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_category_path = \"data/train_category.csv\"\n",
    "val_category_path = \"data/val_category.csv\"\n",
    "\n",
    "with open(train_category_path, encoding=\"utf-8\") as f:\n",
    "            train_category = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "with open(val_category_path, encoding=\"utf-8\") as f:\n",
    "            val_category = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfaa5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_textfile_path = \"data/train_text.csv\"\n",
    "train_summaryfile_path = \"data/train_summary.csv\"\n",
    "\n",
    "with open(train_textfile_path, encoding=\"utf-8\") as f:\n",
    "            train_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "with open(train_summaryfile_path, encoding=\"utf-8\") as f:\n",
    "            train_sumlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "490b8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_textfile_path = \"data/val_text.csv\"\n",
    "val_summaryfile_path = \"data/val_summary.csv\"\n",
    "\n",
    "with open(val_textfile_path, encoding=\"utf-8\") as f:\n",
    "            val_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "with open(val_summaryfile_path, encoding=\"utf-8\") as f:\n",
    "            val_sumlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f44b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_textlines[0]\n",
    "del val_textlines[0]\n",
    "del train_category[0]\n",
    "del val_category[0]\n",
    "del val_sumlines[0]\n",
    "del train_sumlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a6dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"data/train_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cfba189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일이야 16일 아 너 나한테 돈 보내주면 지금 할 수 잇옹 얼마야 최종 결제액이 잠시만 인당 952 900 합쳐서 1 905 800 근데 나중에 특가 뜰 수도 있으려나 좀 더 두고볼까 뜨기야 뜨겠지 웅웅 보니까 아시아나는 특가 이벤트 꽤 하는 것 같아서 일단 두고보장 그래 구럼 일단 자자'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf8bf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일이야 16일 아 너 나한테 돈 보내주면 지금 할 수 잇옹 얼마야 최종 결제액이 잠시만 인당 952 900 합쳐서 1 905 800 근데 나중에 특가 뜰 수도 있으려나 좀 더 두고볼까 뜨기야 뜨겠지 웅웅 보니까 아시아나는 특가 이벤트 꽤 하는 것 같아서 일단 두고보장 그래 구럼 일단 자자'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_textlines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea82af8",
   "metadata": {},
   "source": [
    "### 3) 메타 데이터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc76a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_textlines)):\n",
    "    temp_cat = \"#\"+val_category[i]+\"# \"\n",
    "    val_textlines[i] = temp_cat+val_textlines[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e363111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_textlines)):\n",
    "    temp_cat = \"#\"+train_category[i]+\"# \"\n",
    "    train_textlines[i] = temp_cat+train_textlines[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9b898",
   "metadata": {},
   "source": [
    "### 4) DataFrame로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b5c20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(zip(train_textlines, train_sumlines), columns=['Text', 'Summary'])\n",
    "val_df = pd.DataFrame(zip(val_textlines, val_sumlines), columns=['Text', 'Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8964a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(inplace=True, drop=True)\n",
    "val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3df00b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#상거래(쇼핑)# 그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우...</td>\n",
       "      <td>비행기 표 가격에 대해 이야기하며 특가 이벤트를 기다리고 있다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#상거래(쇼핑)# kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마...</td>\n",
       "      <td>비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#상거래(쇼핑)# 아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 ...</td>\n",
       "      <td>케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#상거래(쇼핑)# 칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕...</td>\n",
       "      <td>칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계 가자고 했다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#상거래(쇼핑)# 잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보...</td>\n",
       "      <td>잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  #상거래(쇼핑)# 그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우...   \n",
       "1  #상거래(쇼핑)# kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마...   \n",
       "2  #상거래(쇼핑)# 아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 ...   \n",
       "3  #상거래(쇼핑)# 칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕...   \n",
       "4  #상거래(쇼핑)# 잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보...   \n",
       "\n",
       "                                             Summary  \n",
       "0                 비행기 표 가격에 대해 이야기하며 특가 이벤트를 기다리고 있다  \n",
       "1                 비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다  \n",
       "2  케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...  \n",
       "3                칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계 가자고 했다  \n",
       "4                   잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37901092",
   "metadata": {},
   "source": [
    "## 3. 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb300fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mecab 적용 후 문장 len 출력하는 함수 구현 - 전체 데이터\n",
    "\n",
    "# # 한글 데이터 Mecab 적용하기\n",
    "# mecab = Mecab()\n",
    "\n",
    "# def sentence_len_total(data):\n",
    "\n",
    "#     # 빈 리스트 적용\n",
    "#     text_split_text = []\n",
    "#     text_split_summary = []\n",
    "    \n",
    "#     # 반복문으로 Mecab 적용\n",
    "#     for text_sen in data['Text'].iloc[range(0, len(data))]:\n",
    "#         text_split_text.append(mecab.morphs(text_sen))\n",
    "\n",
    "#     for summary_sen in data['Summary'].iloc[range(0, len(data))]:\n",
    "#         text_split_summary.append(mecab.morphs(summary_sen))\n",
    "    \n",
    "#     df_ext = pd.DataFrame(zip(text_split_text,text_split_summary),\\\n",
    "#                           columns=['Text', 'Summary'])\n",
    "\n",
    "    \n",
    "#     # Mecab 적용 후 길이 출력\n",
    "#     text_len = df_ext.Text.map(len)\n",
    "#     headlines_len = df_ext.Summary.map(len)\n",
    "    \n",
    "#     # text_len 사분위수 구하기\n",
    "    \n",
    "#     text_Q1 = text_len.quantile(.25)\n",
    "#     text_Q3 = text_len.quantile(.75)\n",
    "#     text_IQR = text_Q3 - text_Q1\n",
    "#     text_Q2 = text_len.quantile(.5)\n",
    "#     text_Q4 = text_len.quantile(1)\n",
    "#     text_threshold_len_left = text_Q1 - (1.5 * text_IQR)\n",
    "#     text_threshold_len_right = text_Q3 + (1.5 * text_IQR)\n",
    "#     # headlines_len 사분위수 구하기\n",
    "    \n",
    "#     headlines_Q1 = headlines_len.quantile(.25)\n",
    "#     headlines_Q3 = headlines_len.quantile(.75)\n",
    "#     headlines_IQR = headlines_Q3 - headlines_Q1\n",
    "#     headlines_Q2 = headlines_len.quantile(.5)\n",
    "#     headlines_Q4 = headlines_len.quantile(1)\n",
    "#     headlines_threshold_len_left = headlines_Q1 - (1.5 * headlines_IQR)\n",
    "#     headlines_threshold_len_right = headlines_Q3 + (1.5 * headlines_IQR)\n",
    "    \n",
    "#     print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "#     print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "#     print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "    \n",
    "#     print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "#     print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "#     print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "    \n",
    "\n",
    "    \n",
    "#     print('text_Q1 = {}'.format(text_Q1), 'headlines_Q1 = {}'.format(headlines_Q1))\n",
    "#     print('text_Q3 = {}'.format(text_Q3), 'headlines_Q3 = {}'.format(headlines_Q3))\n",
    "#     print('text_IQR = {}'.format(text_IQR), 'headlines_IQR = {}'.format(headlines_IQR))\n",
    "#     print('text_Q2 = {}'.format(text_Q2), 'headlines_Q2 = {}'.format(headlines_Q2))\n",
    "#     print('text_Q4 = {}'.format(text_Q4), 'headlines_Q4 = {}'.format(headlines_Q4))\n",
    "#     print('텍스트의 왼쪽 울타리 범위 : {}'. format(text_threshold_len_left),\n",
    "#          '텍스트의 오른쪽 울타리 범위 : {}'. format(text_threshold_len_right))\n",
    "#     print('헤드라인의 왼쪽 울타리 범위 : {}'. format(headlines_threshold_len_left),\n",
    "#          '헤드라인의 오른쪽 울타리 범위 : {}'. format(headlines_threshold_len_right))\n",
    "    \n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.boxplot(text_len)\n",
    "#     plt.title('text')\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.boxplot(headlines_len)\n",
    "#     plt.title('headlines')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.title('text')\n",
    "#     plt.hist(text_len, bins = 40)\n",
    "#     plt.xlabel('length of samples')\n",
    "#     plt.ylabel('number of samples')\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.title('headlines')\n",
    "#     plt.hist(headlines_len, bins = 40)\n",
    "#     plt.xlabel('length of samples')\n",
    "#     plt.ylabel('number of samples')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04df32f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sentence_len_total(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9be10bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_len_total(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1958c796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#상거래(쇼핑)# 그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우...</td>\n",
       "      <td>비행기 표 가격에 대해 이야기하며 특가 이벤트를 기다리고 있다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#상거래(쇼핑)# kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마...</td>\n",
       "      <td>비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#상거래(쇼핑)# 아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 ...</td>\n",
       "      <td>케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#상거래(쇼핑)# 칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕...</td>\n",
       "      <td>칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계 가자고 했다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#상거래(쇼핑)# 잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보...</td>\n",
       "      <td>잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  #상거래(쇼핑)# 그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우...   \n",
       "1  #상거래(쇼핑)# kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마...   \n",
       "2  #상거래(쇼핑)# 아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 ...   \n",
       "3  #상거래(쇼핑)# 칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕...   \n",
       "4  #상거래(쇼핑)# 잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보...   \n",
       "\n",
       "                                             Summary  \n",
       "0                 비행기 표 가격에 대해 이야기하며 특가 이벤트를 기다리고 있다  \n",
       "1                 비염이 있어서 싸게 나온 일회용 부직포 마스크를 사두려고 한다  \n",
       "2  케이크 업체 중 중앙동 쪽은 맛만 있고 디자인은 별로고 고잔동 케이크 업체는 배달도...  \n",
       "3                칫솔을 3개월에 하나씩 바꿔서 왕 칫솔 사러 신세계 가자고 했다  \n",
       "4                   잠도 안 와서 고구마 말랭이를 양심상 하나만 먹으려고 한다  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495394f",
   "metadata": {},
   "source": [
    "## 4. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34d49",
   "metadata": {},
   "source": [
    "### 1) dataset으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7795db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Set으로 전환\n",
    "train_len = len(train_df) //4\n",
    "train_data = Dataset.from_pandas(train_df[:train_len]) \n",
    "val_len = len(val_df) // 2\n",
    "val_data = Dataset.from_pandas(val_df[:val_len])\n",
    "test_data=Dataset.from_pandas(val_df[val_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e44a3d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 69998)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 17502)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 17502)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931b2af",
   "metadata": {},
   "source": [
    "### 2) EDA 바탕으로 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b3f8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 70\n",
    "max_target = 30\n",
    "batch_size = 4\n",
    "ignore_index = -100# tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05965137",
   "metadata": {},
   "source": [
    "### 3) 토큰화 함수 구현 및 토큰화\n",
    "- input_ids, attention_mask, lables토큰만 구현\n",
    "- 추가로 decoder_input_ids, decoder_attention_mask 토큰화도 시도해봤으나 성능에는 차이가 없고 허깅페이스에 그에 관한 설명이 나왔있음\n",
    "    - https://huggingface.co/docs/transformers/glossary#decoder-input-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "868a8d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_words = [\n",
    "#     \"#@주소#\",\n",
    "#     \"#@이모티콘#\",\n",
    "#     \"#@이름#\",\n",
    "#     \"#@URL#\",\n",
    "#     \"#@소속#\",\n",
    "#     \"#@기타#\",\n",
    "#     \"#@전번#\",\n",
    "#     \"#@계정#\",\n",
    "#     \"#@url#\",\n",
    "#     \"#@번호#\",\n",
    "#     \"#@금융#\",\n",
    "#     \"#@신원#\",\n",
    "#     \"#@장소#\",\n",
    "#     \"#@시스템#사진#\",\n",
    "#     \"#@시스템#동영상#\",\n",
    "#     \"#@시스템#기타#\",\n",
    "#     \"#@시스템#검색#\",\n",
    "#     \"#@시스템#지도#\",\n",
    "#     \"#@시스템#삭제#\",\n",
    "#     \"#@시스템#파일#\",\n",
    "#     \"#@시스템#송금#\",\n",
    "#     \"#@시스템#\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ea2834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_tokenizer = PreTrainedTokenizerFast(\n",
    "#         tokenizer_object=tokenizer,\n",
    "\n",
    "#         additional_special_tokens=special_words,\n",
    "#     )\n",
    "# pretrained_tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5e5de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def add_ignored_data(inputs, max_len, ignore_index):\n",
    "        if len(inputs) < max_len:\n",
    "            pad = [ignore_index] *(max_len - len(inputs)) # ignore_index즉 -100으로 패딩을 만들 것인데 max_len - lne(inpu)\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:max_len]\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1826589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding_data(inputs, max_len):\n",
    "        pad_index = tokenizer.pad_token_id\n",
    "        if len(inputs) < max_len:\n",
    "            pad = [pad_index] *(max_len - len(inputs))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:max_len]\n",
    "\n",
    "        return inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9e1daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "    label_id= []\n",
    "    label_ids = []\n",
    "    dec_input_ids = []\n",
    "    inputs = [dialogue for dialogue in data_to_process['Text']]\n",
    "    model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "\n",
    "    for i in range(len(data_to_process['Summary'])):\n",
    "        label_id.append(tokenizer.encode(data_to_process['Summary'][i]))  \n",
    "    for i in range(len(data_to_process['Summary'])):\n",
    "        label_id[i].append(tokenizer.eos_token_id)\n",
    "        label_ids.append(add_ignored_data(label_id[i], max_target, ignore_index))\n",
    "#    for i in range(len(data_to_process['Summary'])):  \n",
    "#        dec_input_id = [tokenizer.eos_token_id]\n",
    "#        dec_input_id += label_ids[i][:-1]\n",
    "#        dec_input_ids.append(add_padding_data(dec_input_id, max_target))  \n",
    "    \n",
    "    model_inputs['labels'] = label_ids\n",
    "#    model_inputs['decoder_input_ids'] = dec_input_ids\n",
    "#    model_inputs['decoder_attention_mask'] = (np.array(dec_input_ids) != tokenizer.pad_token_id).astype(int) \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e243852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3732c25c652450babc0bd9189cd6844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30be1ca2998c4e99b685f7b046c61a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])\n",
    "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text', 'Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d8e04",
   "metadata": {},
   "source": [
    "## 5. 학습을 진행하기 위한 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce4bad",
   "metadata": {},
   "source": [
    "### 1) config 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f59e80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set special tokens\n",
    "#from transformers import EncoderDecoderConfig\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "model.config.max_length = 30 # 256은 쿠다 메모리 오류 생김\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 2\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 2\n",
    "#model.config.suppress_tokens = [23782, 14338, 22554, 234]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4eaafdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartConfig {\n",
       "  \"_name_or_path\": \"/aiffel/aiffel/Korean_Conversation_Summary/MLM_35epoch_test/checkpoint-21500\",\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": false,\n",
       "  \"architectures\": [\n",
       "    \"BartForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classif_dropout\": 0.1,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 3072,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 1,\n",
       "  \"do_blenderbot_90_layernorm\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 3072,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 6,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"extra_pos_embeddings\": 2,\n",
       "  \"force_bos_token_to_be_generated\": false,\n",
       "  \"forced_eos_token_id\": 1,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"NEGATIVE\",\n",
       "    \"1\": \"POSITIVE\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"kobart_version\": 2.0,\n",
       "  \"label2id\": {\n",
       "    \"NEGATIVE\": 0,\n",
       "    \"POSITIVE\": 1\n",
       "  },\n",
       "  \"length_penalty\": 2.0,\n",
       "  \"max_length\": 30,\n",
       "  \"max_position_embeddings\": 1026,\n",
       "  \"model_type\": \"bart\",\n",
       "  \"no_repeat_ngram_size\": 2,\n",
       "  \"normalize_before\": false,\n",
       "  \"normalize_embedding\": true,\n",
       "  \"num_beams\": 2,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 3,\n",
       "  \"scale_embedding\": false,\n",
       "  \"static_position_embeddings\": false,\n",
       "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.24.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e6ca10",
   "metadata": {},
   "source": [
    "### 2) rounge 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0cea456",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "#     print(\"labels_ids\",labels_ids)\n",
    "#     print(\"labels_ids[labels_ids == -100]\",labels_ids[labels_ids == -100])\n",
    "#     print(\"tokenizer.pad_token_id\",tokenizer.pad_token_id)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "    rouge_output2 = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    rouge_outputL = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \n",
    "        \"rouge2_precision\": round(rouge_output2.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output2.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output2.fmeasure, 4), \n",
    "        \n",
    "        \"rougeL_precision\": round(rouge_outputL.precision, 4),\n",
    "        \"rougeL_recall\": round(rouge_outputL.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(rouge_outputL.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ee75a",
   "metadata": {},
   "source": [
    "### 3) arguments 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c46c0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"MLM_35epoch_test2\",\n",
    "    num_train_epochs=20,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-05,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True, # 생성기능을 사용하고 싶다고 지정한다.\n",
    "    logging_dir=\"logs2\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=3,\n",
    "  \n",
    "    #evaluation_strategy = \"steps\",# step별로 2버 loss가 오르는거 아니면 계속 반복하는듯\n",
    "    #load_best_model_at_end = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ab114",
   "metadata": {},
   "source": [
    "### 4) data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d40f80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDataCollatorForSeq2Seq 를 사용하여 예제 배치를 생성 하십시오 . \\n또한 일괄 처리에서 가장 긴 요소의 길이로 텍스트와 레이블을 동적으로 채워서 균일한 길이가 되도록 합니다.\\ntokenizer를 설정하여 함수 에서 텍스트를 채울 수 있지만 padding=True동적 패딩이 더 효율적입니다.\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model) # 데이터 일괄 처리?\n",
    "\"\"\"\n",
    "DataCollatorForSeq2Seq 를 사용하여 예제 배치를 생성 하십시오 . \n",
    "또한 일괄 처리에서 가장 긴 요소의 길이로 텍스트와 레이블을 동적으로 채워서 균일한 길이가 되도록 합니다.\n",
    "tokenizer를 설정하여 함수 에서 텍스트를 채울 수 있지만 padding=True동적 패딩이 더 효율적입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55be2b7",
   "metadata": {},
   "source": [
    "### 5) train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1e3c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_tokenize_data,\n",
    "    eval_dataset=val_tokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "   # callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f063986f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 69998\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 87500\n",
      "  Number of trainable parameters = 123859968\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/aiffel/aiffel/Korean_Conversation_Summary/wandb/run-20221127_155022-47xbay5x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/47xbay5x\" target=\"_blank\">MLM_35epoch_test2</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87500' max='87500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87500/87500 5:46:19, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.782200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.799800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.815700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.755600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.619500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.635500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.680800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.697300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.462600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.529500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.552900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.575200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.362300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.467700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.308700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.331400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.188600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>2.213600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>2.241400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.244600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>2.252600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.254400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>2.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>2.111800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>2.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>2.148400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.160100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>2.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>2.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>2.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>2.049600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>2.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>1.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>1.953000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>1.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>1.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>1.978300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>1.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>1.985900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>1.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>1.972600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.877800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>1.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>1.901300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>1.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>1.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>1.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>1.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>1.878900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>1.832300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.835600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>1.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>1.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>1.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>1.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>1.862900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>1.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>1.804100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>1.785800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>1.791500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>1.805700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>1.808600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>1.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>1.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>1.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>1.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>1.750200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>1.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>1.760200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>1.765500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>1.771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>1.775800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>1.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>1.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>1.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>1.723300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>1.723800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>1.728800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>1.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>1.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>1.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>1.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>1.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>1.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>1.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>1.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>1.704700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>1.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>1.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>1.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>1.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>1.670300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>1.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>1.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>1.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>1.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>1.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>1.647300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>1.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>1.650100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>1.651100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>1.653700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>1.653200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>1.657600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>1.650100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.630100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>1.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>1.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>1.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>1.634200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>1.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>1.636800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>1.635900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>1.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>1.617500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80500</td>\n",
       "      <td>1.619200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>1.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81500</td>\n",
       "      <td>1.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>1.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>1.621900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>1.623100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83500</td>\n",
       "      <td>1.612700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>1.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84500</td>\n",
       "      <td>1.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85500</td>\n",
       "      <td>1.609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>1.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86500</td>\n",
       "      <td>1.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>1.609900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>1.610200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-1000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-1000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-1500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-1500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-2000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-2000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-2500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-2500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-3000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-3000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-3500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-3500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-4000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-4000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-4500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-4500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-5000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-5000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-5500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-5500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-6000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-6000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-6500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-6500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-7000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-7000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-7500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-7500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-8000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-8000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-8500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-8500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-9000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-9000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-9500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-9500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-10000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-10000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-10500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-10500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-11000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-11000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-11500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-11500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-12000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-12000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-12500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-12500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-13000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-13000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-13500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-13500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-14000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-14000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-14500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-14500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-15000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-15000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-15500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-15500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-16000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-16000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-16500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-16500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-17000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-17000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-17500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-17500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-18000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-18000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-18500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-18500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-19000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-19000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-19500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-19500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-20000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-20000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-20500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-20500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-21000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-21000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-21500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-21500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-22000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-22000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-22500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-22500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-23000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-23000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-23500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-23500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-24000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-24000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-24500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-24500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-25000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-25000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-25500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-25500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-26000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-26000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-26500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-26500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-27000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-27000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-27500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-27500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-28000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-28000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-28500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-28500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-29000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-29000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-29500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-29500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-30000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-30000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-30500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-30500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-31000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-31000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-31500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-31500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-32000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-32000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-32500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-32500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-33000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-33000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-33500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-33500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-34000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-34000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-34500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-34500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-35000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-35000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-35500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-35500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-36000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-36000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-36500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-36500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-37000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-37000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-37500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-37500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-38000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-38000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-38500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-38500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-39000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-39000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-39500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-39500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-40000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-40000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-40500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-40500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-41000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-41000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-41500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-41500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-42000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-42000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-42500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-42500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-43000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-43000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-43500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-43500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-44000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-44000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-44500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-44500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-45000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-45000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-45500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-45500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-46000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-46000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-46500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-46500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-47000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-47000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-47500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-47500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-48000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-48000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-48500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-48500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-48500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-49000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-49000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-49500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-49500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-50000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-50000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-48500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-50500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-50500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-51000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-51000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-51500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-51500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-52000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-52000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-50500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-52500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-52500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-53000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-53000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-53500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-53500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-53500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-54000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-54000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-52500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-54500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-54500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-54500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-55000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-55000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-53500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-55500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-55500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-55500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-56000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-56000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-56000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-56500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-56500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-56500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-57000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-57000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-57000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-55500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-57500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-57500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-57500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-56000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-58000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-58000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-58000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-56500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-58500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-58500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-58500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-57000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-59000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-59000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-59000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-57500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-59500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-59500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-59500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-59500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-59500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-58000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-60000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-60000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-58500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-60500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-60500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-60500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-60500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-60500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-59000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-61000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-61000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-61000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-61000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-61000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-59500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-61500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-61500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-61500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-61500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-60000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-62000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-62000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-62000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-62000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-62000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-60500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-62500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-62500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-62500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-61000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-63000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-63000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-63000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-63000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-63000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-61500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-63500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-63500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-63500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-63500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-63500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-62000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-64000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-64000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-64000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-64000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-64000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-62500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-64500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-64500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-64500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-64500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-64500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-63000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-65000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-65000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-63500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-65500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-65500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-65500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-65500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-65500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-64000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-66000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-66000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-66000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-66000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-66000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-64500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-66500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-66500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-66500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-66500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-66500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-65000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-67000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-67000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-67000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-67000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-67000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-65500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-67500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-67500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-67500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-67500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-67500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-66000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-68000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-68000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-68000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-68000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-68000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-66500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-68500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-68500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-68500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-68500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-68500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-67000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-69000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-69000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-69000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-69000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-69000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-67500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-69500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-69500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-69500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-69500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-69500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-68000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-70000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-70000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-68500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-70500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-70500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-70500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-70500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-70500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-69000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-71000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-71000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-71000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-71000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-71000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-69500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-71500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-71500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-71500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-71500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-71500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-70000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-72000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-72000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-72000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-72000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-72000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-70500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-72500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-72500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-72500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-72500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-72500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-71000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-73000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-73000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-73000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-73000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-73000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-71500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-73500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-73500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-73500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-73500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-73500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-72000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-74000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-74000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-74000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-74000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-74000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-72500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-74500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-74500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-74500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-74500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-74500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-73000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-75000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-75000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-73500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-75500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-75500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-75500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-75500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-75500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-74000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-76000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-76000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-76000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-76000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-76000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-74500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-76500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-76500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-76500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-76500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-76500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-75000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-77000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-77000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-77000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-77000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-77000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-75500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-77500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-77500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-77500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-77500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-77500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-76000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-78000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-78000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-78000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-78000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-78000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-76500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-78500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-78500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-78500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-78500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-78500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-77000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-79000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-79000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-79000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-79000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-79000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-77500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-79500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-79500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-79500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-79500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-79500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-78000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-80000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-80000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-78500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-80500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-80500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-80500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-80500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-80500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-79000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-81000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-81000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-81000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-81000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-81000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-79500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-81500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-81500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-81500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-81500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-81500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-80000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-82000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-82000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-82000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-82000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-82000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-80500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-82500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-82500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-82500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-82500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-82500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-81000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-83000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-83000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-83000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-83000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-83000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-81500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-83500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-83500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-83500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-83500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-83500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-82000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-84000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-84000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-84000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-84000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-84000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-82500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-84500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-84500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-84500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-84500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-84500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-83000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-85000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-85000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-83500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-85500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-85500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-85500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-85500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-85500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-84000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-86000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-86000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-86000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-86000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-86000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-84500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-86500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-86500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-86500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-86500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-86500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-85000] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-87000\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-87000/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-87000/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-87000/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-87000/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-85500] due to args.save_total_limit\n",
      "Saving model checkpoint to MLM_35epoch_test2/checkpoint-87500\n",
      "Configuration saved in MLM_35epoch_test2/checkpoint-87500/config.json\n",
      "Model weights saved in MLM_35epoch_test2/checkpoint-87500/pytorch_model.bin\n",
      "tokenizer config file saved in MLM_35epoch_test2/checkpoint-87500/tokenizer_config.json\n",
      "Special tokens file saved in MLM_35epoch_test2/checkpoint-87500/special_tokens_map.json\n",
      "Deleting older checkpoint [MLM_35epoch_test2/checkpoint-86000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87500, training_loss=2.001541648297991, metrics={'train_runtime': 20782.3537, 'train_samples_per_second': 67.363, 'train_steps_per_second': 4.21, 'total_flos': 5.8352017231872e+16, 'train_loss': 2.001541648297991, 'epoch': 20.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "640de13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 17502\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='274' max='274' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [274/274 06:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.236032962799072,\n",
       " 'eval_rouge1_precision': 0.1145,\n",
       " 'eval_rouge1_recall': 0.115,\n",
       " 'eval_rouge1_fmeasure': 0.1109,\n",
       " 'eval_rouge2_precision': 0.0233,\n",
       " 'eval_rouge2_recall': 0.0234,\n",
       " 'eval_rouge2_fmeasure': 0.0224,\n",
       " 'eval_rougeL_precision': 0.1132,\n",
       " 'eval_rougeL_recall': 0.1138,\n",
       " 'eval_rougeL_fmeasure': 0.1097,\n",
       " 'eval_runtime': 381.3285,\n",
       " 'eval_samples_per_second': 45.897,\n",
       " 'eval_steps_per_second': 0.719,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f25c4a",
   "metadata": {},
   "source": [
    "## 6. 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "157f44e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, num_beams=2,no_repeat_ngram_size=2, max_length=40,\n",
    "                            suppress_tokens= [234,23782,14338,240,199,198,161,116, 14338, 239], \n",
    "                            attention_mask=attention_mask, top_p=0.92,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id,\n",
    "                            eos_token_id=tokenizer.eos_token_id,)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "#model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)# 여기에 기본 kobart가져오기?ㅇ\n",
    "import random\n",
    "from random import randrange\n",
    "ck_num = len(test_data)\n",
    "test_samples = test_data.select(range(0, ck_num, 500))# 0, len(test_data), 200\n",
    "\n",
    "#summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1] # 여기에 체크포인트 가져오기 \n",
    "# 연구해봐야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "261677dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx_0 \n",
      "\n",
      "Summary after \n",
      " 생활 중인 웹툰을 보라고 하자 안 자면 바꾼다고 하면서 이런 영화는 싫다고 한다\n",
      "\n",
      "Target summary \n",
      " 곧 유료화되는 웹툰을 보고 재미있으면 말해주겠다\n",
      "\n",
      "Text #여가 생활# 웹툰볼그야 안자면바야지 곧유료화되는것들 먼저봐야지 이런영웅은싫어 괜찮다던데 17일인가유료화 그게머지 첨들어보는데 나도몰랏는데 인기글에서봤어 웅 보고 재밋으면말해준다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_1 \n",
      "\n",
      "Summary after \n",
      " 하나만 달리기엔 찜찜한 느낌이라고 하고 볼 건 많다고 한다\n",
      "\n",
      "Target summary \n",
      " 볼 건 많지만 보고 싶지 않다며 죄다 백 같은 거라 안 끌린다고 한다\n",
      "\n",
      "Text #여가 생활# 리전 하나만 달리기엔 찜찜한느낌 그리고 이제 진짜 볼 게 없어 아니 볼 건 많지 보고 싶지 않아 애말이 죄다 백같은거냐 하아아아나도 안 끌려 죽겠네 그치 난 오래전부터 그랫어 넌 백이라도 잇엇지 진짜 힘들었겠다 나\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_2 \n",
      "\n",
      "Summary after \n",
      " 요새는 주드로 영화 스파이를 보고 싶다고 한다\n",
      "\n",
      "Target summary \n",
      " 영화 스파이가 재미있어서 보고 싶다며 스파이더맨을 봐야겠다고 한다\n",
      "\n",
      "Text #여가 생활# 영화 스파이 알지 이런 꿀잼 보고 싶어 요새는 주드로 나그영화 개개개가가개래좋아해 나도 생각만해도 웃겨 스파이나 볼까 그런 영화를 찾아 스파이더맨이나 봐야겠다 얼마나 해맷는데 생각해보니까 나 스파이 저걸 안 봤내 오십번봣어\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_3 \n",
      "\n",
      "Summary after \n",
      " 생활리듬이 깨져서 면역력이 떨어졌는지 이야기하고 패턴 깨진 게 제일 크다고 한다\n",
      "\n",
      "Target summary \n",
      " 생활리듬이 깨져서 면역력이 떨어진 것 같다고 하며 늦게 자지 말라고 하고 있다\n",
      "\n",
      "Text #미용과 건강# 음 생활리듬이 깨져서 면역력이 떨어졌나 그런것같아 느낌이 패턴깨진게 제일 큰것같아 응응 너무 늦게 자지말구 응응\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_4 \n",
      "\n",
      "Summary after \n",
      " 애쉬그레이로 염색을 하면 어울릴 것 같다고 한다\n",
      "\n",
      "Target summary \n",
      " 애쉬그레이로 염색하고 싶지만 가격도 비싸고 머릿결이 너무 상해서 고민이다\n",
      "\n",
      "Text #미용과 건강# 내가 애쉬그레이로 염색하면 어떨거같아 어울리려나 염색한걸 못봤어 옛날에 해보긴했는데 머릿결이 너무상해 탈색을 많이해야돼서 그렇잖아 응 그래서 고민이야 가격도 비싸고 하고싶으면 해야지 더늙기전에 맞아 나이들어서 하면 이상할거같긴해 고민하고 해버려 다른 색도 많잖아\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_5 \n",
      "\n",
      "Summary after \n",
      " 침이라도 맞아야 괜찮은데 엽기떡볶이가 만병통치라고 했다\n",
      "\n",
      "Target summary \n",
      " 엽기떡볶이을 먹으면 나을 것 같다\n",
      "\n",
      "Text #미용과 건강# 바로 병원가야 되는거 아니냥 침이라도 맞아야 괜차나 엽떡이면 나을듯 만병통치약이냐 근육통에도 엽떡 아 빨리 먹고 시팓 오늘 칼퇴해야지 고고\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_6 \n",
      "\n",
      "Summary after \n",
      " 피어싱이 막힌 것 같아서 빼놨다고 한다\n",
      "\n",
      "Target summary \n",
      " 뚫어놓은 피어싱이 막힌 줄 알았는데 아니었다\n",
      "\n",
      "Text #미용과 건강# 근데 큰일났어 지금 피어싱 막힌것같애 앗 피어싱 빼놨어 아직도 피어싱 못샀고 돈을다썼다 헉 그 피어싱 뒤에꺼 못찾아서 아 근데 진짜 막힌거야 후덜덜 그건아닌것같은데 부어서 안들어가는걸수도 막혔으면난 진짜 도마뱀인간이게 앗 그런가 으으음 피어싱 사면 뚫어주나 아 찾았음 개아프네 지쟈 아 진짜 다행이닫 으으 아프지말고 연고발라\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_7 \n",
      "\n",
      "Summary after \n",
      " 교육평가에서 교수 발표가 나와서 피피티도 만들어야 한다\n",
      "\n",
      "Target summary \n",
      " 어떤 교수의 수업을 들으면 피피티 만들어서 발표해야 한다는 게 쓰여있다고 대화한다\n",
      "\n",
      "Text #시사/교육# 음 근데 교수 발표하네 뭔발표 피피티도 만들어야돼 이거 교육평가임 응 아맞네 써있네\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_8 \n",
      "\n",
      "Summary after \n",
      " 수강신청을 2개 잡았는데 성공했다고 한다\n",
      "\n",
      "Target summary \n",
      " 수강신청하는데 두 개밖에 신청 못했다고 하자 마지막 학기에는 다 넣어 준다며 메일을 보내라는 이야기를 하고 있다\n",
      "\n",
      "Text #시사/교육# 와 나 수강신청 개망함 두 개 잡았어 대체 왜 매번 이러는걸까 와 또 실패했네 다 전공아니야 맞아 아니 막학기까지 실패하네 막학기면 다 넣어주긴 하더라 메일보내\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_9 \n",
      "\n",
      "Summary after \n",
      " 지진이 있었다고 해서 건지진이라고 하자 본인은 건다고 느끼지도 못했지만 다행이라고 한다\n",
      "\n",
      "Target summary \n",
      " 자느라 지진을 못 느꼈는데 엄마는 느꼈다\n",
      "\n",
      "Text #시사/교육# 거기지진은괜차나 지진있었다는데 응 난잔다고 느끼지도못했어 다행이다 근데엄마는느꼈대\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_10 \n",
      "\n",
      "Summary after \n",
      " 피크닉에 가고 싶다고 하자 가만히 있으라고 말한다\n",
      "\n",
      "Target summary \n",
      " 자기는 케이크를 가지고 어디에 숨어 있어야 하는지 묻는다\n",
      "\n",
      "Text #개인 및 관계# 케이크 들고다닐거아니면 피크닉가고싶다고 가만히잇어라 그래서 내가 일단 알겠다고했는데 그럼 나 어디서부터 숨어있녀 아 나 혼자 너네집에 있엌 그니깤\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_11 \n",
      "\n",
      "Summary after \n",
      " 어릴 때도 얌전했었다며 자기와 좀 반대로 되게 조용한 면 그랬던 거 같다고 한다\n",
      "\n",
      "Target summary \n",
      " 어릴 때 얌전하고 조용한 성격을 가졌었다고 이야기하고 있다\n",
      "\n",
      "Text #개인 및 관계# 넌 근데 어릴때도 얌전했자나 난 거의 그랬던것같어 나랑 좀 반대로 되게 조용한면도 있고 맞어 왜그랫는지 모르겠지만 그게 내 기본적 성격이었나봐\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_12 \n",
      "\n",
      "Summary after \n",
      " 광복절 전날인 8월에 다닌다고 욕하고 싶다고 한다\n",
      "\n",
      "Target summary \n",
      " 8월 광복절 전날부터 얼마나 아프다고 2월까지 다녀서 화가 난다\n",
      "\n",
      "Text #개인 및 관계# 얼마나 아프다고 2월까지 다니냐 그때가 8월이었은데 광복절 전날인가 웅 8월 맞아 욕하고싶다 지금 열받아서 0 쌍판때기 궁금 응 진짜\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_13 \n",
      "\n",
      "Summary after \n",
      " 클럽에 너무 가고 싶지만 현실은 그렇지 않다\n",
      "\n",
      "Target summary \n",
      " 클럽이 너무 가고 싶어졌는데 현실은 어딜 가도 시끄럽다고 했다\n",
      "\n",
      "Text #개인 및 관계# 클럽 너무 가고싶어져 근데 현실은 그냥 어 그냥 그래 요샌 어딜가도 쫌 시끄러 음 맞아 나이먹으니까 시끄러운거 싫어\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_14 \n",
      "\n",
      "Summary after \n",
      " 대국민 사기극이라서 앞으로 5년간은 쓸 일이 없겠다고 한다\n",
      "\n",
      "Target summary \n",
      " 앞으로 향후 3년간은 쓸 일이 없을 정도로 사기 수준이다\n",
      "\n",
      "Text #개인 및 관계# 와 이정도면 대국민 사기극인데 그칭 그럼 앞으로 향후 3년간은 쓸일 없겠둔 히히\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_15 \n",
      "\n",
      "Summary after \n",
      " 일단은 판사가 꿈인데 평생 일할 수는 없을 거라고 하자 만약에 진짜 멋있다고 하면 나중에 후회하지 않을 거라고 한다\n",
      "\n",
      "Target summary \n",
      " 판사가 꿈인 사람에게 평생 일할 수 없다고 말하자 되고 나서 생각하겠다 답하고 있다\n",
      "\n",
      "Text #개인 및 관계# 넌 나중에 뭐하고싶냐 난 일단은 판사가 꿈인데 그걸로 평생 일할 수는 없을걸 만약에 만약에 판사되면 은퇴하고나서는 모르겠다 그때 생각해야지\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_16 \n",
      "\n",
      "Summary after \n",
      " 저녁으로 순두부를 먹으러 왔다고 이야기한다\n",
      "\n",
      "Target summary \n",
      " 지난주에도 먹었지만 오늘도 저녁으로 순두부를 먹으러 왔다\n",
      "\n",
      "Text #개인 및 관계# 난 저녁 먹으러 옴 뭐 먹어요 순두부 집에서 먹은 지 얼마 안되지 않았어 저번주인가 괜찮아 난 또 잘 먹어 그랴 맛있게 먹고 조금만 힘내 넵 알겠어요\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_17 \n",
      "\n",
      "Summary after \n",
      " 요즘 못 갔다고 하길래 마음이 아파서 스타벅스를 못갔다\n",
      "\n",
      "Target summary \n",
      " 오빠가 요즘 스타벅스를 못 갔다는 말에 마음이 아파서 스타벅스 기프티콘을 선물했다\n",
      "\n",
      "Text #개인 및 관계# 먹엉 먹고 힘내쟈 갑자기 왠 스벅을 요새 스벅 못갔다고 하길래 마음아파서 내마음이라고 생각해주라 오늘갔는뎅 그래서 그냥 돈도 돈인데 시간도 없고 그래서 잘 안가성 일단 잘먹을게요 그럼 거절해 나는 그냥 오빠가 맛있게 먹었으면 하는 마음에서 힝 맛있게 먹을게용 고마워요 진짜 잘먹을겡 난 마음까지 아플줄은 몰랐징\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_18 \n",
      "\n",
      "Summary after \n",
      " 언니는 씻었고 자기는 샤워를 안 해서 모자를 쓰고 가야겠다고 한다\n",
      "\n",
      "Target summary \n",
      " 언니는 어제 샤워하고 잤다고 해서 모자를 쓰고 나간다고 하였다\n",
      "\n",
      "Text #개인 및 관계# 언니는 씻어얗 어제 씻규 잤엉 샤워 아 그럼 그냥 모자 쓰고 가야겠다 뭐여 뭔즤 알즤 오늘 꼭 씻은다매\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_19 \n",
      "\n",
      "Summary after \n",
      " 향수 테스트를 했는데 잘 어울리는 사람이 쓸 거 같은 향수와 멱살잡이를 했다\n",
      "\n",
      "Target summary \n",
      " 향수 테스트를 했는데 사이가 안 좋은 이성이 쓸 것 같은 향수와 잘 어울리는 이성이 쓸 것 같은 향수가 같았다고 한다\n",
      "\n",
      "Text #개인 및 관계# 향수테스트 했는데 거기서 잘 어울리는 이성이 쓸거 같은 향수랑 나랑 멱살잡이인가 아무튼 사이 안좋을 이성이 쓸거 같은 향수 알려줬는데 두개가 같음 어쩌란거야 그니까 그게머냐고 테스트해주는사람이머래 사람이 아니고 페이지였음 링크보내줄게 너도 한번 그 테스트 해봐\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_20 \n",
      "\n",
      "Summary after \n",
      " 멍이 안 들면 또 괴롭힐 거라고 하니 괴롭히지 말고 내가 괴롭혀야 한다고 한다\n",
      "\n",
      "Target summary \n",
      " 괴롭히지 말라고 하면 괴롭히지 않을 것이라고 해서 내일은 가만히 있을 것이다\n",
      "\n",
      "Text #개인 및 관계# 멍 안들면 또 괴롭힐꺼양 괴롭히지 말라묜 하지 말아야지모 그롬 내가 괴롭혀야징 에 그럼 나는 내일 가만히 잇어야겟당 룰룰루 가만히잇을수잇나용 당근 가만히 잇어야겟당\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_21 \n",
      "\n",
      "Summary after \n",
      " 28살이면 채팅으로 만났다가 봉변이 아니라고 한다\n",
      "\n",
      "Target summary \n",
      " 채팅으로 만나고 애플리케이션으로 만나서 모텔을 왜 간 건지 모르겠다\n",
      "\n",
      "Text #개인 및 관계# 28살이면 진짜 뭣도 모르고 걍 채팅으로 만났다가 걍 우리같은 애자나 봉변아니가 저런사람일줄알았겠냐고 근데 어플로 만낫는데 모텔을 왜 간겨 끌려간건가 몰라\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_22 \n",
      "\n",
      "Summary after \n",
      " 벚꽃 준비를 거의 다 했고 퀘스트 11이 끝이다\n",
      "\n",
      "Target summary \n",
      " 벚꽃잎 개수가 모자라서 펭귄을 못 샀다지만 퀘스트만 다하면 펭귄을 살 것이다\n",
      "\n",
      "Text #개인 및 관계# 벚꽃은 많이 했어여 퀘스트 11하고잇는데 13이 끝이예여 우왕 거의 다햇네요 내일 또 열심히 구경해야징 네근데 벚꽃잎갯수가 모잘라서 펭귄을 아직 하나도 못삿아여 퀘스트에 급급해서 아직 시간 많이 있으니까 데려올거잖아여 마쟈요 퀘스트만 다하면 이제 벚꽃잎쓸일이앖어서 펭귄살거예여 올해 못본 벚꽃 거기서 보니까 좋네여\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_23 \n",
      "\n",
      "Summary after \n",
      " 부모님이 마음에 들지 않아서 고르지 못하겠다 말한다고 이야기하고 있다\n",
      "\n",
      "Target summary \n",
      " 본인과 부모님 모두 둘 다 마음에 들어서 고르지 못하고 있다\n",
      "\n",
      "Text #개인 및 관계# 엄마랑아빠도 둘다맘에들어서못고르겟대 돌아불것다짖짜 개웃 너가원하는걸 픽해그러면 훜훜훜 못골라 결정장애쓰 유후 유후 마지막 선택은 너의 것이가 휴\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_24 \n",
      "\n",
      "Summary after \n",
      " 또 한 번도 만나보지 못한 사람이라고 새로운 타입이라고 한다\n",
      "\n",
      "Target summary \n",
      " 할 때마다 한 번도 만나보지 못 한 새로운 사람이라고 해서 신기하다고 한다\n",
      "\n",
      "Text #개인 및 관계# 새로운 타입이래 또 한 번도 만나보지 못 한 사람이래 이거 아니야 어떤 사람 만나는 거야 저번에도 이 리딩이었는데 맨날 새로운 사람이래 도대체 그 사람이 누구죠 신기하다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_25 \n",
      "\n",
      "Summary after \n",
      " 같이 다니던 친구가 있다고 하지 않았냐며 왕따라고 한다\n",
      "\n",
      "Target summary \n",
      " 같이 다니던 친구들이 모두 휴학해서 학교를 다니 때 혼자 다니는 것이 싫어서 종강을 했으면 좋겠다고 하고 있다\n",
      "\n",
      "Text #개인 및 관계# 웅 나 왕따야 흑흑 빨리 종강하고싶다 같이다니던친구있다고하지않았어 다 휴학해서 혼자다닌다고 했자누 아맞다 넌저번에 미리하구 힝 그거 내 미래야 다음학기의 나 눈물난다 가기싫겟다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_26 \n",
      "\n",
      "Summary after \n",
      " 교수님한테 일하라고 하는 것은 상사에게 말하기라고 한다\n",
      "\n",
      "Target summary \n",
      " 제일 효과 빠른 방법은 상사에게 말하기여서 교수님에게 이르려고 한다\n",
      "\n",
      "Text #개인 및 관계# 난 교수님한테 일를라고 역시 제일 효과 빠른 건 상사에게 말하기 맞아 제일 빠른건 상사 내건 사이트도 느리고 느리고 이래서 권력이 중요한가봐요 인터넷도 빠르고 컴퓨터도 좋은 거 쓰고 역시 다르다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_27 \n",
      "\n",
      "Summary after \n",
      " 어제 그렇게 잤는데 일찍 일어나서 아침에 청소를 해야겠다고 한다\n",
      "\n",
      "Target summary \n",
      " 아침에 일어나서 청소를 했다고 하자 잘했다고 한다\n",
      "\n",
      "Text #개인 및 관계# 인나따아앙 출근주우웅 응웅 일찍 일어났네 어제 그렇게 잣는데 일찍 인나야지에 청소 아침에 싸악햇다 잘햇다아아엉\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_28 \n",
      "\n",
      "Summary after \n",
      " 햇반을 사 왔다고 하자 자기도 회사에서 12개를 가져왔다고 한다\n",
      "\n",
      "Target summary \n",
      " 쌀을 샀냐고 해서 햇반을 사 왔다고 하니 나도 회사에서 12개 가져왔다고 이야기하고 있다\n",
      "\n",
      "Text #식음료# 쌀 샀어 햇반사왔어 헐 나도 회사에서 가져옴 12개 쿠쿠 헐 그거 어캐줄랴구 나중에주게\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_29 \n",
      "\n",
      "Summary after \n",
      " 비린내가 나는 것 같지만 씻어서 냉동식품이 됐다\n",
      "\n",
      "Target summary \n",
      " 옥수수에서 비린내가 나는 것 같다고 하자 씻어서 냉동 보관을 해야 하는데 그냥 보관해서 그런 것 같다고 한다\n",
      "\n",
      "Text #식음료# 옥슈슈 먹었니 응 맛나 근데 왜 비린내 나는거 같지 좀 나지 근게 씻어서 냉동보관해야하는데 그냥 냉동보관해서 그른가 응응 맛은 잇엇는데 냄새가 좀 나더랏\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_30 \n",
      "\n",
      "Summary after \n",
      " 내가 어떻게 해야 할지 감이 안 온다고 하니 딸기 때문에 걱정이라고 한다\n",
      "\n",
      "Target summary \n",
      " 딸기 때문에 걱정인데 카페를 하면 딸기청 같은 거나 라테를 만들며 도와주려 한다\n",
      "\n",
      "Text #식음료# 후 나는 진짜 딸기때매 걱정이햐 딸기 농장 왜왜 내가 어캐해야할지감이안와 카페를 해도 잘할수잇을지머르겟고 너가 어떤 거 하게 된고야 구냥 도와드리기만 하는거 아니였닝 딸기청만들어서 팔고 그런거 카페 할까하는데 딸기라떼팔고 그런데 감이안와후\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_31 \n",
      "\n",
      "Summary after \n",
      " 오칼이 정말 맛있겠다고 하니 뜨끈한 국물하며 먹고 싶다고 한다\n",
      "\n",
      "Target summary \n",
      " 오징어 칼국수 먹으러 한남대에 오라고 하니까 미세먼지만 아니었으면 바로 갔을 거라고 한다\n",
      "\n",
      "Text #식음료# 오칼 와 대박 맛이 겟가 역시 오칼은 크 뜨끈한 국물하며 먹고싶다 진심 한남대와 미세먼지만 아니었으면 바로 갔다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_32 \n",
      "\n",
      "Summary after \n",
      " 어제 푸드위크가서 산 식품이 진짜 맛있다며 다이어트가 망한다고 하고 있다\n",
      "\n",
      "Target summary \n",
      " 푸드위크 가서 사 온 것들이 입맛에 딱 맞아서 한 달 참고 다음 달에 사 먹을 것이다\n",
      "\n",
      "Text #식음료# 이거 어제 푸드위크가서샀는데 진짜 존맛탱 두봉먹었다방금 다이어트 망함 저거 중국에서 먹던거 존맛 겟다 오늘 회먹어서 식욕증진햇나 오늘 폭주 저거 진짜맛이써 내입맛에딱맞음 한달참고 담달에 사먹어야지 두봉밖에안남음 두통사올걸 만원밖에안하등데 저거 무한정 먹을 수 잇을 간식 담달 아직 멀엇다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_33 \n",
      "\n",
      "Summary after \n",
      " 어떤 로제 파스타를 해야 할지 메뉴를쫙 적어놓으라고 한다\n",
      "\n",
      "Target summary \n",
      " 꾸덕꾸덕하게 소스가 많은 파스타를 해달라고 했다\n",
      "\n",
      "Text #식음료# 어떤 로제파스타를 해야할지 메뉴 쫙 적어놔 나잘할거같은데 알게떠 개웃겨 잘할거 같뎈 무슨 자신감이야 여뷰 진심인데 여부 라면 경력으로 익힌 면빨의 익힘 파악 정확한 순도높은 면빨과 걸쭉한 카레 요리로 인한 그 찐득하고 맛깔나는 상태 그 상태도 잘파악함 꾸덕꾸덕 소스많은 파스타해줘\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_34 \n",
      "\n",
      "Summary after \n",
      " 엄마가 마트에서 겨울 사과 수프를 사 왔는데 맛있다\n",
      "\n",
      "Target summary \n",
      " 엄마가 마트에서 사 온 겨울 사과는 아삭하고 맛있어서 주스로 해 먹어도 좋을 것 같다\n",
      "\n",
      "Text #식음료# 나 엄마가 어제 응 마트에서 겨울 사과라고 부사 사왔는데 너무 와삭하고 맛있다 역시 사과는 와삭해야 돼 사과 좋지 갈아먹어도 맛있겠다 아침에 쥬스로 먹어도 좋지\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "idx_35 \n",
      "\n",
      "Summary after \n",
      " 본죽에 신메뉴가 나왔다는 걸 왜 못 봤냐고 한다\n",
      "\n",
      "Target summary \n",
      " 본죽에서 신메뉴로 6쪽 마늘 닭죽이 나왔는데 마늘이 토핑처럼 들어가 있다\n",
      "\n",
      "Text #식음료# 아 본죽에 신메뉴 나온 거 알아 오 신메뉴 나온 걸 왜 못봤지 언니는 오늘 갔었는데 말이야 뭔데 6쪽 마늘 닭죽이라고 꿀간장 베이스에다가 닭다리살 구이가 가득 들어갔대 마늘 닭죽이면 마늘도 토핑처럼 들어갔으려나 오 맞았어 사진을 보니까 구운 마늘 마늘 후레이크 이 둘 중 하나가 가득 들어있더라구 와아 어느정도 보장된 맛일 거 같아\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(summaries_after_tuning)):\n",
    "    print('idx_{} '.format(i))\n",
    "  #  print(\"Summary before \\n\", summaries_before_tuning[i])\n",
    "    print()\n",
    "    print(\"Summary after \\n\", summaries_after_tuning[i])\n",
    "    print()\n",
    "    print(\"Target summary \\n\", test_samples[\"Summary\"][i])\n",
    "    print()\n",
    "    print('Text', test_samples[\"Text\"][i])\n",
    "    print('-'*100)\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf141612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # step 50000\n",
    "# print(\"ROUGE 1 SCORE: \",rouge.compute(predictions=summaries_after_tuning, references=test_samples[\"Summary\"],\\\n",
    "#                                             rouge_types=[\"rouge1\"])[\"rouge1\"].mid)\n",
    "# print(\"ROUGE 2 SCORE: \",rouge.compute(predictions=summaries_after_tuning, references=test_samples[\"Summary\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n",
    "# print(\"ROUGE L SCORE: \",rouge.compute(predictions=summaries_after_tuning, references=test_samples[\"Summary\"], rouge_types=[\"rougeL\"])[\"rougeL\"].mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2dc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5722da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
