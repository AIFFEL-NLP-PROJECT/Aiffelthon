{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba67d8e1",
   "metadata": {},
   "source": [
    "# DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903966d",
   "metadata": {},
   "source": [
    "## 1. Import 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af10183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.10.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.10.0)\n",
      "Requirement already satisfied: rouge_score in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.1.2)\n",
      "Requirement already satisfied: datasets in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.7.1)\n",
      "Requirement already satisfied: transformers==4.24.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (4.24.0)\n",
      "Requirement already satisfied: transformer-utils in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (0.1.1)\n",
      "Requirement already satisfied: packaging in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: wandb in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.13.5)\n",
      "Requirement already satisfied: pandas in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.3.5)\n",
      "Requirement already satisfied: numpy in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (1.21.6)\n",
      "Requirement already satisfied: matplotlib in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (3.5.3)\n",
      "Requirement already satisfied: dataclasses in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (0.6)\n",
      "Requirement already satisfied: tqdm in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from torch==1.10.0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (5.1.0)\n",
      "Requirement already satisfied: filelock in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformers==4.24.0->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from rouge_score->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: nltk in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from rouge_score->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (10.0.1)\n",
      "Requirement already satisfied: dill<0.3.7 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (2022.11.0)\n",
      "Requirement already satisfied: xxhash in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.14)\n",
      "Requirement already satisfied: colorcet in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformer-utils->-r requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: seaborn in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from transformer-utils->-r requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from packaging->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (4.21.9)\n",
      "Requirement already satisfied: setuptools in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (65.5.0)\n",
      "Requirement already satisfied: setproctitle in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (1.11.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (1.0.11)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (5.9.4)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (8.1.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (3.1.29)\n",
      "Requirement already satisfied: pathtools in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from wandb->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 8)) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 11)) (4.38.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (22.1.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 7)) (4.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from requests->transformers==4.24.0->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from colorcet->transformer-utils->-r requirements.txt (line 5)) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from importlib-metadata->transformers==4.24.0->-r requirements.txt (line 4)) (3.10.0)\n",
      "Requirement already satisfied: joblib in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from nltk->rouge_score->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: param>=1.7.0 in /home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages (from pyct>=0.4.4->colorcet->transformer-utils->-r requirements.txt (line 5)) (1.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d795fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6228bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    LineByLineTextDataset,\n",
    "    EarlyStoppingCallback\n",
    "\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9aa4d3",
   "metadata": {},
   "source": [
    "## 2. 모델 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3960551d",
   "metadata": {},
   "source": [
    "### 1) 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fa5bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoints = \"gogamza/kobart-base-v2\" #/MLM_pretrain_3ep_221121/checkpoint-33000\"#\"gogamza/kobart-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4c81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_params(model):\n",
    "    for par in model.parameters():\n",
    "        par.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d206d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_params(model.get_encoder()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54087112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train params in Summarization Model : 159\n"
     ]
    }
   ],
   "source": [
    "train_p = [p for p in model.parameters() if p.requires_grad] \n",
    "print(f'Length of train params in Summarization Model : {len(train_p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de888ce9",
   "metadata": {},
   "source": [
    "### 2) 데이터 불러오기 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ef28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_textfile_path = \"data/train_text.csv\"\n",
    "val_textfile_path = \"data/val_text.csv\"\n",
    "\n",
    "with open(train_textfile_path, encoding=\"utf-8\") as f:\n",
    "            train_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]     \n",
    "\n",
    "with open(val_textfile_path, encoding=\"utf-8\") as f:\n",
    "            val_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78abbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_textlines[0]\n",
    "del val_textlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c04fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(zip(train_textlines), columns=['Text'])\n",
    "val_df = pd.DataFrame(zip(val_textlines), columns=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c6a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(inplace=True, drop=True)\n",
    "val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7cd522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  그럼 날짜는 가격 큰 변동 없으면 6 28-7 13로 확정할까 우리 비행포함 15일...\n",
       "1  kf마스크만 5부제 하는거지 응 면마스크는 아무때나 사도될껀 면마스크말고 부직포 마...\n",
       "2  아 근데 케이크 업체들 봤는데 중앙동쪽 거기는 맛만있고 디자인은 그냥그런것같애 그러...\n",
       "3  칫솔사야하는데 쓱으로 살까 뭘 칫솔사는것까지 물어보시남 아 그 왕칫솔 또 사려나 싶...\n",
       "4  잠도안오네 얼릉 고구마츄 먹고싶단 그게 그렇게 맛있었어 아주 여보 빼이보릿 되버렸네..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edfe37",
   "metadata": {},
   "source": [
    "## 3. 데이터 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8882a08",
   "metadata": {},
   "source": [
    "### 1) dataset으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7e403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df)\n",
    "val_data = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d718d",
   "metadata": {},
   "source": [
    "### 2) EDA 바탕으로 길이 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5ef1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input = 128\n",
    "max_target = 128\n",
    "batch_size = 16\n",
    "ignore_index = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88650a1",
   "metadata": {},
   "source": [
    "### 3) 토큰화 함수 구현 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d7d78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ignored_data(inputs, max_len, ignore_index):\n",
    "    if len(inputs) < max_len:\n",
    "        pad = [ignore_index] *(max_len - len(inputs)) # ignore_index즉 -100으로 패딩을 만들 것인데 max_len - lne(inpu)\n",
    "        inputs = np.concatenate([inputs, pad])\n",
    "    else:\n",
    "        inputs = inputs[:max_len]\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43ae2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_to_process):\n",
    "    label_id= []\n",
    "    label_ids = []\n",
    "\n",
    "    inputs = [dialogue for dialogue in data_to_process['Text']]\n",
    "    model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
    "\n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        label_id.append(tokenizer.encode(data_to_process['Text'][i]))  \n",
    "    for i in range(len(data_to_process['Text'])):\n",
    "        label_id[i].append(tokenizer.eos_token_id)\n",
    "        label_ids.append(add_ignored_data(label_id[i], max_target, ignore_index))\n",
    "\n",
    "    model_inputs['labels'] = label_ids\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd84e382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f5c67052974009939b0d015c672233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586be1154ef0494aa4f849b5ff242a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenize_data = train_data.map(preprocess_data, batched = True, remove_columns=['Text'])\n",
    "val_tokenize_data = val_data.map(preprocess_data, batched = True, remove_columns=['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee9af0",
   "metadata": {},
   "source": [
    "## 4. 학습을 진행하기 위한 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b659c2e",
   "metadata": {},
   "source": [
    "### 1) config 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43fb52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "model.config.eos_token_id = tokenizer.eos_token_id                        \n",
    "model.config.max_length = 128\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 5\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e29516",
   "metadata": {},
   "source": [
    "### 2) rounge 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f921544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
    "    rouge_output2 = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    rouge_outputL = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "        \n",
    "        \"rouge2_precision\": round(rouge_output2.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output2.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output2.fmeasure, 4), \n",
    "        \n",
    "        \"rougeL_precision\": round(rouge_outputL.precision, 4),\n",
    "        \"rougeL_recall\": round(rouge_outputL.recall, 4),\n",
    "        \"rougeL_fmeasure\": round(rouge_outputL.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7134965",
   "metadata": {},
   "source": [
    "### 3) arguments 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c308ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"chckpoint/MLM_pretrain_basev2_freezing\",\n",
    "    num_train_epochs=50,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=16,  # demo\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=3e-05,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True, # 생성기능을 사용하고 싶다고 지정한다.\n",
    "    logging_dir=\"logs2\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=10,\n",
    "    #evaluation_strategy = \"steps\",# step별로 2버 loss가 오르는거 아니면 계속 반복하는듯\n",
    "    #load_best_model_at_end = True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123b5d6",
   "metadata": {},
   "source": [
    "### 4) data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "544b4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01635f0c",
   "metadata": {},
   "source": [
    "### 5) train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9944ec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model, \n",
    "    training_args,\n",
    "    train_dataset=train_tokenize_data,\n",
    "    eval_dataset=val_tokenize_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef5c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/jx7789/anaconda3/envs/dohwan/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 279992\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 875000\n",
      "  Number of trainable parameters = 57501696\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjx7789\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jx7789/Download/koBART/wandb/run-20221125_155627-1wmjz0vy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jx7789/huggingface/runs/1wmjz0vy\" target=\"_blank\">chckpoint/MLM_pretrain_basev2_freezing</a></strong> to <a href=\"https://wandb.ai/jx7789/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='627001' max='875000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [627001/875000 26:13:44 < 10:22:27, 6.64 it/s, Epoch 35.83/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.161300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.140700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>5.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>5.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>5.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>5.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>4.966300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.970700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>4.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>4.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>4.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>4.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>4.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>4.892700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>4.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>4.899000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>4.866100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>4.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>4.876200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>4.858500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>4.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>4.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>4.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>4.836900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>4.828100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>4.835900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>4.833900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>4.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>4.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>4.802000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>4.798800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>4.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>4.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>4.809800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>4.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>4.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>4.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>4.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>4.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>4.784800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>4.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>4.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>4.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>4.765800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>4.744300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>4.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>4.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>4.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>4.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>4.744200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>4.751600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>4.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>4.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>4.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>4.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>4.719300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>4.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>4.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>4.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>4.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>4.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>4.705200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>4.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>4.687200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>4.708000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>4.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>4.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>4.671100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>4.674600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>4.690200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>4.669100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>4.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>4.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>4.648600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>4.695200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>4.677800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>4.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>4.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>4.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>4.656400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>4.672600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>4.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>4.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>4.638700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>4.666100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>4.645400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>4.656600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>4.662900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>4.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>4.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>4.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>4.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>4.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>4.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>4.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>4.610300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>4.631100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>4.615600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>4.599100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>4.615800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>4.619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>4.621900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>4.610200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>4.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>4.630500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>4.607100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>4.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>4.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>4.586600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>4.625800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>4.607900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>4.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63500</td>\n",
       "      <td>4.600800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>4.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64500</td>\n",
       "      <td>4.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>4.600900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65500</td>\n",
       "      <td>4.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>4.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66500</td>\n",
       "      <td>4.595100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>4.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>4.607100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>4.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68500</td>\n",
       "      <td>4.582400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>4.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69500</td>\n",
       "      <td>4.619900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>4.588600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70500</td>\n",
       "      <td>4.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>4.563700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71500</td>\n",
       "      <td>4.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>4.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>4.576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>4.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73500</td>\n",
       "      <td>4.586600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>4.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74500</td>\n",
       "      <td>4.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>4.552600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75500</td>\n",
       "      <td>4.575300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>4.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76500</td>\n",
       "      <td>4.554500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>4.596300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>4.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>4.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78500</td>\n",
       "      <td>4.559200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>4.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79500</td>\n",
       "      <td>4.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>4.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80500</td>\n",
       "      <td>4.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>4.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81500</td>\n",
       "      <td>4.534200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>4.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82500</td>\n",
       "      <td>4.561100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>4.542300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83500</td>\n",
       "      <td>4.556600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>4.573100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84500</td>\n",
       "      <td>4.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>4.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85500</td>\n",
       "      <td>4.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>4.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86500</td>\n",
       "      <td>4.548100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>4.559400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87500</td>\n",
       "      <td>4.569200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>4.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88500</td>\n",
       "      <td>4.535900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>4.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89500</td>\n",
       "      <td>4.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>4.514600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90500</td>\n",
       "      <td>4.521100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>4.549800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91500</td>\n",
       "      <td>4.527500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>4.530800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92500</td>\n",
       "      <td>4.521500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>4.547600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93500</td>\n",
       "      <td>4.544600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>4.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94500</td>\n",
       "      <td>4.538500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>4.543300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95500</td>\n",
       "      <td>4.547400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>4.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96500</td>\n",
       "      <td>4.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97000</td>\n",
       "      <td>4.513700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97500</td>\n",
       "      <td>4.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>4.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98500</td>\n",
       "      <td>4.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>4.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99500</td>\n",
       "      <td>4.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>4.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100500</td>\n",
       "      <td>4.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101000</td>\n",
       "      <td>4.503800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101500</td>\n",
       "      <td>4.514700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102000</td>\n",
       "      <td>4.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102500</td>\n",
       "      <td>4.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103000</td>\n",
       "      <td>4.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103500</td>\n",
       "      <td>4.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104000</td>\n",
       "      <td>4.507500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104500</td>\n",
       "      <td>4.502300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>4.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105500</td>\n",
       "      <td>4.499200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106000</td>\n",
       "      <td>4.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106500</td>\n",
       "      <td>4.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107000</td>\n",
       "      <td>4.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107500</td>\n",
       "      <td>4.474800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108000</td>\n",
       "      <td>4.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108500</td>\n",
       "      <td>4.505500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109000</td>\n",
       "      <td>4.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109500</td>\n",
       "      <td>4.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>4.485800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110500</td>\n",
       "      <td>4.490700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111000</td>\n",
       "      <td>4.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111500</td>\n",
       "      <td>4.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112000</td>\n",
       "      <td>4.484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112500</td>\n",
       "      <td>4.501000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113000</td>\n",
       "      <td>4.471900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113500</td>\n",
       "      <td>4.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114000</td>\n",
       "      <td>4.469800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114500</td>\n",
       "      <td>4.484100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>4.475400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115500</td>\n",
       "      <td>4.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116000</td>\n",
       "      <td>4.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116500</td>\n",
       "      <td>4.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117000</td>\n",
       "      <td>4.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117500</td>\n",
       "      <td>4.490200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118000</td>\n",
       "      <td>4.503500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118500</td>\n",
       "      <td>4.486300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119000</td>\n",
       "      <td>4.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119500</td>\n",
       "      <td>4.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>4.478400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120500</td>\n",
       "      <td>4.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121000</td>\n",
       "      <td>4.477100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121500</td>\n",
       "      <td>4.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122000</td>\n",
       "      <td>4.485400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122500</td>\n",
       "      <td>4.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123000</td>\n",
       "      <td>4.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123500</td>\n",
       "      <td>4.473300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124000</td>\n",
       "      <td>4.469800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124500</td>\n",
       "      <td>4.474200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>4.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125500</td>\n",
       "      <td>4.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126000</td>\n",
       "      <td>4.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126500</td>\n",
       "      <td>4.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127000</td>\n",
       "      <td>4.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127500</td>\n",
       "      <td>4.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128000</td>\n",
       "      <td>4.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128500</td>\n",
       "      <td>4.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129000</td>\n",
       "      <td>4.471400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129500</td>\n",
       "      <td>4.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>4.482100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130500</td>\n",
       "      <td>4.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131000</td>\n",
       "      <td>4.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131500</td>\n",
       "      <td>4.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132000</td>\n",
       "      <td>4.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132500</td>\n",
       "      <td>4.460900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133000</td>\n",
       "      <td>4.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133500</td>\n",
       "      <td>4.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134000</td>\n",
       "      <td>4.466500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134500</td>\n",
       "      <td>4.462600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>4.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135500</td>\n",
       "      <td>4.453500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136000</td>\n",
       "      <td>4.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136500</td>\n",
       "      <td>4.464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137000</td>\n",
       "      <td>4.451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137500</td>\n",
       "      <td>4.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>4.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138500</td>\n",
       "      <td>4.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139000</td>\n",
       "      <td>4.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139500</td>\n",
       "      <td>4.445400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>4.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140500</td>\n",
       "      <td>4.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141000</td>\n",
       "      <td>4.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141500</td>\n",
       "      <td>4.417700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142000</td>\n",
       "      <td>4.443500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142500</td>\n",
       "      <td>4.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143000</td>\n",
       "      <td>4.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143500</td>\n",
       "      <td>4.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144000</td>\n",
       "      <td>4.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144500</td>\n",
       "      <td>4.454800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>4.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145500</td>\n",
       "      <td>4.449500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146000</td>\n",
       "      <td>4.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146500</td>\n",
       "      <td>4.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147000</td>\n",
       "      <td>4.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147500</td>\n",
       "      <td>4.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148000</td>\n",
       "      <td>4.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148500</td>\n",
       "      <td>4.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149000</td>\n",
       "      <td>4.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149500</td>\n",
       "      <td>4.441100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>4.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150500</td>\n",
       "      <td>4.432400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151000</td>\n",
       "      <td>4.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151500</td>\n",
       "      <td>4.438700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152000</td>\n",
       "      <td>4.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152500</td>\n",
       "      <td>4.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153000</td>\n",
       "      <td>4.432900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153500</td>\n",
       "      <td>4.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154000</td>\n",
       "      <td>4.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154500</td>\n",
       "      <td>4.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>4.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155500</td>\n",
       "      <td>4.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156000</td>\n",
       "      <td>4.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156500</td>\n",
       "      <td>4.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157000</td>\n",
       "      <td>4.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157500</td>\n",
       "      <td>4.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158000</td>\n",
       "      <td>4.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158500</td>\n",
       "      <td>4.413200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159000</td>\n",
       "      <td>4.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159500</td>\n",
       "      <td>4.425800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>4.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160500</td>\n",
       "      <td>4.426400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161000</td>\n",
       "      <td>4.434000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161500</td>\n",
       "      <td>4.422400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162000</td>\n",
       "      <td>4.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162500</td>\n",
       "      <td>4.407800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163000</td>\n",
       "      <td>4.437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163500</td>\n",
       "      <td>4.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164000</td>\n",
       "      <td>4.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164500</td>\n",
       "      <td>4.427300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>4.412400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165500</td>\n",
       "      <td>4.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166000</td>\n",
       "      <td>4.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166500</td>\n",
       "      <td>4.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167000</td>\n",
       "      <td>4.436700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167500</td>\n",
       "      <td>4.424700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168000</td>\n",
       "      <td>4.441800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168500</td>\n",
       "      <td>4.417600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169000</td>\n",
       "      <td>4.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169500</td>\n",
       "      <td>4.410100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>4.401100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170500</td>\n",
       "      <td>4.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171000</td>\n",
       "      <td>4.417800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171500</td>\n",
       "      <td>4.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172000</td>\n",
       "      <td>4.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172500</td>\n",
       "      <td>4.422600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173000</td>\n",
       "      <td>4.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173500</td>\n",
       "      <td>4.426800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174000</td>\n",
       "      <td>4.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174500</td>\n",
       "      <td>4.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175000</td>\n",
       "      <td>4.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175500</td>\n",
       "      <td>4.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176000</td>\n",
       "      <td>4.419600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176500</td>\n",
       "      <td>4.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177000</td>\n",
       "      <td>4.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177500</td>\n",
       "      <td>4.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178000</td>\n",
       "      <td>4.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178500</td>\n",
       "      <td>4.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179000</td>\n",
       "      <td>4.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179500</td>\n",
       "      <td>4.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>4.416600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180500</td>\n",
       "      <td>4.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181000</td>\n",
       "      <td>4.414800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181500</td>\n",
       "      <td>4.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182000</td>\n",
       "      <td>4.419400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182500</td>\n",
       "      <td>4.411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183000</td>\n",
       "      <td>4.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183500</td>\n",
       "      <td>4.395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184000</td>\n",
       "      <td>4.415800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184500</td>\n",
       "      <td>4.399200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185000</td>\n",
       "      <td>4.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185500</td>\n",
       "      <td>4.422100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186000</td>\n",
       "      <td>4.404700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186500</td>\n",
       "      <td>4.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187000</td>\n",
       "      <td>4.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187500</td>\n",
       "      <td>4.429700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188000</td>\n",
       "      <td>4.404900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188500</td>\n",
       "      <td>4.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189000</td>\n",
       "      <td>4.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189500</td>\n",
       "      <td>4.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>4.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190500</td>\n",
       "      <td>4.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191000</td>\n",
       "      <td>4.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191500</td>\n",
       "      <td>4.395400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192000</td>\n",
       "      <td>4.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192500</td>\n",
       "      <td>4.421500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193000</td>\n",
       "      <td>4.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193500</td>\n",
       "      <td>4.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194000</td>\n",
       "      <td>4.385200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194500</td>\n",
       "      <td>4.393700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>4.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195500</td>\n",
       "      <td>4.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196000</td>\n",
       "      <td>4.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196500</td>\n",
       "      <td>4.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197000</td>\n",
       "      <td>4.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197500</td>\n",
       "      <td>4.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198000</td>\n",
       "      <td>4.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198500</td>\n",
       "      <td>4.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199000</td>\n",
       "      <td>4.381100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199500</td>\n",
       "      <td>4.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>4.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200500</td>\n",
       "      <td>4.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201000</td>\n",
       "      <td>4.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201500</td>\n",
       "      <td>4.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202000</td>\n",
       "      <td>4.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202500</td>\n",
       "      <td>4.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203000</td>\n",
       "      <td>4.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203500</td>\n",
       "      <td>4.390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204000</td>\n",
       "      <td>4.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204500</td>\n",
       "      <td>4.389600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205000</td>\n",
       "      <td>4.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205500</td>\n",
       "      <td>4.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206000</td>\n",
       "      <td>4.400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206500</td>\n",
       "      <td>4.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207000</td>\n",
       "      <td>4.414800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207500</td>\n",
       "      <td>4.395900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208000</td>\n",
       "      <td>4.405400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208500</td>\n",
       "      <td>4.411400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209000</td>\n",
       "      <td>4.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209500</td>\n",
       "      <td>4.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>4.386700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210500</td>\n",
       "      <td>4.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211000</td>\n",
       "      <td>4.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211500</td>\n",
       "      <td>4.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212000</td>\n",
       "      <td>4.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212500</td>\n",
       "      <td>4.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213000</td>\n",
       "      <td>4.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213500</td>\n",
       "      <td>4.374100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214000</td>\n",
       "      <td>4.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214500</td>\n",
       "      <td>4.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215000</td>\n",
       "      <td>4.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215500</td>\n",
       "      <td>4.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216000</td>\n",
       "      <td>4.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216500</td>\n",
       "      <td>4.391900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217000</td>\n",
       "      <td>4.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217500</td>\n",
       "      <td>4.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218000</td>\n",
       "      <td>4.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218500</td>\n",
       "      <td>4.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219000</td>\n",
       "      <td>4.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219500</td>\n",
       "      <td>4.393700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>4.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220500</td>\n",
       "      <td>4.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221000</td>\n",
       "      <td>4.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221500</td>\n",
       "      <td>4.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222000</td>\n",
       "      <td>4.389200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222500</td>\n",
       "      <td>4.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223000</td>\n",
       "      <td>4.392900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223500</td>\n",
       "      <td>4.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224000</td>\n",
       "      <td>4.382800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224500</td>\n",
       "      <td>4.404300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225000</td>\n",
       "      <td>4.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225500</td>\n",
       "      <td>4.396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226000</td>\n",
       "      <td>4.384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226500</td>\n",
       "      <td>4.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227000</td>\n",
       "      <td>4.379700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227500</td>\n",
       "      <td>4.392800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228000</td>\n",
       "      <td>4.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228500</td>\n",
       "      <td>4.370100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229000</td>\n",
       "      <td>4.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229500</td>\n",
       "      <td>4.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230000</td>\n",
       "      <td>4.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230500</td>\n",
       "      <td>4.380200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231000</td>\n",
       "      <td>4.375300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231500</td>\n",
       "      <td>4.377400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232000</td>\n",
       "      <td>4.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232500</td>\n",
       "      <td>4.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233000</td>\n",
       "      <td>4.390400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233500</td>\n",
       "      <td>4.373300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234000</td>\n",
       "      <td>4.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234500</td>\n",
       "      <td>4.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235000</td>\n",
       "      <td>4.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235500</td>\n",
       "      <td>4.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236000</td>\n",
       "      <td>4.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236500</td>\n",
       "      <td>4.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237000</td>\n",
       "      <td>4.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237500</td>\n",
       "      <td>4.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238000</td>\n",
       "      <td>4.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238500</td>\n",
       "      <td>4.367700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239000</td>\n",
       "      <td>4.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239500</td>\n",
       "      <td>4.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>4.366500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240500</td>\n",
       "      <td>4.379700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241000</td>\n",
       "      <td>4.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241500</td>\n",
       "      <td>4.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242000</td>\n",
       "      <td>4.396400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242500</td>\n",
       "      <td>4.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243000</td>\n",
       "      <td>4.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243500</td>\n",
       "      <td>4.361100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244000</td>\n",
       "      <td>4.374500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244500</td>\n",
       "      <td>4.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245000</td>\n",
       "      <td>4.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245500</td>\n",
       "      <td>4.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246000</td>\n",
       "      <td>4.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246500</td>\n",
       "      <td>4.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247000</td>\n",
       "      <td>4.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247500</td>\n",
       "      <td>4.327600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248000</td>\n",
       "      <td>4.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248500</td>\n",
       "      <td>4.351600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249000</td>\n",
       "      <td>4.362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249500</td>\n",
       "      <td>4.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250000</td>\n",
       "      <td>4.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250500</td>\n",
       "      <td>4.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251000</td>\n",
       "      <td>4.369900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251500</td>\n",
       "      <td>4.352700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252000</td>\n",
       "      <td>4.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252500</td>\n",
       "      <td>4.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253000</td>\n",
       "      <td>4.367300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253500</td>\n",
       "      <td>4.366700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254000</td>\n",
       "      <td>4.367900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254500</td>\n",
       "      <td>4.345500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255000</td>\n",
       "      <td>4.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255500</td>\n",
       "      <td>4.373400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256000</td>\n",
       "      <td>4.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256500</td>\n",
       "      <td>4.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257000</td>\n",
       "      <td>4.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257500</td>\n",
       "      <td>4.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258000</td>\n",
       "      <td>4.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258500</td>\n",
       "      <td>4.352700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259000</td>\n",
       "      <td>4.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259500</td>\n",
       "      <td>4.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>4.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260500</td>\n",
       "      <td>4.353100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261000</td>\n",
       "      <td>4.353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261500</td>\n",
       "      <td>4.382900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262000</td>\n",
       "      <td>4.365600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262500</td>\n",
       "      <td>4.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263000</td>\n",
       "      <td>4.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263500</td>\n",
       "      <td>4.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264000</td>\n",
       "      <td>4.361100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264500</td>\n",
       "      <td>4.356300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265000</td>\n",
       "      <td>4.333900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265500</td>\n",
       "      <td>4.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266000</td>\n",
       "      <td>4.347500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266500</td>\n",
       "      <td>4.348500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267000</td>\n",
       "      <td>4.364800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267500</td>\n",
       "      <td>4.351700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268000</td>\n",
       "      <td>4.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268500</td>\n",
       "      <td>4.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269000</td>\n",
       "      <td>4.354800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269500</td>\n",
       "      <td>4.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270000</td>\n",
       "      <td>4.349600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270500</td>\n",
       "      <td>4.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271000</td>\n",
       "      <td>4.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271500</td>\n",
       "      <td>4.371400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272000</td>\n",
       "      <td>4.365600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272500</td>\n",
       "      <td>4.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273000</td>\n",
       "      <td>4.370600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273500</td>\n",
       "      <td>4.360700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274000</td>\n",
       "      <td>4.350100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274500</td>\n",
       "      <td>4.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275000</td>\n",
       "      <td>4.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275500</td>\n",
       "      <td>4.351300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276000</td>\n",
       "      <td>4.338200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276500</td>\n",
       "      <td>4.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277000</td>\n",
       "      <td>4.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277500</td>\n",
       "      <td>4.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278000</td>\n",
       "      <td>4.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278500</td>\n",
       "      <td>4.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279000</td>\n",
       "      <td>4.352800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279500</td>\n",
       "      <td>4.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>4.332100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280500</td>\n",
       "      <td>4.357800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281000</td>\n",
       "      <td>4.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281500</td>\n",
       "      <td>4.349200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282000</td>\n",
       "      <td>4.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282500</td>\n",
       "      <td>4.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283000</td>\n",
       "      <td>4.352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283500</td>\n",
       "      <td>4.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284000</td>\n",
       "      <td>4.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284500</td>\n",
       "      <td>4.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285000</td>\n",
       "      <td>4.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285500</td>\n",
       "      <td>4.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286000</td>\n",
       "      <td>4.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286500</td>\n",
       "      <td>4.346800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287000</td>\n",
       "      <td>4.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287500</td>\n",
       "      <td>4.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288000</td>\n",
       "      <td>4.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288500</td>\n",
       "      <td>4.359500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289000</td>\n",
       "      <td>4.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289500</td>\n",
       "      <td>4.338800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290000</td>\n",
       "      <td>4.329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290500</td>\n",
       "      <td>4.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291000</td>\n",
       "      <td>4.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291500</td>\n",
       "      <td>4.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292000</td>\n",
       "      <td>4.337000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292500</td>\n",
       "      <td>4.367800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293000</td>\n",
       "      <td>4.348000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293500</td>\n",
       "      <td>4.333100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294000</td>\n",
       "      <td>4.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294500</td>\n",
       "      <td>4.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295000</td>\n",
       "      <td>4.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295500</td>\n",
       "      <td>4.346500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296000</td>\n",
       "      <td>4.346400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296500</td>\n",
       "      <td>4.351300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297000</td>\n",
       "      <td>4.332100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297500</td>\n",
       "      <td>4.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298000</td>\n",
       "      <td>4.328500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298500</td>\n",
       "      <td>4.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299000</td>\n",
       "      <td>4.337400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299500</td>\n",
       "      <td>4.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>4.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300500</td>\n",
       "      <td>4.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301000</td>\n",
       "      <td>4.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301500</td>\n",
       "      <td>4.328200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302000</td>\n",
       "      <td>4.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302500</td>\n",
       "      <td>4.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303000</td>\n",
       "      <td>4.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303500</td>\n",
       "      <td>4.326200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304000</td>\n",
       "      <td>4.343100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304500</td>\n",
       "      <td>4.340900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305000</td>\n",
       "      <td>4.328200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305500</td>\n",
       "      <td>4.329700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306000</td>\n",
       "      <td>4.340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306500</td>\n",
       "      <td>4.343900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307000</td>\n",
       "      <td>4.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307500</td>\n",
       "      <td>4.329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308000</td>\n",
       "      <td>4.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308500</td>\n",
       "      <td>4.329700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309000</td>\n",
       "      <td>4.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309500</td>\n",
       "      <td>4.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310000</td>\n",
       "      <td>4.329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310500</td>\n",
       "      <td>4.326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311000</td>\n",
       "      <td>4.346800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311500</td>\n",
       "      <td>4.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312000</td>\n",
       "      <td>4.359200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312500</td>\n",
       "      <td>4.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313000</td>\n",
       "      <td>4.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313500</td>\n",
       "      <td>4.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314000</td>\n",
       "      <td>4.344100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314500</td>\n",
       "      <td>4.344800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>4.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315500</td>\n",
       "      <td>4.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316000</td>\n",
       "      <td>4.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316500</td>\n",
       "      <td>4.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317000</td>\n",
       "      <td>4.320200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317500</td>\n",
       "      <td>4.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318000</td>\n",
       "      <td>4.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318500</td>\n",
       "      <td>4.335300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319000</td>\n",
       "      <td>4.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319500</td>\n",
       "      <td>4.343800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>4.322400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320500</td>\n",
       "      <td>4.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321000</td>\n",
       "      <td>4.312900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321500</td>\n",
       "      <td>4.338600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322000</td>\n",
       "      <td>4.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322500</td>\n",
       "      <td>4.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323000</td>\n",
       "      <td>4.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323500</td>\n",
       "      <td>4.331600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324000</td>\n",
       "      <td>4.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324500</td>\n",
       "      <td>4.338900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325000</td>\n",
       "      <td>4.345400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325500</td>\n",
       "      <td>4.319200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326000</td>\n",
       "      <td>4.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326500</td>\n",
       "      <td>4.323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327000</td>\n",
       "      <td>4.334400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327500</td>\n",
       "      <td>4.346400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328000</td>\n",
       "      <td>4.332100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328500</td>\n",
       "      <td>4.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329000</td>\n",
       "      <td>4.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329500</td>\n",
       "      <td>4.334700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330000</td>\n",
       "      <td>4.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330500</td>\n",
       "      <td>4.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331000</td>\n",
       "      <td>4.352400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331500</td>\n",
       "      <td>4.338200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332000</td>\n",
       "      <td>4.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332500</td>\n",
       "      <td>4.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333000</td>\n",
       "      <td>4.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333500</td>\n",
       "      <td>4.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334000</td>\n",
       "      <td>4.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334500</td>\n",
       "      <td>4.327900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335000</td>\n",
       "      <td>4.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335500</td>\n",
       "      <td>4.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336000</td>\n",
       "      <td>4.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336500</td>\n",
       "      <td>4.325400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337000</td>\n",
       "      <td>4.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337500</td>\n",
       "      <td>4.316800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338000</td>\n",
       "      <td>4.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338500</td>\n",
       "      <td>4.314300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339000</td>\n",
       "      <td>4.329400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339500</td>\n",
       "      <td>4.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340000</td>\n",
       "      <td>4.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340500</td>\n",
       "      <td>4.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341000</td>\n",
       "      <td>4.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341500</td>\n",
       "      <td>4.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342000</td>\n",
       "      <td>4.328600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342500</td>\n",
       "      <td>4.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343000</td>\n",
       "      <td>4.333900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343500</td>\n",
       "      <td>4.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344000</td>\n",
       "      <td>4.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344500</td>\n",
       "      <td>4.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345000</td>\n",
       "      <td>4.350100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345500</td>\n",
       "      <td>4.330800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346000</td>\n",
       "      <td>4.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346500</td>\n",
       "      <td>4.341700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347000</td>\n",
       "      <td>4.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347500</td>\n",
       "      <td>4.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348000</td>\n",
       "      <td>4.310600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348500</td>\n",
       "      <td>4.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349000</td>\n",
       "      <td>4.324200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349500</td>\n",
       "      <td>4.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350000</td>\n",
       "      <td>4.314300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350500</td>\n",
       "      <td>4.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351000</td>\n",
       "      <td>4.306600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351500</td>\n",
       "      <td>4.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352000</td>\n",
       "      <td>4.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352500</td>\n",
       "      <td>4.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353000</td>\n",
       "      <td>4.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353500</td>\n",
       "      <td>4.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354000</td>\n",
       "      <td>4.316600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354500</td>\n",
       "      <td>4.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355000</td>\n",
       "      <td>4.289800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355500</td>\n",
       "      <td>4.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356000</td>\n",
       "      <td>4.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356500</td>\n",
       "      <td>4.325100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357000</td>\n",
       "      <td>4.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357500</td>\n",
       "      <td>4.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358000</td>\n",
       "      <td>4.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358500</td>\n",
       "      <td>4.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359000</td>\n",
       "      <td>4.319100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359500</td>\n",
       "      <td>4.319100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360000</td>\n",
       "      <td>4.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360500</td>\n",
       "      <td>4.320400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361000</td>\n",
       "      <td>4.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361500</td>\n",
       "      <td>4.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362000</td>\n",
       "      <td>4.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362500</td>\n",
       "      <td>4.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363000</td>\n",
       "      <td>4.299500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363500</td>\n",
       "      <td>4.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364000</td>\n",
       "      <td>4.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364500</td>\n",
       "      <td>4.304700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365000</td>\n",
       "      <td>4.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365500</td>\n",
       "      <td>4.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366000</td>\n",
       "      <td>4.303900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366500</td>\n",
       "      <td>4.318900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367000</td>\n",
       "      <td>4.330600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367500</td>\n",
       "      <td>4.326900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368000</td>\n",
       "      <td>4.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368500</td>\n",
       "      <td>4.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369000</td>\n",
       "      <td>4.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369500</td>\n",
       "      <td>4.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370000</td>\n",
       "      <td>4.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370500</td>\n",
       "      <td>4.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371000</td>\n",
       "      <td>4.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371500</td>\n",
       "      <td>4.322300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372000</td>\n",
       "      <td>4.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372500</td>\n",
       "      <td>4.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373000</td>\n",
       "      <td>4.280600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373500</td>\n",
       "      <td>4.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374000</td>\n",
       "      <td>4.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374500</td>\n",
       "      <td>4.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375000</td>\n",
       "      <td>4.309300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375500</td>\n",
       "      <td>4.314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376000</td>\n",
       "      <td>4.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376500</td>\n",
       "      <td>4.295800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377000</td>\n",
       "      <td>4.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377500</td>\n",
       "      <td>4.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378000</td>\n",
       "      <td>4.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378500</td>\n",
       "      <td>4.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379000</td>\n",
       "      <td>4.316600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379500</td>\n",
       "      <td>4.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380000</td>\n",
       "      <td>4.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380500</td>\n",
       "      <td>4.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381000</td>\n",
       "      <td>4.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381500</td>\n",
       "      <td>4.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382000</td>\n",
       "      <td>4.289300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382500</td>\n",
       "      <td>4.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383000</td>\n",
       "      <td>4.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383500</td>\n",
       "      <td>4.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384000</td>\n",
       "      <td>4.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384500</td>\n",
       "      <td>4.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385000</td>\n",
       "      <td>4.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385500</td>\n",
       "      <td>4.306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386000</td>\n",
       "      <td>4.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386500</td>\n",
       "      <td>4.271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387000</td>\n",
       "      <td>4.296600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387500</td>\n",
       "      <td>4.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388000</td>\n",
       "      <td>4.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388500</td>\n",
       "      <td>4.291200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389000</td>\n",
       "      <td>4.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389500</td>\n",
       "      <td>4.311600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390000</td>\n",
       "      <td>4.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390500</td>\n",
       "      <td>4.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391000</td>\n",
       "      <td>4.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391500</td>\n",
       "      <td>4.311200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392000</td>\n",
       "      <td>4.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392500</td>\n",
       "      <td>4.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393000</td>\n",
       "      <td>4.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393500</td>\n",
       "      <td>4.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394000</td>\n",
       "      <td>4.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394500</td>\n",
       "      <td>4.298200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395000</td>\n",
       "      <td>4.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395500</td>\n",
       "      <td>4.302100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396000</td>\n",
       "      <td>4.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396500</td>\n",
       "      <td>4.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397000</td>\n",
       "      <td>4.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397500</td>\n",
       "      <td>4.307200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398000</td>\n",
       "      <td>4.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398500</td>\n",
       "      <td>4.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399000</td>\n",
       "      <td>4.302700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399500</td>\n",
       "      <td>4.323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400000</td>\n",
       "      <td>4.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400500</td>\n",
       "      <td>4.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401000</td>\n",
       "      <td>4.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401500</td>\n",
       "      <td>4.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402000</td>\n",
       "      <td>4.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402500</td>\n",
       "      <td>4.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403000</td>\n",
       "      <td>4.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403500</td>\n",
       "      <td>4.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404000</td>\n",
       "      <td>4.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404500</td>\n",
       "      <td>4.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405000</td>\n",
       "      <td>4.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405500</td>\n",
       "      <td>4.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406000</td>\n",
       "      <td>4.284700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406500</td>\n",
       "      <td>4.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407000</td>\n",
       "      <td>4.290100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407500</td>\n",
       "      <td>4.300900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408000</td>\n",
       "      <td>4.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408500</td>\n",
       "      <td>4.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409000</td>\n",
       "      <td>4.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409500</td>\n",
       "      <td>4.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410000</td>\n",
       "      <td>4.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410500</td>\n",
       "      <td>4.292600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411000</td>\n",
       "      <td>4.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411500</td>\n",
       "      <td>4.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412000</td>\n",
       "      <td>4.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412500</td>\n",
       "      <td>4.316800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413000</td>\n",
       "      <td>4.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413500</td>\n",
       "      <td>4.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414000</td>\n",
       "      <td>4.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414500</td>\n",
       "      <td>4.290800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415000</td>\n",
       "      <td>4.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415500</td>\n",
       "      <td>4.293600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416000</td>\n",
       "      <td>4.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416500</td>\n",
       "      <td>4.275400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417000</td>\n",
       "      <td>4.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417500</td>\n",
       "      <td>4.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418000</td>\n",
       "      <td>4.303400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418500</td>\n",
       "      <td>4.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419000</td>\n",
       "      <td>4.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419500</td>\n",
       "      <td>4.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420000</td>\n",
       "      <td>4.299600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420500</td>\n",
       "      <td>4.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421000</td>\n",
       "      <td>4.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421500</td>\n",
       "      <td>4.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422000</td>\n",
       "      <td>4.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422500</td>\n",
       "      <td>4.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423000</td>\n",
       "      <td>4.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423500</td>\n",
       "      <td>4.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424000</td>\n",
       "      <td>4.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424500</td>\n",
       "      <td>4.308800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425000</td>\n",
       "      <td>4.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425500</td>\n",
       "      <td>4.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426000</td>\n",
       "      <td>4.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426500</td>\n",
       "      <td>4.271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427000</td>\n",
       "      <td>4.271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427500</td>\n",
       "      <td>4.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428000</td>\n",
       "      <td>4.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428500</td>\n",
       "      <td>4.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429000</td>\n",
       "      <td>4.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429500</td>\n",
       "      <td>4.282700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430000</td>\n",
       "      <td>4.308000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430500</td>\n",
       "      <td>4.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431000</td>\n",
       "      <td>4.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431500</td>\n",
       "      <td>4.292100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432000</td>\n",
       "      <td>4.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432500</td>\n",
       "      <td>4.271600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433000</td>\n",
       "      <td>4.291500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433500</td>\n",
       "      <td>4.287900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434000</td>\n",
       "      <td>4.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434500</td>\n",
       "      <td>4.287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435000</td>\n",
       "      <td>4.273400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435500</td>\n",
       "      <td>4.272500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436000</td>\n",
       "      <td>4.274400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436500</td>\n",
       "      <td>4.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437000</td>\n",
       "      <td>4.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437500</td>\n",
       "      <td>4.296500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438000</td>\n",
       "      <td>4.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438500</td>\n",
       "      <td>4.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439000</td>\n",
       "      <td>4.281200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439500</td>\n",
       "      <td>4.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440000</td>\n",
       "      <td>4.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440500</td>\n",
       "      <td>4.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441000</td>\n",
       "      <td>4.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441500</td>\n",
       "      <td>4.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442000</td>\n",
       "      <td>4.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442500</td>\n",
       "      <td>4.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443000</td>\n",
       "      <td>4.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443500</td>\n",
       "      <td>4.304500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444000</td>\n",
       "      <td>4.291100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444500</td>\n",
       "      <td>4.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445000</td>\n",
       "      <td>4.294200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445500</td>\n",
       "      <td>4.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446000</td>\n",
       "      <td>4.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446500</td>\n",
       "      <td>4.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447000</td>\n",
       "      <td>4.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447500</td>\n",
       "      <td>4.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448000</td>\n",
       "      <td>4.298800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448500</td>\n",
       "      <td>4.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449000</td>\n",
       "      <td>4.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449500</td>\n",
       "      <td>4.294900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450000</td>\n",
       "      <td>4.284200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450500</td>\n",
       "      <td>4.272800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451000</td>\n",
       "      <td>4.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451500</td>\n",
       "      <td>4.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452000</td>\n",
       "      <td>4.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452500</td>\n",
       "      <td>4.289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453000</td>\n",
       "      <td>4.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453500</td>\n",
       "      <td>4.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454000</td>\n",
       "      <td>4.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454500</td>\n",
       "      <td>4.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455000</td>\n",
       "      <td>4.283300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455500</td>\n",
       "      <td>4.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456000</td>\n",
       "      <td>4.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456500</td>\n",
       "      <td>4.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457000</td>\n",
       "      <td>4.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457500</td>\n",
       "      <td>4.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458000</td>\n",
       "      <td>4.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458500</td>\n",
       "      <td>4.287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459000</td>\n",
       "      <td>4.274400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459500</td>\n",
       "      <td>4.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460000</td>\n",
       "      <td>4.271600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460500</td>\n",
       "      <td>4.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461000</td>\n",
       "      <td>4.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461500</td>\n",
       "      <td>4.264800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462000</td>\n",
       "      <td>4.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462500</td>\n",
       "      <td>4.283400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463000</td>\n",
       "      <td>4.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463500</td>\n",
       "      <td>4.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464000</td>\n",
       "      <td>4.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464500</td>\n",
       "      <td>4.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465000</td>\n",
       "      <td>4.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465500</td>\n",
       "      <td>4.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466000</td>\n",
       "      <td>4.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466500</td>\n",
       "      <td>4.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467000</td>\n",
       "      <td>4.289400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467500</td>\n",
       "      <td>4.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468000</td>\n",
       "      <td>4.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468500</td>\n",
       "      <td>4.298700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469000</td>\n",
       "      <td>4.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469500</td>\n",
       "      <td>4.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470000</td>\n",
       "      <td>4.310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470500</td>\n",
       "      <td>4.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471000</td>\n",
       "      <td>4.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471500</td>\n",
       "      <td>4.298200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472000</td>\n",
       "      <td>4.289200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472500</td>\n",
       "      <td>4.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473000</td>\n",
       "      <td>4.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473500</td>\n",
       "      <td>4.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474000</td>\n",
       "      <td>4.280400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474500</td>\n",
       "      <td>4.284600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475000</td>\n",
       "      <td>4.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475500</td>\n",
       "      <td>4.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476000</td>\n",
       "      <td>4.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476500</td>\n",
       "      <td>4.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477000</td>\n",
       "      <td>4.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477500</td>\n",
       "      <td>4.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478000</td>\n",
       "      <td>4.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478500</td>\n",
       "      <td>4.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479000</td>\n",
       "      <td>4.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479500</td>\n",
       "      <td>4.279400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480000</td>\n",
       "      <td>4.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480500</td>\n",
       "      <td>4.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481000</td>\n",
       "      <td>4.270800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481500</td>\n",
       "      <td>4.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482000</td>\n",
       "      <td>4.274300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482500</td>\n",
       "      <td>4.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483000</td>\n",
       "      <td>4.286100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483500</td>\n",
       "      <td>4.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484000</td>\n",
       "      <td>4.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484500</td>\n",
       "      <td>4.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485000</td>\n",
       "      <td>4.270200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485500</td>\n",
       "      <td>4.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486000</td>\n",
       "      <td>4.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486500</td>\n",
       "      <td>4.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487000</td>\n",
       "      <td>4.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487500</td>\n",
       "      <td>4.287200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488000</td>\n",
       "      <td>4.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488500</td>\n",
       "      <td>4.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489000</td>\n",
       "      <td>4.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489500</td>\n",
       "      <td>4.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490000</td>\n",
       "      <td>4.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490500</td>\n",
       "      <td>4.267700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491000</td>\n",
       "      <td>4.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491500</td>\n",
       "      <td>4.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492000</td>\n",
       "      <td>4.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>492500</td>\n",
       "      <td>4.272800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493000</td>\n",
       "      <td>4.258400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493500</td>\n",
       "      <td>4.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494000</td>\n",
       "      <td>4.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494500</td>\n",
       "      <td>4.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495000</td>\n",
       "      <td>4.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495500</td>\n",
       "      <td>4.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496000</td>\n",
       "      <td>4.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496500</td>\n",
       "      <td>4.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497000</td>\n",
       "      <td>4.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497500</td>\n",
       "      <td>4.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498000</td>\n",
       "      <td>4.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498500</td>\n",
       "      <td>4.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499000</td>\n",
       "      <td>4.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499500</td>\n",
       "      <td>4.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>4.281800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500500</td>\n",
       "      <td>4.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501000</td>\n",
       "      <td>4.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501500</td>\n",
       "      <td>4.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502000</td>\n",
       "      <td>4.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502500</td>\n",
       "      <td>4.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503000</td>\n",
       "      <td>4.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503500</td>\n",
       "      <td>4.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504000</td>\n",
       "      <td>4.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504500</td>\n",
       "      <td>4.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505000</td>\n",
       "      <td>4.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505500</td>\n",
       "      <td>4.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506000</td>\n",
       "      <td>4.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>506500</td>\n",
       "      <td>4.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507000</td>\n",
       "      <td>4.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507500</td>\n",
       "      <td>4.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508000</td>\n",
       "      <td>4.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>508500</td>\n",
       "      <td>4.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509000</td>\n",
       "      <td>4.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509500</td>\n",
       "      <td>4.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000</td>\n",
       "      <td>4.281300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510500</td>\n",
       "      <td>4.246600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511000</td>\n",
       "      <td>4.273700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>511500</td>\n",
       "      <td>4.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512000</td>\n",
       "      <td>4.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512500</td>\n",
       "      <td>4.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513000</td>\n",
       "      <td>4.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>513500</td>\n",
       "      <td>4.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514000</td>\n",
       "      <td>4.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514500</td>\n",
       "      <td>4.257800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515000</td>\n",
       "      <td>4.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515500</td>\n",
       "      <td>4.271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516000</td>\n",
       "      <td>4.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516500</td>\n",
       "      <td>4.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517000</td>\n",
       "      <td>4.286500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517500</td>\n",
       "      <td>4.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518000</td>\n",
       "      <td>4.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518500</td>\n",
       "      <td>4.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519000</td>\n",
       "      <td>4.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519500</td>\n",
       "      <td>4.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520000</td>\n",
       "      <td>4.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520500</td>\n",
       "      <td>4.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521000</td>\n",
       "      <td>4.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521500</td>\n",
       "      <td>4.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522000</td>\n",
       "      <td>4.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522500</td>\n",
       "      <td>4.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523000</td>\n",
       "      <td>4.286700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523500</td>\n",
       "      <td>4.250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524000</td>\n",
       "      <td>4.274100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524500</td>\n",
       "      <td>4.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525000</td>\n",
       "      <td>4.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525500</td>\n",
       "      <td>4.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526000</td>\n",
       "      <td>4.229300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>526500</td>\n",
       "      <td>4.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527000</td>\n",
       "      <td>4.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527500</td>\n",
       "      <td>4.257700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528000</td>\n",
       "      <td>4.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528500</td>\n",
       "      <td>4.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>529000</td>\n",
       "      <td>4.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>529500</td>\n",
       "      <td>4.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530000</td>\n",
       "      <td>4.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530500</td>\n",
       "      <td>4.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531000</td>\n",
       "      <td>4.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531500</td>\n",
       "      <td>4.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532000</td>\n",
       "      <td>4.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532500</td>\n",
       "      <td>4.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533000</td>\n",
       "      <td>4.260300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533500</td>\n",
       "      <td>4.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534000</td>\n",
       "      <td>4.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534500</td>\n",
       "      <td>4.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535000</td>\n",
       "      <td>4.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535500</td>\n",
       "      <td>4.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536000</td>\n",
       "      <td>4.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536500</td>\n",
       "      <td>4.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537000</td>\n",
       "      <td>4.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537500</td>\n",
       "      <td>4.272200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538000</td>\n",
       "      <td>4.268600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538500</td>\n",
       "      <td>4.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539000</td>\n",
       "      <td>4.267200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539500</td>\n",
       "      <td>4.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540000</td>\n",
       "      <td>4.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540500</td>\n",
       "      <td>4.258800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541000</td>\n",
       "      <td>4.239400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541500</td>\n",
       "      <td>4.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542000</td>\n",
       "      <td>4.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>542500</td>\n",
       "      <td>4.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543000</td>\n",
       "      <td>4.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543500</td>\n",
       "      <td>4.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544000</td>\n",
       "      <td>4.257700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544500</td>\n",
       "      <td>4.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>4.263700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545500</td>\n",
       "      <td>4.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546000</td>\n",
       "      <td>4.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546500</td>\n",
       "      <td>4.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547000</td>\n",
       "      <td>4.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547500</td>\n",
       "      <td>4.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548000</td>\n",
       "      <td>4.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548500</td>\n",
       "      <td>4.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549000</td>\n",
       "      <td>4.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549500</td>\n",
       "      <td>4.248800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>4.271600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550500</td>\n",
       "      <td>4.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551000</td>\n",
       "      <td>4.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551500</td>\n",
       "      <td>4.255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552000</td>\n",
       "      <td>4.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552500</td>\n",
       "      <td>4.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553000</td>\n",
       "      <td>4.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553500</td>\n",
       "      <td>4.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554000</td>\n",
       "      <td>4.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>554500</td>\n",
       "      <td>4.250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>4.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555500</td>\n",
       "      <td>4.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556000</td>\n",
       "      <td>4.237800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>556500</td>\n",
       "      <td>4.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557000</td>\n",
       "      <td>4.261200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557500</td>\n",
       "      <td>4.265200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558000</td>\n",
       "      <td>4.263700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>558500</td>\n",
       "      <td>4.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559000</td>\n",
       "      <td>4.257800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559500</td>\n",
       "      <td>4.250200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>4.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560500</td>\n",
       "      <td>4.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>561000</td>\n",
       "      <td>4.244300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>561500</td>\n",
       "      <td>4.264600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562000</td>\n",
       "      <td>4.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562500</td>\n",
       "      <td>4.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563000</td>\n",
       "      <td>4.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>563500</td>\n",
       "      <td>4.252800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564000</td>\n",
       "      <td>4.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564500</td>\n",
       "      <td>4.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>4.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565500</td>\n",
       "      <td>4.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566000</td>\n",
       "      <td>4.259800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566500</td>\n",
       "      <td>4.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567000</td>\n",
       "      <td>4.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567500</td>\n",
       "      <td>4.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568000</td>\n",
       "      <td>4.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568500</td>\n",
       "      <td>4.226200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>569000</td>\n",
       "      <td>4.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>569500</td>\n",
       "      <td>4.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>4.253600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570500</td>\n",
       "      <td>4.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571000</td>\n",
       "      <td>4.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571500</td>\n",
       "      <td>4.231700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572000</td>\n",
       "      <td>4.253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572500</td>\n",
       "      <td>4.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573000</td>\n",
       "      <td>4.258200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573500</td>\n",
       "      <td>4.237300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574000</td>\n",
       "      <td>4.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>574500</td>\n",
       "      <td>4.239800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>4.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575500</td>\n",
       "      <td>4.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576000</td>\n",
       "      <td>4.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576500</td>\n",
       "      <td>4.236200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577000</td>\n",
       "      <td>4.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577500</td>\n",
       "      <td>4.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578000</td>\n",
       "      <td>4.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>578500</td>\n",
       "      <td>4.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579000</td>\n",
       "      <td>4.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>579500</td>\n",
       "      <td>4.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>4.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580500</td>\n",
       "      <td>4.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581000</td>\n",
       "      <td>4.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>581500</td>\n",
       "      <td>4.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582000</td>\n",
       "      <td>4.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>582500</td>\n",
       "      <td>4.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583000</td>\n",
       "      <td>4.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>583500</td>\n",
       "      <td>4.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584000</td>\n",
       "      <td>4.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584500</td>\n",
       "      <td>4.226800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>4.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585500</td>\n",
       "      <td>4.229400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586000</td>\n",
       "      <td>4.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586500</td>\n",
       "      <td>4.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587000</td>\n",
       "      <td>4.229400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587500</td>\n",
       "      <td>4.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588000</td>\n",
       "      <td>4.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588500</td>\n",
       "      <td>4.226400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589000</td>\n",
       "      <td>4.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589500</td>\n",
       "      <td>4.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>4.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590500</td>\n",
       "      <td>4.242300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>591000</td>\n",
       "      <td>4.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>591500</td>\n",
       "      <td>4.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592000</td>\n",
       "      <td>4.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>592500</td>\n",
       "      <td>4.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593000</td>\n",
       "      <td>4.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>593500</td>\n",
       "      <td>4.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594000</td>\n",
       "      <td>4.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>594500</td>\n",
       "      <td>4.241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>4.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595500</td>\n",
       "      <td>4.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596000</td>\n",
       "      <td>4.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>596500</td>\n",
       "      <td>4.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597000</td>\n",
       "      <td>4.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597500</td>\n",
       "      <td>4.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598000</td>\n",
       "      <td>4.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598500</td>\n",
       "      <td>4.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599000</td>\n",
       "      <td>4.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>599500</td>\n",
       "      <td>4.251200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>4.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600500</td>\n",
       "      <td>4.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>601000</td>\n",
       "      <td>4.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>601500</td>\n",
       "      <td>4.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602000</td>\n",
       "      <td>4.248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602500</td>\n",
       "      <td>4.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>603000</td>\n",
       "      <td>4.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>603500</td>\n",
       "      <td>4.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604000</td>\n",
       "      <td>4.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604500</td>\n",
       "      <td>4.227800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>4.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605500</td>\n",
       "      <td>4.243300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606000</td>\n",
       "      <td>4.227000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606500</td>\n",
       "      <td>4.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607000</td>\n",
       "      <td>4.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>607500</td>\n",
       "      <td>4.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608000</td>\n",
       "      <td>4.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>608500</td>\n",
       "      <td>4.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609000</td>\n",
       "      <td>4.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609500</td>\n",
       "      <td>4.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>4.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610500</td>\n",
       "      <td>4.237300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611000</td>\n",
       "      <td>4.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>611500</td>\n",
       "      <td>4.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612000</td>\n",
       "      <td>4.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612500</td>\n",
       "      <td>4.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613000</td>\n",
       "      <td>4.243600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613500</td>\n",
       "      <td>4.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>614000</td>\n",
       "      <td>4.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>614500</td>\n",
       "      <td>4.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>4.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615500</td>\n",
       "      <td>4.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616000</td>\n",
       "      <td>4.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>616500</td>\n",
       "      <td>4.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>617000</td>\n",
       "      <td>4.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>617500</td>\n",
       "      <td>4.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618000</td>\n",
       "      <td>4.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618500</td>\n",
       "      <td>4.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619000</td>\n",
       "      <td>4.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619500</td>\n",
       "      <td>4.242100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>4.253800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620500</td>\n",
       "      <td>4.233100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621000</td>\n",
       "      <td>4.240800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621500</td>\n",
       "      <td>4.241200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622000</td>\n",
       "      <td>4.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622500</td>\n",
       "      <td>4.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623000</td>\n",
       "      <td>4.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623500</td>\n",
       "      <td>4.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624000</td>\n",
       "      <td>4.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624500</td>\n",
       "      <td>4.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>4.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625500</td>\n",
       "      <td>4.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626000</td>\n",
       "      <td>4.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626500</td>\n",
       "      <td>4.248800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-17500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-23500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-36500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-48500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-50500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-52500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-53500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-55500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-56500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-57500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-58500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-59500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-60500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-61500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-62500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-63500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-64500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-65500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-66500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-67500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-68500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-69500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-70500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76500/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-71500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-72500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-73500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-74500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-75500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-76500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-77500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-78500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-79500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-80500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-81500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-82500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-83500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-84500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-85500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-86500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-87500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-88500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-89500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-90500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-91500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-92500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-93500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-94500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-95500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-96500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-97500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-98500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-99500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-100500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-101500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-102500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-103500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-104500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-105500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-106500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-107500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-108500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-109500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-110500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-111500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-112500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-113500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-114500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-115500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-116500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-117500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-118500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-119500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-120500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-121500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-122500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-123500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-124500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-125500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-126500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-127500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-128500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-129500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-130500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-131500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-132500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-133500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-134500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-135500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-136500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-137500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-138500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-139500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-140500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-141500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-142500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-143500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-144500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-145500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-146500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-147500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-148500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-149500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-150500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-151500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-152500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-153500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-154500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-155500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-156500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-157500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-158500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-159500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-160500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-161500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-162500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-163500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-164500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-165500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-166500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-167500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-168500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-169500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-170500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-171500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-172500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-173500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-174500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-175500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-176500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-177500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-178500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-179500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-180500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-181500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-182500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-183500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-184500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-185500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-186500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-187500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-188500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-189500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-190500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-191500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-192500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-193500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-194500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-195500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-196500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-197500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-198500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-199500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-200500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-201500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-202500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-203500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-204500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-205500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-206500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-207500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-208500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-209500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-210500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-211500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-212500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-213500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-214500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-215500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-216500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-217500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-218500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-219500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-220500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-221500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-222500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-223500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-224500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-225500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-226500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-227500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-228500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-229500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-230500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-231500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-232500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-233500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-234500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-235500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-236500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-237500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-238500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-239500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-240500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-241500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-242500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-243500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-244500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-245500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-246500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-247500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-248500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-249500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-250500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-251500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-252500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-253500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-254500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-255500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-256500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-257500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-258500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-259500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-260500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-261500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-262500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-263500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-264500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-265500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-266500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-267500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-268500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-269500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-270500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-271500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-272500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-273500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-274500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-275500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-276500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-277500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-278500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-279500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-280500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-281500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-282500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-283500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-284500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-285500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-286500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-287500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-288500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-289500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-290500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-291500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-292500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-293500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-294500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-295500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-296500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-297500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-298500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-299500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-300500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-301500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-302500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-303500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-304500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-305500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-306500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-307500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-308500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-309500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-310500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-311500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-312500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-313500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-314500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-315500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-316500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-317500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-318500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-319500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-320500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-321500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-322500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-323500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-324500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-325500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-326500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-327500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-328500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-329500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-330500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-331500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-332500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-333500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-334500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-335500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-336500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-337500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-338500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-339500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-340500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-341500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-342500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-343500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-344500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-345500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-346500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-347500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-348500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-349500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-350500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-351500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-352500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-353500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-354500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-355500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-356500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-357500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-358500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-359500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-360500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-361500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-362500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-363500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-364500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-365500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-366500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-367500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-368500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-369500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-370500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-371500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-372500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-373500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-374500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-375500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-376500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-377500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-378500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-379500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-380500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-381500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-382500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-383500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-384500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-385500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-386500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-387500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-388500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-389500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-390500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-391500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-392500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-393500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-394500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-395500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-396500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-397500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-398500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-399500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-400500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-401500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-402500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-403500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-404500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-405500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-406500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-407500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-408500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-409500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-410500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-411500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-412500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-413500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-414500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-415500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-416500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-417500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-418500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-419500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-420500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-421500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-422500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-423500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-424500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-425500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-426500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-427500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-428500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-429500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-430500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-431500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-432500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-433500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-434500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-435500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-436500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-437500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-438500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-439500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-440500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-441500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-442500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-443500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-444500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-445500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-446500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-447500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-448500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-449500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-450500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-451500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-452500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-453500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-454500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-455500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-456500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-457500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-458500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-459500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-460500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-461500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-462500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-463500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-464500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-465500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-466500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-467500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-468500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-469500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-470500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-471500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-472500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-473500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-474500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-475500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-476500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-477500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-478500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-479500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-480500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-481500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-482500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-483500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-484500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-485500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-486500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-487500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-488500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-489500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-490500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-491500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-492500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-493500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-494500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-495500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-496500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-497500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-498500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-499500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-500500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-501500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-502500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-503500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-504500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-505500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-506500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-507500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-508500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-509500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-510500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-511500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-512500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-513500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-514500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-515500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-516500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-517500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-518500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-519500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-520500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-521500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-522500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-523500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-524500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-525500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-526500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-527500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-528500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-529500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-530500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-531500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-532500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-533500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-534500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-535500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-536500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-537500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-538500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-539500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-540500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-541500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-542500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-543500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-544500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-545500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-546500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-547500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-548500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-549500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-550500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-551500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-552500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-553500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-554500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-555500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-556500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-557500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-558500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-559500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-560500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-561500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-562500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-563500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-564500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-565500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-566500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-567500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-568500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-569500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-570500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-571500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-572500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-573500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-574500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-575500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-576500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-577500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-578500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-579500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-580500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-581500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-582500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-583500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-584500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-585500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-586500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-587500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-588500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-589500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-590500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-591500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-592500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-593500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-594500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-595500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-596500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-597500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603500/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-598500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-599500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-600500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-601500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-602500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-603500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-604500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-605500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-606500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-607500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-608500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-609500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-610500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-611500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-612500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-613500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-614500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-615500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-616500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-622500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-617500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-623500/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-618500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-624500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-619500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-625500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-620500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626000/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626000/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626000/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626000/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621000] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626500\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626500/config.json\n",
      "Model weights saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626500/pytorch_model.bin\n",
      "tokenizer config file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626500/tokenizer_config.json\n",
      "Special tokens file saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-626500/special_tokens_map.json\n",
      "Deleting older checkpoint [chckpoint/MLM_pretrain_basev2_freezing/checkpoint-621500] due to args.save_total_limit\n",
      "Saving model checkpoint to chckpoint/MLM_pretrain_basev2_freezing/checkpoint-627000\n",
      "Configuration saved in chckpoint/MLM_pretrain_basev2_freezing/checkpoint-627000/config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a388d2a",
   "metadata": {},
   "source": [
    "## 5. 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_textfile_path, encoding=\"utf-8\") as f:\n",
    "            val_textlines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "        \n",
    "val_df = pd.DataFrame(zip(val_textlines), columns=['Text'])\n",
    "val_df.reset_index(inplace=True, drop=True)\n",
    "val_data = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd38b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"Text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = inputs.input_ids.to(model.device)\n",
    "    \n",
    "    attention_mask = inputs.attention_mask.to(model.device)\n",
    "    outputs = model.generate(input_ids, num_beams=5,no_repeat_ngram_size=5, max_length=128,\n",
    "                            suppress_tokens= [234,23782,14338,240,199,198,161,116, 14338, 239], \n",
    "                             attention_mask=attention_mask, top_p=0.92)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)# 여기에 기본 kobart가져오기?\n",
    "import random\n",
    "from random import randrange\n",
    "ck_num = len(val_data)\n",
    "test_samples = val_data.select(range(0, ck_num, 1000))# 0, len(test_data), 200\n",
    "\n",
    "summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1] # 여기에 체크포인트 가져오기 \n",
    "# 연구해봐야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(summaries_after_tuning)):\n",
    "    print('idx_{} '.format(i))\n",
    "    print(\"Summary before \\n\", summaries_before_tuning[i])\n",
    "    print()\n",
    "    print(\"Summary after \\n\", summaries_after_tuning[i])\n",
    "    print()\n",
    "    print(\"Target summary \\n\", test_samples[\"Summary\"][i])\n",
    "    print()\n",
    "    print('Text', test_samples[\"Text\"][i])\n",
    "    print('-'*100)\n",
    "    print()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
