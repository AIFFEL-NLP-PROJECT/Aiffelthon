{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8124bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f427fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('~/aiffel/aiffelthon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5fed3f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-16\t\tmodeling_encoder_decoder.py   roberta-ko-small.ipynb\r\n",
      "configuration_utils.py\t__pycache__\t\t      runs\r\n",
      "csv\t\t\troberta-ko-small-Copy1.ipynb  seq2seq_training_args.py\r\n",
      "csv.zip\t\t\troberta-ko-small-Copy2.ipynb  src\r\n",
      "import_utils.py\t\troberta-ko-small-Copy3.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2078d8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.21.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=c21dae2ef3ee96a3cc2bb4a2b43f02d05f2f2a081f0457a44d839d44cf334f71\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting datasets==1.0.2\n",
      "  Downloading datasets-1.0.2-py3-none-any.whl (1.8 MB)\n",
      "     |████████████████████████████████| 1.8 MB 5.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (0.3.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (3.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.9/site-packages (from datasets==1.0.2) (6.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets==1.0.2) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.16.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.14.0\n",
      "    Uninstalling datasets-1.14.0:\n",
      "      Successfully uninstalled datasets-1.14.0\n",
      "Successfully installed datasets-1.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "!pip install datasets==1.0.2\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecf179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.24.0\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "     |████████████████████████████████| 5.5 MB 6.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "     |████████████████████████████████| 163 kB 84.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2021.11.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (2.26.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "     |████████████████████████████████| 7.6 MB 69.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.24.0) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.24.0) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.24.0) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.24.0) (2021.10.8)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.19\n",
      "    Uninstalling huggingface-hub-0.0.19:\n",
      "      Successfully uninstalled huggingface-hub-0.0.19\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.11.3\n",
      "    Uninstalling transformers-4.11.3:\n",
      "      Successfully uninstalled transformers-4.11.3\n",
      "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecbd4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformer-utils\n",
      "  Downloading transformer_utils-0.1.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.62.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (1.9.1+cu111)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (0.11.2)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (from transformer-utils) (4.24.0)\n",
      "Collecting colorcet\n",
      "  Downloading colorcet-3.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 6.0 MB/s            \n",
      "\u001b[?25hCollecting pyct>=0.4.4\n",
      "  Downloading pyct-0.4.8-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.3.3)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.9/site-packages (from seaborn->transformer-utils) (1.21.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch->transformer-utils) (4.0.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers->transformer-utils) (3.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn->transformer-utils) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23->seaborn->transformer-utils) (2021.3)\n",
      "Collecting param>=1.7.0\n",
      "  Downloading param-1.12.2-py2.py3-none-any.whl (86 kB)\n",
      "     |████████████████████████████████| 86 kB 11.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers->transformer-utils) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn->transformer-utils) (1.16.0)\n",
      "Installing collected packages: param, pyct, colorcet, transformer-utils\n",
      "Successfully installed colorcet-3.0.1 param-1.12.2 pyct-0.4.8 transformer-utils-0.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformer-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "384763f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a67432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import datasets\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "#Tokenizer\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "#Encoder-Decoder Model\n",
    "from transformers import EncoderDecoderModel\n",
    "\n",
    "#Training\n",
    "from seq2seq_trainer import Seq2SeqTrainer\n",
    "from transformers import TrainingArguments\n",
    "from seq2seq_training_args import Seq2SeqTrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "#%cd ~/aiffel/aiffelthon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb440973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ~/aiffel/aiffelthon/csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501f9a1a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-07 08:23:51--  https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11214 (11K) [text/plain]\n",
      "Saving to: ‘seq2seq_trainer.py’\n",
      "\n",
      "seq2seq_trainer.py  100%[===================>]  10.95K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-11-07 08:23:52 (60.1 MB/s) - ‘seq2seq_trainer.py’ saved [11214/11214]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae56df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/huggingface/transformers/blob/main/src/transformers/utils/import_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb397b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/configuration_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fcaaff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61290 9150\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "train_df = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/train_2-3sent_Sum2.csv')\n",
    "#train_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "train_df.rename(columns = {\"input\": \"Text\"}, inplace = True)\n",
    "#train_df.rename(columns = {\"sentence_onesent\": \"Summary\"}, inplace = True)\n",
    "#train_df.rename(columns = {\"sentence_per_20\": \"Summary\"}, inplace = True)\n",
    "train_df.rename(columns = {\"sentence_sent_2~3\": \"Summary\"}, inplace = True)\n",
    "\n",
    "val_df = pd.read_csv('/aiffel/aiffel/aiffelthon/csv/val_2-3sent_Sum2.csv')\n",
    "#val_df.drop(labels = 'Unnamed: 0', axis = 1, inplace = True)\n",
    "val_df.rename(columns = {\"input\": \"Text\"}, inplace = True)\n",
    "#val_df.rename(columns = {\"summary_onesent\": \"Summary\"}, inplace = True)\n",
    "#val_df.rename(columns = {\"summary_per_20\": \"Summary\"}, inplace = True)\n",
    "val_df.rename(columns = {\"summary_sent_2~3\": \"Summary\"}, inplace = True)\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a1e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10번째 row만 추출\n",
    "train_df = train_df.iloc[range(0, len(train_df), 20)]\n",
    "val_df = val_df.iloc[range(0, len(val_df), 10)]\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e981f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede94f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 제거\n",
    "    sentence = re.sub(\"'\",'', sentence) # 따옴표 제거\n",
    "    sentence = re.sub('\\n','', sentence) # \\n \" 제거\n",
    "    sentence = re.sub('.{2,3}\\W{0,1}기자','', sentence) # 기자 이름 제거\n",
    "    sentence = re.sub(r'[?.!,][/?.!,]', '', sentence) # 여러개 문장 부호를 하나의 문장부호로 바꿉니다\n",
    "    sentence = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-z0-9]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 여러개 공백을 하나의 공백으로 바꿉니다.\n",
    "    sentence = sentence.strip() # 문장 양쪽 공백 제거\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0283778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61290/61290 [00:12<00:00, 5106.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 (1)\n",
    "from tqdm import tqdm\n",
    "clean_text = []\n",
    "\n",
    "for s in tqdm(train_df['Text']):\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "train_df['Text'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1f1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61290/61290 [00:03<00:00, 20233.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 headlines 데이터에 대한 전처리 \n",
    "clean_headlines = []\n",
    "\n",
    "for s in tqdm(train_df['Summary']):\n",
    "      clean_headlines.append(preprocess_sentence(s))\n",
    "        \n",
    "train_df['Summary'] = clean_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "810d4bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9150/9150 [00:01<00:00, 5234.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 (1)\n",
    "from tqdm import tqdm\n",
    "clean_text_val = []\n",
    "\n",
    "for s in tqdm(val_df['Text']):\n",
    "    clean_text_val.append(preprocess_sentence(s))\n",
    "    \n",
    "val_df['Text'] = clean_text_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d05f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9150/9150 [00:00<00:00, 20548.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 headlines 데이터에 대한 전처리 \n",
    "clean_headlines_val = []\n",
    "\n",
    "for s in tqdm(val_df['Summary']):\n",
    "      clean_headlines_val.append(preprocess_sentence(s))\n",
    "        \n",
    "val_df['Summary'] = clean_headlines_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5659dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>내일 주말을 앞두고 있습니다 코로나19에 대한 경각심을 유지하고 생활 속 거리두기를...</td>\n",
       "      <td>코로나19에 대한 경각심을 유지하고 생활 속 거리두기를 잘 실천해 주실 것을 당부드...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>에어컨 지침에 대해서는 저희가 관계부처하고 또 전문가들의 회의를 했는데 아직까지는 ...</td>\n",
       "      <td>구로 콜센터의 경우에는 저희가 공조시스템을 그때 의심을 했던 거는 여러 층에 걸쳐서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아울러 생활방역 시행일로부터 코로나19 감염위기 상황 종료 시까지 생활방역대책본부를...</td>\n",
       "      <td>아울러 생활방역 시행일로부터 코로나19 감염위기 상황 종료 시까지 생활방역대책본부를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고위험 시설에 대해서도 시설유형별로 핵심 수칙을 각각 마련하고 그 핵심 지침이 잘 ...</td>\n",
       "      <td>다음으로 5월 18일에서 19일 이틀 동안 화상으로 개최 중인 제73차 세계보건기구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>특별히 교육시설 종교시설 실내 체육시설 그리고 의료기관과 같이 많은 사람들이 이용하...</td>\n",
       "      <td>특별히 교육시설 종교시설 실내 체육시설 그리고 의료기관과 같이 많은 사람들이 이용하...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  내일 주말을 앞두고 있습니다 코로나19에 대한 경각심을 유지하고 생활 속 거리두기를...   \n",
       "1  에어컨 지침에 대해서는 저희가 관계부처하고 또 전문가들의 회의를 했는데 아직까지는 ...   \n",
       "2  아울러 생활방역 시행일로부터 코로나19 감염위기 상황 종료 시까지 생활방역대책본부를...   \n",
       "3  고위험 시설에 대해서도 시설유형별로 핵심 수칙을 각각 마련하고 그 핵심 지침이 잘 ...   \n",
       "4  특별히 교육시설 종교시설 실내 체육시설 그리고 의료기관과 같이 많은 사람들이 이용하...   \n",
       "\n",
       "                                             Summary  \n",
       "0  코로나19에 대한 경각심을 유지하고 생활 속 거리두기를 잘 실천해 주실 것을 당부드...  \n",
       "1  구로 콜센터의 경우에는 저희가 공조시스템을 그때 의심을 했던 거는 여러 층에 걸쳐서...  \n",
       "2  아울러 생활방역 시행일로부터 코로나19 감염위기 상황 종료 시까지 생활방역대책본부를...  \n",
       "3  다음으로 5월 18일에서 19일 이틀 동안 화상으로 개최 중인 제73차 세계보건기구...  \n",
       "4  특별히 교육시설 종교시설 실내 체육시설 그리고 의료기관과 같이 많은 사람들이 이용하...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad12ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>새해가 밝았다 또 다른 한 해가 시작되었다 눈이 내린 하얀 설원이 앞에 펼쳐져 있는...</td>\n",
       "      <td>새해가 밝았다 시간이라는 미지의 설원을 걸어가면 발자국이 남을 것이다 그 발자국은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기다리던 새해가 밝았네요 올해 제가 드디어 아빠가 됩니다 국내에서 처음으로 남의 팔...</td>\n",
       "      <td>그는 지난 2015년 공장에서 일하다 사고로 왼쪽 팔을 잃었다 그는 장애가 있던 시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김정은 국무위원장이 지난달 28일부터 31일까지 열린 노동당 중앙위원회 전원회의 보...</td>\n",
       "      <td>김정은 국무위원장이 지난달 28일부터 31일까지 열린 노동당 중앙위원회 전원회의 보...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>신 의원은 총선에 제가 다시 도전한다는 의사표시로 예비후보를 등록했다고 말했다 다른...</td>\n",
       "      <td>신 의원은 총선에 제가 다시 도전한다는 의사표시로 예비후보를 등록했다고 말했다 다른...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스웨덴에서는 지갑을 몸에 지니지 않아도 일상생활에 불편을 겪지 않는 이들이 있다 엄...</td>\n",
       "      <td>스웨덴에서는 지갑을 몸에 지니지 않아도 일상생활에 불편을 겪지 않는 이들이 있다 엄...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  새해가 밝았다 또 다른 한 해가 시작되었다 눈이 내린 하얀 설원이 앞에 펼쳐져 있는...   \n",
       "1  기다리던 새해가 밝았네요 올해 제가 드디어 아빠가 됩니다 국내에서 처음으로 남의 팔...   \n",
       "2  김정은 국무위원장이 지난달 28일부터 31일까지 열린 노동당 중앙위원회 전원회의 보...   \n",
       "3  신 의원은 총선에 제가 다시 도전한다는 의사표시로 예비후보를 등록했다고 말했다 다른...   \n",
       "4  스웨덴에서는 지갑을 몸에 지니지 않아도 일상생활에 불편을 겪지 않는 이들이 있다 엄...   \n",
       "\n",
       "                                             Summary  \n",
       "0  새해가 밝았다 시간이라는 미지의 설원을 걸어가면 발자국이 남을 것이다 그 발자국은 ...  \n",
       "1  그는 지난 2015년 공장에서 일하다 사고로 왼쪽 팔을 잃었다 그는 장애가 있던 시...  \n",
       "2  김정은 국무위원장이 지난달 28일부터 31일까지 열린 노동당 중앙위원회 전원회의 보...  \n",
       "3  신 의원은 총선에 제가 다시 도전한다는 의사표시로 예비후보를 등록했다고 말했다 다른...  \n",
       "4  스웨덴에서는 지갑을 몸에 지니지 않아도 일상생활에 불편을 겪지 않는 이들이 있다 엄...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_index 사용\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "val_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf87f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF > data Set으로 전환\n",
    "train_data = Dataset.from_pandas(train_df) \n",
    "val_len = len(val_df) // 2\n",
    "val_data = Dataset.from_pandas(val_df[:val_len])\n",
    "test_data=Dataset.from_pandas(val_df[val_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b66bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 61290)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 4575)\n",
      "Dataset(features: {'Text': Value(dtype='string', id=None), 'Summary': Value(dtype='string', id=None)}, num_rows: 4575)\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53f314a2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤 전 르노닛산 회장이 레바논으로 비밀리에 도주했다 30일 미 일간 월스트리트저널은 소식통을 인용해 곤 전 회장이 이날 레바논 수도 베이루트 공항에 도착했다고 전했다 곤 전 회장은 보도 이후 미국의 대변인을 통해 자신이 레바논에 머물고 있다는 내용의 성명을 발표했다 이 때문에 곤 전 회장의 변호인은 물론 수사 출입국 당국까지 당혹스럽다는 반응을 보이는 상황이다 곤 전 회장은 일본의 정치적 박해 로부터 빠져나왔다고 주장하고 있다 그는 성명을 통해 유죄가 전제되고 차별이 만연하고 기본적 인권이 무시되는 잘못된 일본 사법제도의 인질 이 되지 않겠다 고 밝혔다 곤 전 회장은 르노닛산 회장 시절 회사 공금을 유용했다는 혐의 등으로 일본에서 재판을 받고 있다 지난해 4월 두 번째 보석 당시 법원에서는 거주제한 출국금지 조치를 포함한 엄격한 감시 명령을 내렸다 도쿄지방재판소는 도쿄도 미나토구 소재 단독 주택으로 곤의 주거지를 제한하고 일본에서 출국하는 것을 금지하는 등의 조건으로 보석을 인정했다 곤 전 회장의 주거지 현관에 감시 카메라를 설치해 녹화된 내용을 정기적으로 법원에 제출하며 휴대전화의 경우 인터넷 접속을 할 수 없는 1대만 변호인에게서 받아 사용하고 그 통화 이력도 법원에 제출하도록 하는 조건도 걸려 있었다 곤 전 회장의 변호인 히로나카 준이치로 변호사는 보도된 내용 이상의 것을 알지 못하며 현재 상황에 매우 놀랐다 앞으로 정보가 들어오면 법원에 제공하겠다 고 반응했다 그는 곤 전 회장의 여권은 변호사가 보관하고 있으며 변호인단이 여권을 주는 일은 있을 수 없다 고 설명했다 교도통신은 일본 출입국재류관리청의 데이터베이스에 곤 전 회장이 출국한 기록이 없는 것으로 확인됐다고 관계자의 설명을 토대로 전했다 이와 관련해 레바논 치안 당국자는 곤 전 회장으로 보이는 인물이 개인용 제트기를 이용해 베이루트에 도착했다고 nhk에 설명했다 이 인물의 입국 절차에 관해선 다른 이름으로 입국했다 카를로스 곤이라는 이름은 아니었다 고 말했다 교도통신은 곤 전 회장이 터키에서부터 개인용 제트기를 이용한 것으로 보인다고 프랑스 일간지 레제코를 인용해 전했다 교도통신에 따르면 레바논 유력 방송사인 mtv가 곤 전 회장이 악기 상자에 숨어 일본 지방공항을 통해 출국했다고 보도하는 등 의외의 경로가 이용됐을 가능성도 제기된다',\n",
       " 'Summary': '일본 사법당국의 출국금지 명령이 내려져 있던 카를로스 곤 전 르노닛산 회장이 레바논으로 비밀리에 도주했다 이 때문에 곤 전 회장의 변호인은 물론 수사 출입국 당국까지 당혹스럽다는 반응을 보이는 상황이다 곤 전 회장은 일본의 정치적 박해 로부터 빠져나왔다고 주장하고 있다'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444251c6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': '국토교통부장관 서승환 100 150 뭐 그쯤 이이재 위원 적어도 이게 평균시속 150 이상은 돼야 경쟁력이 있을 거라는 것을 지적하고 싶고요 그다음에 삼척 제진 간 이것도 역시 마찬가지로 평균시속 150 이상으로 돼야 될 것이라는 거고 이번에 수립하는 3차 국가철도망 구축계획에 바로 이런 부분들이 제대로 반영이 되어야 될 거다 하는 것을 말씀을 드립니다 꼭 좀 그렇게 해 주시기 바랍니다 국토교통부장관 서승환 예 공감하고 있습니다 이이재 위원 그리고 양양국제공항 문제입니다 우리 대한민국에 국제공항이 총 몇 개지요 인천 포함해서 한국공항공사 7개 총 8개입니다 그런데 양양국제공항만 현재 개항공항으로 지정되지 못하고 있습니다 그런데 양양국제공항이 금년도에 2009년 3000명에서 작년에 5만 명을 넘어섰고 올해 30만 명을 넘어설 것으로 계획되고 있습니다 여기에 개항공항이 안 됨으로 인해서 ciq 문제가 대단히 여객 불편을 초래하기 때문에 이 부분을 해결해 달라고 수차례 건의를 드렸음에도 불구하고 아직 해결되고 있지 않은 데 대해서 물론 관세청 고시와 관세법 시행령에 일치하지 않는 부분이 있기는 합니다마는 우선 당장에 이것은 4월부터 문제에 부딪히기 때문에 해결을 하실 수 있도록 장관님께서 관심을 가지시고 바로 좀 챙겨 주시기를 부탁드립니다 국토교통부장관 서승환 예 관계 부처하고 긴밀하게 협의하겠습니다',\n",
       " 'Summary': '국토교통부장관 서승환 예 관계 부처하고 긴밀하게 협의하겠습니다 이이재 위원 그리고 양양국제공항 문제입니다 그런데 양양국제공항만 현재 개항공항으로 지정되지 못하고 있습니다'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66f1d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92696975d91d481db2c966eb90d21275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefaef77cf8c44fa8cac440d1ee14fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/344k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8cf6bb60b94ec99efe0303fc7176f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8c976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.bos_token = tokenizer.cls_token\n",
    "#tokenizer.eos_token = tokenizer.sep_token\n",
    "#parameter setting\n",
    "batch_size=16  \n",
    "encoder_max_length=256\n",
    "decoder_max_length=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef057e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):                                                               \n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]                                               \n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
    "    outputs = tokenizer(batch[\"Summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
    "                                                                                                        \n",
    "    batch[\"input_ids\"] = inputs.input_ids                                                               \n",
    "    batch[\"attention_mask\"] = inputs.attention_mask                                                     \n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids                                                      \n",
    "    batch[\"labels\"] = outputs.input_ids.copy()                                                          \n",
    "    # mask loss for padding                                                                             \n",
    "    batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]                     \n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask                                                                              \n",
    "                                                                                                         \n",
    "    return batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "311d0750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69832f5fa68e40f09c2f0ae04e792019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3831 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5d48cc2b5e45f5bb05872728f02abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/286 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#processing training data\n",
    "train_data = train_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"Text\", \"Summary\"])\n",
    "train_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],)\n",
    "\n",
    "#processing validation data\n",
    "val_data = val_data.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"Text\", \"Summary\"])\n",
    "val_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565a08cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5619709b56e24b48900d83f91f49c82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/589M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    }
   ],
   "source": [
    "# 인코더 모델 불러오기\n",
    "\n",
    "bertshared =EncoderDecoderModel.from_pretrained(\"kykim/bertshared-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f29c8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "#from transformers import EncoderDecoderConfig\n",
    "bertshared.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
    "bertshared.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "# set decoding params                               \n",
    "bertshared.config.max_length = 32\n",
    "bertshared.config.early_stopping = True\n",
    "bertshared.config.no_repeat_ngram_size = 2\n",
    "bertshared.config.length_penalty = 2.0\n",
    "bertshared.config.num_beams = 5\n",
    "bertshared.config.vocab_size = bertshared.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed5e412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282b05992ed6498081b49bb2b2b74587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load rouge for validation\n",
    "rouge = datasets.load_metric(\"rouge\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd410183",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Seq2SeqTrainingArguments(TrainingArguments):\n",
    "    label_smoothing: Optional[float] = field(\n",
    "        default=0.0, metadata={\"help\": \"The label smoothing epsilon to apply (if not zero).\"}\n",
    "    )\n",
    "    sortish_sampler: bool = field(default=False, metadata={\"help\": \"Whether to SortishSamler or not.\"})\n",
    "    predict_with_generate: bool = field(\n",
    "        default=False, metadata={\"help\": \"Whether to use generate to calculate generative metrics (ROUGE, BLEU).\"}\n",
    "    )\n",
    "    adafactor: bool = field(default=False, metadata={\"help\": \"whether to use adafactor\"})\n",
    "    encoder_layerdrop: Optional[float] = field(\n",
    "        default=None, metadata={\"help\": \"Encoder layer dropout probability. Goes into model.config.\"}\n",
    "    )\n",
    "    decoder_layerdrop: Optional[float] = field(\n",
    "        default=None, metadata={\"help\": \"Decoder layer dropout probability. Goes into model.config.\"}\n",
    "    )\n",
    "    dropout: Optional[float] = field(default=None, metadata={\"help\": \"Dropout probability. Goes into model.config.\"})\n",
    "    attention_dropout: Optional[float] = field(\n",
    "        default=None, metadata={\"help\": \"Attention dropout probability. Goes into model.config.\"}\n",
    "    )\n",
    "    lr_scheduler: Optional[str] = field(\n",
    "        default=\"linear\", metadata={\"help\": f\"Which lr scheduler to use.\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4af93ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using cuda_amp half precision backend\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 61290\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16\n",
      "  Number of trainable parameters = 147298320\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:28, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.082100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.076000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/aiffelthon/ch/checkpoint-16\n",
      "Configuration saved in /aiffel/aiffel/aiffelthon/ch/checkpoint-16/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffelthon/ch/checkpoint-16/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16, training_loss=0.07062062248587608, metrics={'train_runtime': 29.0873, 'train_samples_per_second': 17.602, 'train_steps_per_second': 0.55, 'total_flos': 90162516197376.0, 'train_loss': 0.07062062248587608, 'epoch': 0.01})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"~/aiffel/aiffelthon/ch\",\n",
    "    num_train_epochs = 6,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=4, \n",
    "    save_steps=16, \n",
    "    eval_steps=7500, \n",
    "    warmup_steps=3000,\n",
    "    max_steps=16,\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,)\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=bertshared,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24b01b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /aiffel/.cache/huggingface/hub/models--kykim--bertshared-kor-base/snapshots/8ea27677d006a547aee2a7753d1ff18a0346860c/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /aiffel/.cache/huggingface/hub/models--kykim--bertshared-kor-base/snapshots/8ea27677d006a547aee2a7753d1ff18a0346860c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--kykim--bertshared-kor-base/snapshots/8ea27677d006a547aee2a7753d1ff18a0346860c/config.json\n",
      "Model config EncoderDecoderConfig {\n",
      "  \"_commit_hash\": \"8ea27677d006a547aee2a7753d1ff18a0346860c\",\n",
      "  \"_name_or_path\": \"kykim/bertshared-kor-base\",\n",
      "  \"architectures\": [\n",
      "    \"EncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": [\n",
      "      \"BertForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": 2,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"embedding_size\": 768,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 3,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": 3,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.24.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 42000\n",
      "  },\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"BertForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"embedding_size\": 768,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 3,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": 3,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.24.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 42000\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"length_penalty\": 1.5,\n",
      "  \"min_length\": 30,\n",
      "  \"model_type\": \"encoder-decoder\",\n",
      "  \"no_repeat_ngram_size\": 2,\n",
      "  \"num_beams\": 4,\n",
      "  \"tie_encoder_decoder\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"vocab_size\": 42000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /aiffel/.cache/huggingface/hub/models--kykim--bertshared-kor-base/snapshots/8ea27677d006a547aee2a7753d1ff18a0346860c/config.json\n",
      "Model config EncoderDecoderConfig {\n",
      "  \"_commit_hash\": \"8ea27677d006a547aee2a7753d1ff18a0346860c\",\n",
      "  \"_name_or_path\": \"kykim/bertshared-kor-base\",\n",
      "  \"architectures\": [\n",
      "    \"EncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": [\n",
      "      \"BertForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": 2,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"embedding_size\": 768,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 3,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": 3,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.24.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 42000\n",
      "  },\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"BertForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"embedding_size\": 768,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 3,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": 3,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.24.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 42000\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"length_penalty\": 1.5,\n",
      "  \"min_length\": 30,\n",
      "  \"model_type\": \"encoder-decoder\",\n",
      "  \"no_repeat_ngram_size\": 2,\n",
      "  \"num_beams\": 4,\n",
      "  \"tie_encoder_decoder\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"vocab_size\": 42000\n",
      "}\n",
      "\n",
      "loading configuration file /aiffel/aiffel/aiffelthon/ch/checkpoint-16/config.json\n",
      "Model config EncoderDecoderConfig {\n",
      "  \"_commit_hash\": null,\n",
      "  \"_name_or_path\": \"kykim/bertshared-kor-base\",\n",
      "  \"architectures\": [\n",
      "    \"EncoderDecoderModel\"\n",
      "  ],\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": true,\n",
      "    \"architectures\": [\n",
      "      \"BertForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": 2,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"embedding_size\": 768,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 3,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": true,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": 3,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.24.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 42000\n",
      "  },\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": [\n",
      "      \"BertForMaskedLM\"\n",
      "    ],\n",
      "    \"attention_probs_dropout_prob\": 0.1,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"classifier_dropout\": null,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"directionality\": \"bidi\",\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"embedding_size\": 768,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": 3,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"gradient_checkpointing\": false,\n",
      "    \"hidden_act\": \"gelu\",\n",
      "    \"hidden_dropout_prob\": 0.1,\n",
      "    \"hidden_size\": 768,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 3072,\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"layer_norm_eps\": 1e-12,\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"max_position_embeddings\": 512,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"bert\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_attention_heads\": 12,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_hidden_layers\": 12,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": 0,\n",
      "    \"pooler_fc_size\": 768,\n",
      "    \"pooler_num_attention_heads\": 12,\n",
      "    \"pooler_num_fc_layers\": 3,\n",
      "    \"pooler_size_per_head\": 128,\n",
      "    \"pooler_type\": \"first_token_transform\",\n",
      "    \"position_embedding_type\": \"absolute\",\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": 3,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.24.0\",\n",
      "    \"type_vocab_size\": 2,\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 42000\n",
      "  },\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 32,\n",
      "  \"min_length\": 30,\n",
      "  \"model_type\": \"encoder-decoder\",\n",
      "  \"no_repeat_ngram_size\": 2,\n",
      "  \"num_beams\": 5,\n",
      "  \"tie_encoder_decoder\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": null,\n",
      "  \"vocab_size\": 42000\n",
      "}\n",
      "\n",
      "loading weights file /aiffel/aiffel/aiffelthon/ch/checkpoint-16/pytorch_model.bin\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
      "\n",
      "All the weights of EncoderDecoderModel were initialized from the model checkpoint at /aiffel/aiffel/aiffelthon/ch/checkpoint-16/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50f371462d04e7e8427ab7195b688f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:3 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")\n",
    "model = EncoderDecoderModel.from_pretrained('/aiffel/aiffel/aiffelthon/ch/checkpoint-16/').to(\"cuda\")\n",
    "batch_size = 32\n",
    "\n",
    "# map data correctly\n",
    "def generate_summary(batch):\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=32, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    batch[\"pred\"] = output_str\n",
    "\n",
    "    return batch\n",
    "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"Text\"])\n",
    "pred_str = results[\"pred\"]\n",
    "label_str = results[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dd59f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted sentence :  8 8분분 시간 시간 제약제약제약 때문에 때문에 인해 인해 계속 계속 연관 연관 연결된된된 문제 문제 문제로 문제로 문제가 문제가문제가문제가 문제가 계속\n",
      "real sentence :  이군현 위원 그런데 아까 말씀드렸듯이 이게 14조면 국가 전체 예산의 3 6 에 불과하다고요 이렇게 농림부 예산이 증가하고 있지 않은데 내년에 1500억 쌀생산조정제 예산을 확실하게 확보하겠다 하는 것에 대해서 많은 농민단체나 국민들이 의심을 하고 있다고요 과연 농림부가 그런 능력이 있는가 또 그런 의지가 있는가 하는 것에 대해서 의심을 하고 있거든요\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산산식품식품부장부장부부총리총리자자선선선을선을 선 선 동 동감감을감을도를도를도로도로\n",
      "real sentence :  김철민 위원 용산 화상경마장에 대해서 잠시 질문을 하도록 하겠습니다 당초 마사회의 화상경마장 이전 과정에서 인근 학교와의 거리 또 민원 발생 가능성 등을 우리 농림부에 허위로 보고하고 이에 대해 제대로 검증하지 않고 이전 승인을 하면서 문제가 촉발되었다는 지적이 있습니다 후보자께서는 장관에 취임하시면 당시의 이전 승인 과정을 면밀히 재검토하고 그 내용에 대해서 국회에 보고할 용의가 있으십니까\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산식품식품부장부장부부후보후보자자 김영 김영록록 위원 위원위원은위원은위원위원님님님이님이 말씀 말씀\n",
      "real sentence :  농림축산식품부장관후보자 김영록 4대강 사업에 대한 평가는 다양한 평가가 있습니다 저는 4대강 사업에 대해서 당초 할 때 제가 농촌 출신이기 때문에 한 13조 정도의 예산을 투입하면 이 하천정비를 할 수 있다 이렇게 생각했습니다마는 그 이상의 투자가 이루어진 부분에 대해서는 여러 가지 평가가 있습니다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산산식품식품부장부장부부총리총리회회회의회의후보후보추천추천위원회위원회위위위원회위원위원 위원 위원\n",
      "real sentence :  농림축산식품부장관후보자 김영록 그래서 지금 위원님께서 저한테 질문하신 것으로 알고 있는데요 이 부분은 정부 여러 가지 사항이 얽혀 있기 때문에 제가 대안을 한번 찾아보겠습니다 그런데 지금 이 자리에서 법령을 무시하고 제가 말씀드리기는 좀 어렵습니다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  김종 김종회회 위원 위원위원위원 존경 존경하는하는 김 김영 김영청청 후보자 후보자께서는께서는께서께서 알고 알고 알기 알기로로 차로 차로\n",
      "real sentence :  김종회 위원 존경하는 김영록 후보자께서는 제가 알고 듣기로 농민을 위해서 또 6년간 농해수위에서 농민 편에 서서 농민의 애로를 함께한 것으로 알고 있습니다 그렇기 때문에 제가 간곡히 당부드리고 싶은 말씀은 기존에 지금까지 후보자께서 해 오셨던 이러한 신념과 마음가짐을 가지고 어민의 편에서 농민의 편에서 이러한 사안을 바라보신다고 하면 한정어업 허가는 내줄 수밖에 없습니다 이 부분을 후보자께서는 각별히 유념해 주셔서 전향적으로 어민의 편에서 해결의 실마리 풀어 주시기를 간곡히 당부드립니다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  이완 이완영영위원 위원 위원위원위원직직무무대리대리 이 이개개 개 개개개를개를 개를 개를 빨리 빨리 빠르게 빠르게 이완\n",
      "real sentence :  이완영 위원 왜 안 가느냐 지금 환경단체들이 철새가 날아오면 보호하기 위해서 먹이도 주고 이러다 보니까 자생적으로 사실 먹고 살아야 되는데 이제 갖다 주는 것 그냥 먹습니다 그러다 보니까 비대해지고 다시 날아갈 생각을 안 한다 이런 설이 제기됐어요\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  다음 다음 농 농식품식품부부 관계자 관계자의의 이야기 이야기 하기 하기 하기에 먹기에 먹기에 하기에 하기에하기에하기에에에 이에 이에 대해 대해서 대해서\n",
      "real sentence :  위성곤 위원 그런데 다음 농식품부 관계자의 얘기 보겠습니다 진드기와 벌레 등이 살충제에 대한 내성이 생기면서 인허가 약제품은 효과가 떨어지기 때문에 계속해서 독성이 강한 미승인 약품을 사용하고 있는 것으로 파악하고 있다 당국자가 답변한 내용입니다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산산식품식품부부차차관관 김현 김현수수 원자력 원자력곤곤위원위원위원은위원은위원 위원 위원 회의 회의\n",
      "real sentence :  위성곤 위원 계란에 대한 약물검사라든가 안에 있는 잔류량 검사라든가 우리 기관이 아니면 불가능한데 제가 봤을 때는 이것을 의무화시켜야 된다고 생각이 됩니다 그래서 저는 gp센터를 반드시 만들어야 된다고 생각합니다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산식품식품부장부장부부 김영 김영록록 친환경 친환경 부분의 부분의 위반 위반 사례가 사례가 현장 현장 현장에서 현장에서 업체에서 업체에서 업체들이 업체들이\n",
      "real sentence :  위성곤 위원 구체적으로 현장에 가면 계사에 가면 살충제를 뭐를 쓰고 있는지 그리고 살충제 성분은 이곳에 있는지 없는지 지금 우리가 살충제 성분에 대해서 닭만 검사를 하고 있는데 계사 검사는 하고 있습니까 농림축산식품부장관 김영록 계사 소독은 하도록 하고 있지만 실제 분석은 하지 않은 것으로 알고 있습니다\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  충북 충북 제 제천천시시단단단을단을 신청을 신청을 신청 신청신청신청하신하신 위원 위원위원위원님님은님은 두 두 분 분\n",
      "real sentence :  권석창 위원 이제 두 분밖에 안 남았으니까 조금 피곤해도 성실한 답변 좀 부탁드리겠습니다 이번 사태 제가 지적한 내용 중에 가장 큰 내용은 이러한 공급 사슬상에 횡적으로 단절한 부분 이 부분에 대한 문제를 제기하면서 궁극적으로 현재 조직을 건드리지 않고도 기능적으로 잘만 나누면 종적인 분류가 가능하다 저는 그렇게 봅니다\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num in range(10):\n",
    "    print('predicted sentence : ',pred_str[num])\n",
    "    print('real sentence : ', label_str[num])\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfcd5c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted sentence :  올해 올해 국가 국가 전체 전체 예산 예산 증가 증가비율비율 비율이 비율이 비율을 비율을 비율 비율비율 비율을 정도를 정도를 정도 정도정도정도 정도 정도로 정도로 정도만 정도만\n",
      "real sentence :  이군현 위원 그런데 아까 말씀드렸듯이 이게 14조면 국가 전체 예산의 3 6 에 불과하다고요 이렇게 농림부 예산이 증가하고 있지 않은데 내년에 1500억 쌀생산조정제 예산을 확실하게 확보하겠다 하는 것에 대해서 많은 농민단체나 국민들이 의심을 하고 있다고요 과연 농림부가 그런 능력이 있는가 또 그런 의지가 있는가 하는 것에 대해서 의심을 하고 있거든요\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산식품식품부장부장부부 부 부부감감감을감을 하기 하기 하기에 하기에하기에하기에 있기에 있기에 있기 있기 있기에 때문에 때문에\n",
      "real sentence :  김철민 위원 용산 화상경마장에 대해서 잠시 질문을 하도록 하겠습니다 당초 마사회의 화상경마장 이전 과정에서 인근 학교와의 거리 또 민원 발생 가능성 등을 우리 농림부에 허위로 보고하고 이에 대해 제대로 검증하지 않고 이전 승인을 하면서 문제가 촉발되었다는 지적이 있습니다 후보자께서는 장관에 취임하시면 당시의 이전 승인 과정을 면밀히 재검토하고 그 내용에 대해서 국회에 보고할 용의가 있으십니까\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산식품식품부장부장부부제제 제 제션이션이션을션을 대폭 대폭 늘어나 늘어나지지 않으면 않으면 안 안 된다고 된다고\n",
      "real sentence :  농림축산식품부장관후보자 김영록 4대강 사업에 대한 평가는 다양한 평가가 있습니다 저는 4대강 사업에 대해서 당초 할 때 제가 농촌 출신이기 때문에 한 13조 정도의 예산을 투입하면 이 하천정비를 할 수 있다 이렇게 생각했습니다마는 그 이상의 투자가 이루어진 부분에 대해서는 여러 가지 평가가 있습니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  지난 지난 그 그 부분이 부분이 부분을 부분을부분을부분을부분부분부분에부분에 부분에 부분에 부분 부분부분부분이부분이부분에부분들들들에들에들이들이들\n",
      "real sentence :  농림축산식품부장관후보자 김영록 그래서 지금 위원님께서 저한테 질문하신 것으로 알고 있는데요 이 부분은 정부 여러 가지 사항이 얽혀 있기 때문에 제가 대안을 한번 찾아보겠습니다 그런데 지금 이 자리에서 법령을 무시하고 제가 말씀드리기는 좀 어렵습니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림부장부장부가부가 전 전향향향을향을 향을 향을 향이 향이향이향이맛이맛이맛을맛을 맛을 맛을맛을맛맛해해\n",
      "real sentence :  김종회 위원 존경하는 김영록 후보자께서는 제가 알고 듣기로 농민을 위해서 또 6년간 농해수위에서 농민 편에 서서 농민의 애로를 함께한 것으로 알고 있습니다 그렇기 때문에 제가 간곡히 당부드리고 싶은 말씀은 기존에 지금까지 후보자께서 해 오셨던 이러한 신념과 마음가짐을 가지고 어민의 편에서 농민의 편에서 이러한 사안을 바라보신다고 하면 한정어업 허가는 내줄 수밖에 없습니다 이 부분을 후보자께서는 각별히 유념해 주셔서 전향적으로 어민의 편에서 해결의 실마리 풀어 주시기를 간곡히 당부드립니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  여당 여당위원 위원 위원위원위원위위대리대리호호호를호를호호가호가호호는호는 무난하게 무난하게 무난 무난 무난하게 무난한 무난 무난한 무난한 무난하게\n",
      "real sentence :  이완영 위원 왜 안 가느냐 지금 환경단체들이 철새가 날아오면 보호하기 위해서 먹이도 주고 이러다 보니까 자생적으로 사실 먹고 살아야 되는데 이제 갖다 주는 것 그냥 먹습니다 그러다 보니까 비대해지고 다시 날아갈 생각을 안 한다 이런 설이 제기됐어요\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  위성 위성 당 당국국국이국이 국 국국국인국인음식음식부부부에서부에서에서에서 배출 배출배출배출제제제를제를 실시\n",
      "real sentence :  위성곤 위원 그런데 다음 농식품부 관계자의 얘기 보겠습니다 진드기와 벌레 등이 살충제에 대한 내성이 생기면서 인허가 약제품은 효과가 떨어지기 때문에 계속해서 독성이 강한 미승인 약품을 사용하고 있는 것으로 파악하고 있다 당국자가 답변한 내용입니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산산식품식품부부 김현 김현수수 한국 한국 기관 기관기관이기관이이이이를이를 않기 않기하기하기 않기 없기 없기\n",
      "real sentence :  위성곤 위원 계란에 대한 약물검사라든가 안에 있는 잔류량 검사라든가 우리 기관이 아니면 불가능한데 제가 봤을 때는 이것을 의무화시켜야 된다고 생각이 됩니다 그래서 저는 gp센터를 반드시 만들어야 된다고 생각합니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  농림 농림축축산산식품식품부장부장부부 김영 김영록록 위원 위원위원위원위원은위원 위원위원회위원회위 위 위위위도\n",
      "real sentence :  위성곤 위원 구체적으로 현장에 가면 계사에 가면 살충제를 뭐를 쓰고 있는지 그리고 살충제 성분은 이곳에 있는지 없는지 지금 우리가 살충제 성분에 대해서 닭만 검사를 하고 있는데 계사 검사는 하고 있습니까 농림축산식품부장관 김영록 계사 소독은 하도록 하고 있지만 실제 분석은 하지 않은 것으로 알고 있습니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "predicted sentence :  위원장 위원장위원장위원장위위 위 위위위원회위원회 위원 위원위원위원님님님과님과님이님이 둘이 둘이둘이둘이 둘이 둘이서 둘이서만만\n",
      "real sentence :  권석창 위원 이제 두 분밖에 안 남았으니까 조금 피곤해도 성실한 답변 좀 부탁드리겠습니다 이번 사태 제가 지적한 내용 중에 가장 큰 내용은 이러한 공급 사슬상에 횡적으로 단절한 부분 이 부분에 대한 문제를 제기하면서 궁극적으로 현재 조직을 건드리지 않고도 기능적으로 잘만 나누면 종적인 분류가 가능하다 저는 그렇게 봅니다\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for num in range(10):\n",
    "    print('predicted sentence : ',pred_str[num])\n",
    "    print('real sentence : ', label_str[num])\n",
    "    print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a663cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROUGE 1 SCORE: \",rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid)\n",
    "print(\"ROUGE 2 SCORE: \",rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n",
    "print(\"ROUGE L SCORE: \",rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
